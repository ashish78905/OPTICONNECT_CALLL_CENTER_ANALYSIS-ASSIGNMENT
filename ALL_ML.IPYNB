{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhQ8jsePqvZPX2AlWUas+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashish78905/OPTICONNECT_CALLL_CENTER_ANALYSIS-ASSIGNMENT/blob/main/ALL_ML.IPYNB\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE LINEAR REGRESSION 01"
      ],
      "metadata": {
        "id": "hq9RBEyp4_WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the diabetes dataset from sklearn\n",
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "# Display the loaded dataset object\n",
        "diabetes\n",
        "# Print the description of the dataset\n",
        "print(diabetes.DESCR)\n",
        "# Access and display the feature data\n",
        "diabetes.data\n",
        "# Access and display the target variable\n",
        "diabetes.target\n",
        "# Access and display the names of the features\n",
        "diabetes.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "# Add the target variable as a new column in the DataFrame\n",
        "data['target'] = diabetes.target"
      ],
      "metadata": {
        "id": "woiVUp8r5Hta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA, DATCLEANING, DATA PREPARATION, FEATURE ENGINEERING"
      ],
      "metadata": {
        "id": "Xbjv1e6K5mMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVIDE THE DATA INTO X, Y. For simple linear regression, we take only one feature.\n",
        "\n",
        "# Select the 'bmi' column as the feature (X)\n",
        "X = data[[\"bmi\"]]\n",
        "# Select the 'target' column as the target variable (y)\n",
        "y = data[\"target\"]\n",
        "# Display the feature data (X)\n",
        "X\n",
        "# Display the target variable (y)\n",
        "y"
      ],
      "metadata": {
        "id": "xLWAFKIY5qZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the data into train-test"
      ],
      "metadata": {
        "id": "9KmV8sYa58UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the train_test_split function from sklearn.model_selection to split data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dKp_gU_G59d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# X_train: training features\n",
        "# X_test: testing features\n",
        "# y_train: training target\n",
        "# y_test: testing target\n",
        "# test_size = 0.2 means 20% of the data will be used for testing\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "BlC2UKnt6BJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the training features\n",
        "X_train\n",
        "# Display the testing features\n",
        "X_test\n",
        "# Display the training target\n",
        "y_train\n",
        "# Display the testing target\n",
        "y_test"
      ],
      "metadata": {
        "id": "KHayKB6F6FPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "I-1ntDZ46PiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the LinearRegression model from sklearn.linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Create an instance of the LinearRegression model\n",
        "model = LinearRegression()\n",
        "# Display the model object\n",
        "model\n",
        "# Training of the model\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "# At the backend, it will use gradient descent to give optimal coefficients\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "aS7wKLfp6R5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the coefficient (slope) of the linear regression model\n",
        "model.coef_\n",
        "# Display the intercept (y-intercept) of the linear regression model\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "-uz5TH6g6kZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model pridiction"
      ],
      "metadata": {
        "id": "k2mBfQYD6wTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the target variable (y) for the test set (X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "# Display the predicted values\n",
        "y_pred"
      ],
      "metadata": {
        "id": "Wu7OpINb60LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vizualize the result"
      ],
      "metadata": {
        "id": "W0Q_xD3q7Gix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the matplotlib.pyplot library for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# visualise the result\n",
        "# Create a scatter plot of the actual test data (X_test vs y_test)\n",
        "plt.scatter(X_test, y_test, color = 'black', label = 'Actual data')\n",
        "# Plot the linear regression line using the test features and predicted values\n",
        "plt.plot(X_test, y_pred, color = 'blue', linewidth = 3, label = \"Linear regression line\")\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"BMI\")\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"One year progression-target\")\n",
        "# Set the title of the plot\n",
        "plt.title(\"Linear regression on diabetes data\")\n",
        "# Display the legend\n",
        "plt.legend()\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A7ZnKzBQ69oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bic4N0x3hKCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple linear regression 02"
      ],
      "metadata": {
        "id": "g_uXZO5468ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "# Import matplotlib.pyplot for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# Read the data from the csv file into a pandas DataFrame\n",
        "df = pd.read_csv(\"height-weight.csv\")\n",
        "# Create a scatter plot of Weight vs Height\n",
        "plt.scatter(df.Weight, df.Height)\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"weight\")\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"height\")\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j5xXKonP8B0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "divide the data into X, y"
      ],
      "metadata": {
        "id": "7Sq72S7mGExj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the independent feature (X) as the 'Weight' column from the DataFrame\n",
        "X=df[[\"Weight\"]] #independent feature\n",
        "# Define the dependent feature (y) as the 'Height' column from the DataFrame\n",
        "y = df[\"Height\"] #dependent feature"
      ],
      "metadata": {
        "id": "gnTyeF1SGEDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the train_test_split function from sklearn.model_selection to split data\n",
        "#train test split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XxmtR0GPGO5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# X_train: training features\n",
        "# X_test: testing features\n",
        "# y_train: training target\n",
        "# y_test: testing target\n",
        "# test_size = 0.25 means 25% of the data will be used for testing\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
        "# Display the shapes of the resulting arrays\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "Hiai4GF6GRfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling>> standardization >> fit_transform >>tain, transform>>test"
      ],
      "metadata": {
        "id": "9nvnCv96GhPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the StandardScaler from sklearn.preprocessing for feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Create an instance of the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Always perform scaling after train test split\n",
        "# y/target variable should not be scaled\n",
        "# avoid scaling categorical features\n",
        "# Scale the training features using fit_transform\n",
        "X_train = scaler.fit_transform(X_train) #for train data use fit_transform\n",
        "# Scale the testing features using only transform\n",
        "X_test = scaler.transform(X_test) #for test use only transform as it is representative of unknown data>>\n",
        "# Display the scaled training features\n",
        "X_train\n",
        "# Display the scaled testing features\n",
        "X_test\n",
        "# Create a scatter plot of the scaled training features vs the training target\n",
        "plt.scatter(X_train, y_train)"
      ],
      "metadata": {
        "id": "5wvpDZ6UGi_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the LinearRegression model from sklearn.linear_model\n",
        "#model training\n",
        "from sklearn.linear_selection import LinearRegression\n",
        "\n",
        "#linear regression parameters:\n",
        "#fit_intercept >> The best fit line will have intercept, by default it is true\n",
        "#copy__X >> copy the original X_train and then build the model, dont modify the original data,by default>>true\n",
        "#n_jobs >> processor you want to use\n",
        "#positive>> you want all of your coefficient to be positive\n",
        "\n",
        "\n",
        "#After building the model, you have attributes of the mode\n",
        "#coef\n",
        "#intercept"
      ],
      "metadata": {
        "id": "yHhJ9uN8G8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the LinearRegression model\n",
        "regressor = LinearRegression()\n",
        "# Display the model object\n",
        "regressor\n",
        "# Training of the model\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iVDGwrdBHAuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coefficient (slope) of the linear regression model\n",
        "print(\"The slope or coef of model is\", regressor.coef_)\n",
        "# Print the intercept (y-intercept) of the linear regression model\n",
        "print(\"The intercept of the model is\", regressor.intercept_)"
      ],
      "metadata": {
        "id": "LyUzSKzIHHuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicted height output = intercept + coef_(weights), y_pred_train = 160.0+17.74*(X_train)\n",
        "Prediction on test data\n",
        "predicted height output = intercept + coef_(weights) , y_pred_test = 160.0+17.74*(X_test)"
      ],
      "metadata": {
        "id": "aWxAyXUlHNhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training data\n",
        "regressor.predict(X_train)\n",
        "# Create a scatter plot of the scaled training features vs the training target\n",
        "plt.scatter(X_train, y_train)\n",
        "# Plot the linear regression line for the training data\n",
        "plt.plot(X_train, regressor.predict(X_train), 'r')\n",
        "# Make predictions on the testing data\n",
        "y_pred_test = regressor.predict(X_test)\n",
        "# Display the predicted and actual values for the test set\n",
        "y_pred_test, y_test\n",
        "# Create a scatter plot of the scaled testing features vs the testing target\n",
        "plt.scatter(X_test, y_test)\n",
        "# Plot the linear regression line for the testing data\n",
        "plt.plot(X_test, regressor.predict(X_test), 'r')"
      ],
      "metadata": {
        "id": "4twbkhwTHOxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performance metrics"
      ],
      "metadata": {
        "id": "mIRLQmYfHf3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary metrics from sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# Calculate the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "# Calculate the Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "# Calculate the Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print the calculated metrics\n",
        "print(mse, mae, rmse)\n",
        "\n",
        "# Rsquare =  1-SSR/SST\n",
        "\n",
        "# Import the r2_score from sklearn.metrics\n",
        "from sklearn.metrics import r2_score\n",
        "# Calculate the R-squared score\n",
        "score = r2_score(y_test, y_pred_test)\n",
        "# Display the R-squared score\n",
        "score\n",
        "\n",
        "#adjusted r square\n",
        "#R2 = 1 – [(1-R2)*(n-1)/(n-k-1)] #n is no of obs, k is no predictor varaiables\n",
        "# Calculate the adjusted R-squared score\n",
        "1-(1-score)*(len(y_test)-1)/(len(y_test) - X_test.shape[1] -1)\n",
        "#adjusted r square will be always lesser than rsquare"
      ],
      "metadata": {
        "id": "girk30E6HhvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of columns in the testing features (X_test)\n",
        "#to get no of columns\n",
        "X_test.shape[1]"
      ],
      "metadata": {
        "id": "K1O8os02IAd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assumption\n",
        "#X-y should have linear relationship\n",
        "# Observation should have no relation\n",
        "# error should have constant variance\n",
        "#error should be normally distribute\n",
        "# Create a scatter plot of the actual test values vs the predicted test values\n",
        "plt.scatter(y_test, y_pred_test)\n",
        "\n",
        "#residual/error\n",
        "# Calculate the residual error\n",
        "error = y_test - y_pred_test\n",
        "# Display the residual error\n",
        "error"
      ],
      "metadata": {
        "id": "sEcP87vKICo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiple linear regression 01"
      ],
      "metadata": {
        "id": "6rDX0gajI0IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple linear regression - It models the relationship between dependent variable y and more than one independent variable X#To predict disease progression one year after the baseline"
      ],
      "metadata": {
        "id": "G0MSOPjEReJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the load_diabetes function from sklearn.datasets\n",
        "from sklearn.datasets import load_diabetes\n",
        "# Read the dataset\n",
        "diabetes = load_diabetes()\n",
        "# Print the description of the dataset\n",
        "print(diabetes.DESCR)\n",
        "# Access the feature data\n",
        "diabetes.data\n",
        "# Access the target variable\n",
        "diabetes.target\n",
        "# Access the names of the features\n",
        "diabetes.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "# Display the DataFrame\n",
        "data\n",
        "# Add the target variable as a new column in the DataFrame\n",
        "data['target'] = diabetes.target"
      ],
      "metadata": {
        "id": "iity8kNXJJnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA and data prep\n",
        "# Divide into X (features) and y (target)\n",
        "\n",
        "# Define the independent features (X) by dropping the 'target' column\n",
        "X = data.drop('target', axis = 1)\n",
        "# Define the dependent feature (y) as the 'target' column\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "# Display the shapes of the training and testing feature sets\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "4d8qaj9pSMaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling (optional)\n",
        "# This section is commented out, but if scaling were needed,\n",
        "# you would typically use StandardScaler here after splitting the data.\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Mcs4a9rhSePA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Create an instance of the LinearRegression model\n",
        "model = LinearRegression()\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "model.fit(X_train, y_train)\n",
        "# Display the shape of the training data\n",
        "X_train.shape\n",
        "# Display the coefficients of the model\n",
        "model.coef_\n",
        "# Display the number of coefficients\n",
        "len(model.coef_)\n",
        "# Display the intercept of the model\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "wt9L6VGYShT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data using the trained model\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "b0gobS5uSzXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary metrics from sklearn.metrics (Mean Squared Error and R-squared)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# Calculate and display the Mean Squared Error (MSE) between actual and predicted values\n",
        "mean_squared_error(y_test, y_pred)\n",
        "# Calculate and display the R-squared score, which indicates the proportion of variance in the target variable that is predictable from the features\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "SHTUaBrbS1wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple linear regression 02"
      ],
      "metadata": {
        "id": "dFDbA6ftTxxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "# Display the dataset object\n",
        "data\n",
        "# Print the description of the dataset\n",
        "print(data.DESCR)\n",
        "# Print the keys of the dataset dictionary\n",
        "data.keys()\n",
        "# Print the target names of the dataset\n",
        "data.target_names\n",
        "# Access and display the feature data\n",
        "data.data\n",
        "# Access and display the names of the features\n",
        "data.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "# Display the DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "u_ruEqjOT2sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the target variable ('Price') as a new column to the DataFrame\n",
        "df['Price'] = data.target\n",
        "# Display information about the DataFrame (column types, non-null values, etc.)\n",
        "df.info()\n",
        "# Display the data types of each column\n",
        "df.dtypes\n",
        "# Display the first 5 rows of the DataFrame\n",
        "df.head()\n",
        "# Display the last 5 rows of the DataFrame\n",
        "df.tail()\n",
        "# Display 3 random rows from the DataFrame\n",
        "df.sample(3)\n",
        "# Check for and display the sum of null values in each column\n",
        "df.isnull().sum()\n",
        "# Display descriptive statistics for the numerical columns\n",
        "df.describe()\n",
        "# Calculate and display the correlation matrix of the DataFrame\n",
        "df.corr()\n",
        "# Create a heatmap visualization of the correlation matrix with annotations\n",
        "sns.heatmap(df.corr(), annot = True)"
      ],
      "metadata": {
        "id": "z7vOrhe8YZ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the data into independent features (X) and the dependent variable (y)\n",
        "X = df.iloc[:, :-1] #independent var (all columns except the last one)\n",
        "y = df.iloc[:, -1] #dependent variable (the last column, 'Price')\n",
        "# Display the independent features (X)\n",
        "X\n",
        "# Display the dependent variable (y)\n",
        "y"
      ],
      "metadata": {
        "id": "9VmwIyztYzWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing train_test_split function from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# X -> features (independent variables)\n",
        "# y -> target/labels (dependent variable)\n",
        "# test_size = 0.30 → 30% data goes to testing, 70% to training\n",
        "# random_state = 1 → ensures reproducibility (same split every run)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=1)\n",
        "\n",
        "# Checking the shape of the resulting splits\n",
        "# X_train → training features\n",
        "# X_test  → testing features\n",
        "# y_train → training labels\n",
        "# y_test  → testing labels\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "EuR6MURyY-H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing StandardScaler from sklearn.preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creating an object of StandardScaler\n",
        "# StandardScaler removes the mean and scales the data to unit variance (z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler on X_train and transforming it\n",
        "# fit() → calculates mean & standard deviation from training data\n",
        "# transform() → applies scaling using those values\n",
        "# fit_transform() = fit() + transform() (done in one step)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transforming X_test using the same mean & std from X_train\n",
        "# (Important: we do NOT fit again on test data, to avoid data leakage)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Now X_train and X_test contain standardized values (mean=0, std=1 for training set)\n",
        "X_train\n",
        "X_test\n"
      ],
      "metadata": {
        "id": "pR2YaXb3ZIol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "# Importing LinearRegression model from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Creating an object of LinearRegression\n",
        "model = LinearRegression()\n",
        "\n",
        "# Training the model using training data (X_train, y_train)\n",
        "# .fit() → learns the relationship between features (X_train) and target (y_train)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Checking the shape of X_train\n",
        "# This tells us how many samples (rows) and features (columns) we have\n",
        "X_train.shape\n",
        "\n",
        "# Checking the number of coefficients learned by the model\n",
        "# len(model.coef_) → should equal number of features (columns in X_train)\n",
        "len(model.coef_)\n",
        "\n",
        "# Coefficients of the model\n",
        "# Each coefficient represents the weight assigned to a feature\n",
        "model.coef_\n",
        "\n",
        "# Intercept of the model\n",
        "# This is the constant term (bias) in the linear regression equation\n",
        "model.intercept_\n"
      ],
      "metadata": {
        "id": "ySkKiorbZYjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test set using the trained model\n",
        "\n",
        "# model.predict(X_test) → uses the learned coefficients & intercept\n",
        "# to predict target values for the unseen test features\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "wwMxjoGJZpXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Metrics\n",
        "\n",
        "# Importing different regression performance metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "# Formula: average of (actual - predicted)^2\n",
        "# Punishes larger errors more (because of squaring)\n",
        "print(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "# Formula: average of |actual - predicted|\n",
        "# Gives error in the same unit as target variable\n",
        "print(mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "# Square root of MSE → easier to interpret as it has same unit as target\n",
        "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# R² Score (Coefficient of Determination)\n",
        "# Tells how well model explains the variance in data\n",
        "# R² = 1 → perfect prediction, R² = 0 → model no better than mean\n",
        "score = r2_score(y_test, y_pred)\n",
        "\n",
        "# Adjusted R² Score\n",
        "# Adjusts R² by considering number of features\n",
        "# Formula: 1 - (1 - R²) * (n - 1) / (n - p - 1)\n",
        "# n = number of samples in test set\n",
        "# p = number of features in test set\n",
        "1 - (1 - score) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n"
      ],
      "metadata": {
        "id": "T7KjsLB_ZuHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumption Checking (Residual Analysis)\n",
        "\n",
        "# Scatter plot between actual values (y_test) and predicted values (y_pred)\n",
        "# If predictions are good, points should lie close to a straight diagonal line\n",
        "plt.scatter(y_test, y_pred)\n",
        "\n",
        "# Calculate residuals (errors)\n",
        "# residual = actual - predicted\n",
        "error = y_test - y_pred\n",
        "\n",
        "# Distribution plot of residuals\n",
        "# Ideally residuals should follow a normal distribution (mean ≈ 0)\n",
        "# This helps to validate the linear regression assumptions\n",
        "sns.distplot(error)\n",
        "\n",
        "# Scatter plot between predicted values and residuals\n",
        "# Ideally residuals should be randomly scattered around 0\n",
        "# (No visible pattern → good sign for linear regression assumptions)\n",
        "plt.scatter(y_pred, error)\n"
      ],
      "metadata": {
        "id": "OatNzmc4Z4oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pickling model"
      ],
      "metadata": {
        "id": "3dQVhejndRhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python pickle module is used for serialising and de-serialising a Python object structure. Any object in Python can be pickled so that it can be saved on disk. What pickle does is that it “serialises” the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script\n",
        "\n",
        "pickle>> aloows you to store the python object on the disk\n",
        "serialization : Serialization is the process of converting a data structure or object into a format that can be easily stored, transmitted, or persisted. During serialization, the object's state is converted into a stream of bytes or other formats that can be written to disk, sent over a network, or stored in memory\n",
        "Deserialization>>Deserialization is the process of reconstructing a serialized object back into its original form. During deserialization, the serialized data is read and converted back into a data structure or object that matches the original."
      ],
      "metadata": {
        "id": "teLDIt1bkvHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle   # Importing pickle module for saving/loading Python objects\n",
        "\n",
        "# Saving the trained model into a file named \"model.pkl\"\n",
        "# pickle.dump(object, file, mode)\n",
        "# object = model → the trained LinearRegression model\n",
        "# open(\"model.pkl\", \"wb\") → open file in write-binary mode to store bytes\n",
        "pickle.dump(model, open(\"model.pkl\", \"wb\"))  # write binary mode\n",
        "\n",
        "# Explanation:\n",
        "# Python object (here: model), along with its attributes (coefficients, intercept, etc.)\n",
        "# and methods, is converted into a byte stream and saved into a file.\n",
        "# Later, we can load this model back using pickle.load() without retraining.\n"
      ],
      "metadata": {
        "id": "AA6cTrCOkh7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved model from the file \"model.pkl\"\n",
        "\n",
        "# pickle.load(file) → reads the byte stream and reconstructs the original Python object\n",
        "# open(\"model.pkl\", \"rb\") → open file in read-binary mode\n",
        "model = pickle.load(open(\"model.pkl\", 'rb'))\n",
        "\n",
        "# Now 'model' is the same trained LinearRegression model we saved earlier.\n",
        "# We can directly use it for predictions without retraining.\n"
      ],
      "metadata": {
        "id": "qHELTiYalC39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the loaded model to make predictions on the test set\n",
        "\n",
        "# model.predict(X_test) → applies the learned coefficients & intercept\n",
        "# to the features in X_test and returns predicted values for target variable\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Now y_pred contains the predictions made by the trained (or loaded) model\n"
      ],
      "metadata": {
        "id": "QwIj3clClIH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# polynomial Regression"
      ],
      "metadata": {
        "id": "7WsIy9w7lTk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Generating synthetic feature X\n",
        "# np.random.rand(100,1) → 100 random numbers between 0 and 1\n",
        "# Multiplying by 2 → scales values to range [0, 2)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "X\n",
        "\n",
        "# Generating synthetic target variable y\n",
        "# Formula used: y = 4 + 3*X + 1.5*X^2 + noise\n",
        "# (Here, noise is added using np.random.randn(100,1), which gives normal distribution N(0,1))\n",
        "# This creates a quadratic relationship between X and y\n",
        "y = 4 + 3*X + 1.5*X**2 + np.random.randn(100, 1)\n",
        "y\n"
      ],
      "metadata": {
        "id": "NK3mh89ulXQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "\n",
        "# Importing train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# X = features, y = target\n",
        "# test_size = 0.2 → 20% data goes to testing, 80% to training\n",
        "# random_state = 42 → ensures reproducibility (same split every time)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Checking the shape of training and testing sets\n",
        "# X_train → training features\n",
        "# X_test  → testing features\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "pVO3GxTYoLkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Polynomial Regression\n",
        "\n",
        "# Importing PolynomialFeatures for polynomial transformation\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Degree of the polynomial (here quadratic: x, x^2)\n",
        "degree = 2\n",
        "\n",
        "# Creating polynomial features (without bias term, since LinearRegression adds intercept itself)\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "# Transforming training data into polynomial features\n",
        "# If X_train has column [x], after transformation it becomes [x, x^2]\n",
        "X_poly_train = poly_features.fit_transform(X_train)\n",
        "X_poly_train\n",
        "\n",
        "# Creating LinearRegression model\n",
        "poly_reg = LinearRegression()\n",
        "\n",
        "# Training the model with polynomial features\n",
        "poly_reg.fit(X_poly_train, y_train)\n",
        "\n",
        "# Coefficients learned by the model (for x and x^2 terms)\n",
        "poly_reg.coef_\n",
        "\n",
        "# Intercept (constant term) of the model\n",
        "poly_reg.intercept_\n"
      ],
      "metadata": {
        "id": "QYhA2cd-oV3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction on training data itself\n",
        "\n",
        "# Using the trained polynomial regression model to predict on training set\n",
        "y_poly_predict = poly_reg.predict(X_poly_train)\n",
        "\n",
        "# Importing mean_squared_error for evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculating Mean Squared Error (MSE) on training data\n",
        "# Measures how far predicted values are from actual target values\n",
        "mse_train = mean_squared_error(y_train, y_poly_predict)\n",
        "print(f'Mean Squared Error on Training Data: {mse_train}')\n",
        "\n",
        "# Visualizing the training data\n",
        "# Scatter plot → actual training points (X_train, y_train)\n",
        "plt.scatter(X_train, y_train, label=\"training data\")\n"
      ],
      "metadata": {
        "id": "lE0b6I3Uoqgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Polynomial Regression Curve along with Training Data\n",
        "\n",
        "# Scatter plot of actual training data points\n",
        "plt.scatter(X_train, y_train, label=\"training data\")\n",
        "\n",
        "# Creating a smooth range of X values between 0 and 2 (100 points)\n",
        "# This helps to draw a smooth regression curve\n",
        "X_range = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "\n",
        "# Transforming these X values into polynomial features (x, x^2)\n",
        "X_range_poly = poly_features.transform(X_range)\n",
        "\n",
        "# Plotting the polynomial regression curve\n",
        "# poly_reg.predict(X_range_poly) → predicted y values for the smooth range\n",
        "plt.plot(X_range, poly_reg.predict(X_range_poly), color='red',\n",
        "         label=f'Polynomial Regression (Degree {degree})')\n",
        "\n",
        "# Adding axis labels and title\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "\n",
        "# Showing legend (training data points vs regression curve)\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the final plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VF02SMo0o05O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multicollenearity"
      ],
      "metadata": {
        "id": "Qx-ZhiwzpvDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading California Housing dataset\n",
        "\n",
        "# fetch_california_housing → built-in dataset in sklearn\n",
        "# Contains features related to California districts and their housing prices\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Fetching the dataset (called twice in your code, but one call is enough)\n",
        "data = fetch_california_housing()\n",
        "\n",
        "# Creating a DataFrame from the dataset\n",
        "# data.data → contains the feature values (independent variables)\n",
        "# data.feature_names → column names for the features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Adding the target variable (house price) as a new column 'Price'\n",
        "# data.target → median house value for each district\n",
        "df['Price'] = data.target\n"
      ],
      "metadata": {
        "id": "ffGO2wOZp6_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multicollinearity>> when one feature is explained by all other features(more than 2)\n",
        "#when two features>> correlation\n",
        "#more than two features relationship >> VIF, clustermap"
      ],
      "metadata": {
        "id": "MHg4yBLLwH8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Heatmap of correlation matrix\n",
        "# df.corr() → computes correlation between all pairs of numerical features\n",
        "# annot=True → displays correlation values inside the heatmap cells\n",
        "# vmin=-1, vmax=1 → scale of correlation (from -1 to +1)\n",
        "sns.heatmap(df.corr(), annot=True, vmin=-1, vmax=1)\n",
        "\n",
        "# Clustermap: groups features based on their correlation similarity\n",
        "# This helps to visually identify clusters of features that are highly correlated\n",
        "# figsize → sets the size of the plot\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.clustermap(df.corr(), vmin=-1, vmax=1, annot=True)\n"
      ],
      "metadata": {
        "id": "ry3exublwKQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Multicollinearity using Variance Inflation Factor (VIF)\n",
        "\n",
        "# Importing variance_inflation_factor function\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a copy of the original DataFrame\n",
        "df1 = df.copy()\n",
        "\n",
        "# Dropping \"Longitude\" column (maybe due to high multicollinearity or not needed)\n",
        "df1.drop(\"Longitude\", axis=1, inplace=True)\n",
        "\n",
        "# Creating empty DataFrame to store VIF results\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Calculating VIF for each feature\n",
        "# variance_inflation_factor(df1.values, i) → calculates VIF for column i\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Display the VIF table\n",
        "vif\n"
      ],
      "metadata": {
        "id": "ut6b9TDnwZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping another feature (\"AveRooms\") from the DataFrame\n",
        "# Reason: It might have high multicollinearity (high VIF) with other features\n",
        "df1.drop(\"AveRooms\", axis=1, inplace=True)\n",
        "\n",
        "# Creating a new DataFrame to store updated VIF results\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding remaining feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Recalculating VIF values for all remaining features\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Displaying the updated VIF table\n",
        "vif\n"
      ],
      "metadata": {
        "id": "-EshZ2IUwsyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping another feature (\"Latitude\") from the DataFrame\n",
        "# Reason: It may have shown high VIF value (high multicollinearity with other features)\n",
        "df1.drop(\"Latitude\", axis=1, inplace=True)\n",
        "\n",
        "# Creating a new DataFrame to store recalculated VIF values\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding the remaining feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Recalculating VIF for each remaining feature\n",
        "# variance_inflation_factor(df1.values, i) → calculates VIF for feature at index i\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Displaying the updated VIF table after dropping \"Latitude\"\n",
        "vif\n"
      ],
      "metadata": {
        "id": "5vvqwmMZwxMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting independent variables (all columns except last one)\n",
        "X = df1.iloc[:, :-1]   # features\n",
        "\n",
        "# Selecting dependent variable (last column → \"Price\")\n",
        "y = df1.iloc[:, -1]    # target\n"
      ],
      "metadata": {
        "id": "FQVhmuEoxfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFE Elimination"
      ],
      "metadata": {
        "id": "ytKZL8dDy1ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1]   # all independent variables (except last column)\n",
        "y = df.iloc[:, -1]    # last column (dependent variable)\n",
        "X.columns\n"
      ],
      "metadata": {
        "id": "_HTdHpbwy7bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Features\n",
        "X.columns\n",
        "\n",
        "# Apply RFE with Linear Regression\n",
        "rfe = RFE(estimator=LinearRegression(), n_features_to_select=5)\n",
        "rfe.fit(X, y)\n",
        "\n",
        "# Predictions (not needed for feature selection, but works)\n",
        "rfe.predict(X)\n"
      ],
      "metadata": {
        "id": "mKgqt0fpzOb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean mask: True = selected\n",
        "print(rfe.support_)\n",
        "\n",
        "# Ranking of features (1 = selected, higher = eliminated earlier)\n",
        "print(rfe.ranking_)\n",
        "\n",
        "# Get the actual selected feature names\n",
        "selected_features = X.columns[rfe.support_]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "kjTnu2HIzoqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lasso ,ridge and elsticnet inplementation"
      ],
      "metadata": {
        "id": "YKDMFzESz0it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'mpg' dataset directly from seaborn's built-in datasets\n",
        "df = sns.load_dataset('mpg')\n",
        "\n",
        "# Show the first 5 rows of the dataset to quickly inspect its structure\n",
        "df.head()\n",
        "\n",
        "# Drop the \"name\" column from the dataframe, since it is categorical text and not needed for modeling\n",
        "# axis = 1 → column-wise drop, inplace=True → modify original dataframe directly\n",
        "df.drop(\"name\", axis = 1, inplace = True)\n",
        "\n",
        "# Check how many missing values (NaN) each column contains\n",
        "df.isna().sum()\n",
        "\n",
        "# Find the median value of the 'horsepower' column (used for filling missing values)\n",
        "df['horsepower'].median()\n",
        "\n",
        "# Fill missing values in 'horsepower' column with its median (better than mean in case of skewed data)\n",
        "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
        "\n",
        "# Check again for missing values after filling\n",
        "df.isna().sum()\n",
        "\n",
        "# Display summary information of the dataframe:\n",
        "# - Number of entries\n",
        "# - Column names\n",
        "# - Data types\n",
        "# - Non-null counts\n",
        "df.info()\n",
        "\n",
        "# Get data types of each column (as a Series object)\n",
        "df.dtypes\n",
        "\n",
        "# Count frequency of each unique value in the 'origin' column\n",
        "# (origin shows country of manufacture: 'usa', 'japan', 'europe')\n",
        "df['origin'].value_counts()\n",
        "\n",
        "# Convert categorical string values of 'origin' into numeric mapping:\n",
        "# 'usa' → 1, 'japan' → 2, 'europe' → 3\n",
        "df['origin'] = df['origin'].map({'usa': 1, \"japan\": 2, \"europe\": 3})\n",
        "\n",
        "# Explicitly set the 'origin' column data type to integer\n",
        "df['origin'] = df['origin'].astype(int)\n"
      ],
      "metadata": {
        "id": "87Tytcs-0xtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (independent variables) and target (dependent variable)\n",
        "\n",
        "# Create X (features): drop the 'mpg' column from df\n",
        "# axis = 1 → drop column, not row\n",
        "X = df.drop('mpg', axis=1)\n",
        "\n",
        "# Create y (target): select only the 'mpg' column (this is the value we want to predict)\n",
        "y = df['mpg']\n",
        "\n",
        "# Display the feature matrix (all columns except 'mpg')\n",
        "X\n",
        "\n",
        "# Display the target vector (only 'mpg')\n",
        "y\n"
      ],
      "metadata": {
        "id": "EDLAt0H1OzSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function for splitting dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# X → features, y → target\n",
        "# test_size = 0.3 → 30% data for testing, 70% for training\n",
        "# random_state = 1 → ensures same random split every time (reproducibility)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "\n",
        "# Show the shape (rows, columns) of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "HU0CJhSVPB2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LinearRegression model from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an object (instance) of LinearRegression class\n",
        "# This object will represent our regression model\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Just displaying the model object (optional, shows its parameters)\n",
        "regression_model\n",
        "\n",
        "# Train (fit) the regression model using training data\n",
        "# X_train → input features, y_train → target variable\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Loop through each feature column to print its coefficient\n",
        "# enumerate(X_train.columns) → gives index (i) and column name (col_name)\n",
        "# regression_model.coef_[i] → coefficient value for that feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[i]}\")\n"
      ],
      "metadata": {
        "id": "9-BQ2-W1Pw0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficients are relatively smaller, if one independent variable changes\n",
        "slightly there will be not much difference in prediction.\n",
        "This is sometime is called smoother model"
      ],
      "metadata": {
        "id": "o9XXlY3iP72C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import r2_score metric from sklearn\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Use the trained regression model to make predictions on the test dataset\n",
        "# X_test → unseen features (30% data), y_pred_linear → predicted mpg values\n",
        "y_pred_linear = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R² score (coefficient of determination)\n",
        "# y_test → actual mpg values, y_pred_linear → predicted mpg values\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Print the R² score in a formatted string\n",
        "print(f\"R square of linear regression {r2_linear}\")\n"
      ],
      "metadata": {
        "id": "tBNDoZTAQd8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge regression\n",
        "from sklearn.linear_model import Ridge              # importing Ridge class from sklearn.linear_model\n",
        "ridge_regression_model = Ridge(alpha = 0.1)         # creating a Ridge Regression model with regularization strength (alpha) = 0.1\n",
        "ridge_regression_model.fit(X_train, y_train)        # training the Ridge Regression model using training features and labels\n",
        "\n",
        "# printing coefficients for each feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {ridge_regression_model.coef_[i]}\")\n",
        "\n",
        "# Use the trained Ridge Regression model to make predictions on the test set\n",
        "y_pred_ridge = ridge_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score to check how well model predictions match actual values\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "# Print the R² score (goodness of fit measure)\n",
        "print(f\"R-squared score for Ridge Regression: {r2_ridge}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "848SZT1_QpSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We dont see much variation in coeff of ridge regression as compared to linear regression"
      ],
      "metadata": {
        "id": "-37tbKfXRHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso Regression model\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Create a Lasso Regression model with alpha = 0.5 (regularization strength)\n",
        "lasso_regression_model = Lasso(alpha = 0.5)\n",
        "\n",
        "# Train (fit) the Lasso model on training data\n",
        "lasso_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Loop through each feature column and print its coefficient\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {lasso_regression_model.coef_[i]}\")\n",
        "\n",
        "# Predict target values on the test set using the trained Lasso model\n",
        "y_pred_lasso = lasso_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score for Lasso predictions\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "# Print the R² score of the Lasso model\n",
        "print(f\"R-squared score for Lasso Regression: {r2_lasso}\")\n"
      ],
      "metadata": {
        "id": "AInxYQ7tR-cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 features coefficients are 0, Lasso helps in feature selection"
      ],
      "metadata": {
        "id": "lV6XKHkQSM88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ElasticNet Regression\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Create ElasticNet model (alpha = regularization strength, l1_ratio = balance between Lasso & Ridge)\n",
        "elastic_net_model = ElasticNet(alpha = 1, l1_ratio = 0.5)\n",
        "\n",
        "# Train the model on training data\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "\n",
        "# Print coefficients for each feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {elastic_net_model.coef_[i]}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_elastic_net = elastic_net_model.predict(X_test)\n",
        "\n",
        "# Evaluate model with R² score\n",
        "r2_elastic_net = r2_score(y_test, y_pred_elastic_net)\n",
        "print(f\"R-squared score for Elastic Net Regression: {r2_elastic_net}\")\n"
      ],
      "metadata": {
        "id": "XdeMTkZPScH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- LASSO REGRESSION WITH CROSS VALIDATION --------------------\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# LassoCV = Lasso regression + automatic alpha tuning using cross-validation\n",
        "# cv=5 → Perform 5-fold cross-validation to find the best alpha\n",
        "lassocv = LassoCV(cv=5)\n",
        "\n",
        "# Train the model on training data\n",
        "lassocv.fit(X_train, y_train)\n",
        "\n",
        "# Predict target values for the test dataset\n",
        "y_pred_lassocv = lassocv.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using R-squared score\n",
        "score_lassocv = r2_score(y_test, y_pred_lassocv)\n",
        "\n",
        "# Print the best alpha chosen automatically after CV\n",
        "print(\"Best alpha chosen by LassoCV:\", lassocv.alpha_)\n",
        "\n",
        "# Print the final R2 Score\n",
        "print(\"R2 Score (LassoCV):\", score_lassocv)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- RIDGE REGRESSION WITH CROSS VALIDATION --------------------\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# RidgeCV = Ridge regression + automatic alpha tuning using cross-validation\n",
        "# cv=5 → Perform 5-fold cross-validation\n",
        "ridgecv = RidgeCV(cv=5)\n",
        "\n",
        "# Train the Ridge model\n",
        "ridgecv.fit(X_train, y_train)\n",
        "\n",
        "# Predict target values for the test dataset\n",
        "y_pred_ridgecv = ridgecv.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using R-squared score\n",
        "score_ridgecv = r2_score(y_test, y_pred_ridgecv)\n",
        "\n",
        "# Print the best alpha chosen automatically after CV\n",
        "print(\"Best alpha chosen by RidgeCV:\", ridgecv.alpha_)\n",
        "\n",
        "# Print the final R2 Score\n",
        "print(\"R2 Score (RidgeCV):\", score_ridgecv)\n",
        "\n",
        "# Print all hyperparameters of the trained RidgeCV model\n",
        "print(\"RidgeCV Parameters:\", ridgecv.get_params())\n"
      ],
      "metadata": {
        "id": "jNzo3KPTSybf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logistic regression implementation 01"
      ],
      "metadata": {
        "id": "do_9g7mgTlBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT & LOAD IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load the built-in Iris dataset from sklearn\n",
        "data = load_iris()\n",
        "\n",
        "# Show all keys available in the dataset object\n",
        "# (like data, target, feature_names, DESCR, etc.)\n",
        "print(data.keys())\n",
        "\n",
        "# Print the description of the dataset\n",
        "# (contains details about features, targets, citations, etc.)\n",
        "print(data.DESCR)\n",
        "\n",
        "# Features (independent variables) → numerical values of measurements\n",
        "# Each row = 1 flower sample, Columns = sepal/petal length & width\n",
        "print(data.data)\n",
        "\n",
        "# Target (dependent variable) → species labels (0 = setosa, 1 = versicolor, 2 = virginica)\n",
        "print(data.target)\n",
        "\n",
        "# Feature names (column labels for the dataset)\n",
        "print(data.feature_names)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "# Convert data into pandas DataFrame for easy exploration\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target column (species labels) to the DataFrame\n",
        "df['target'] = data.target\n",
        "\n",
        "# Show first 5 rows of dataset\n",
        "print(df.head())\n",
        "\n",
        "# Show last 5 rows of dataset\n",
        "print(df.tail())\n",
        "\n",
        "# Show 2 random rows (for sampling)\n",
        "print(df.sample(2))\n",
        "\n",
        "# Show unique values in the target column (which species classes exist)\n",
        "print(df['target'].unique())\n"
      ],
      "metadata": {
        "id": "l7b3_fy4Tssq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- BINARY CLASSIFICATION SETUP --------------------\n",
        "\n",
        "# Create a new dataframe by removing rows where target = 2 (Virginica)\n",
        "# So only Setosa (0) and Versicolor (1) remain\n",
        "df_final = df[df['target'] != 2]\n",
        "\n",
        "# Check unique target values (should be [0,1])\n",
        "print(df_final.target.unique())\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "# X = all columns except last one (features)\n",
        "X = df_final.iloc[:, :-1]\n",
        "\n",
        "# y = only last column (target labels)\n",
        "y = df_final.iloc[:, -1]\n",
        "\n",
        "# Display X (independent variables)\n",
        "print(X)\n",
        "\n",
        "# Display y (dependent variable)\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "Ea0PU0oHUYCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# X → features, y → target labels\n",
        "# test_size = 0.20 → 20% data for testing, 80% for training\n",
        "# random_state = 1 → ensures the split is reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Show the shape (rows, columns) of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "ANGk9TvbVI2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- LOGISTIC REGRESSION MODEL TRAINING --------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a Logistic Regression classifier object\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# Train the classifier on training data (X_train features and y_train labels)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict target labels for the test dataset\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# Predict probabilities for each class (0 or 1) for the test set\n",
        "# Logistic Regression predicts probabilities and then assigns the class with higher probability\n",
        "# Default cutoff = 0.5 → if P(class=1) > 0.5, predicted label = 1\n",
        "classifier.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "zQs74wphVaF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → gives precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Notes on the classification report:\n",
        "# - First two rows (class 0 and 1) → precision, recall, f1-score, support for each class\n",
        "# - macro avg → simple average of metrics for all classes (ignores class imbalance)\n",
        "# - weighted avg → average weighted by number of samples in each class (important for imbalanced data)\n"
      ],
      "metadata": {
        "id": "dY9jQMNWV3G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- ROC CURVE & AUC --------------------\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class (class = 1)\n",
        "# predict_proba() returns two columns → [:,1] selects probability for class 1\n",
        "y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate False Positive Rate (FPR), True Positive Rate (TPR), and thresholds for ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "roc_auc\n"
      ],
      "metadata": {
        "id": "hOPZwbO4WYmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PLOT ROC-AUC CURVE --------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure of size 8x6 inches\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the ROC curve\n",
        "# fpr → x-axis (False Positive Rate)\n",
        "# tpr → y-axis (True Positive Rate)\n",
        "# color='darkorange', linewidth=2 → styling\n",
        "# label → shows AUC value in legend\n",
        "plt.plot(fpr, tpr, color='darkorange', linewidth=2,\n",
        "         label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "# Plot diagonal line representing random guessing (baseline)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--')\n",
        "\n",
        "# Set x-axis limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "\n",
        "# Set y-axis limits slightly above 1 to give space for plot\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('False Positive Rate')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "# Display legend at lower-right\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Render the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GajnuqLGWul1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CROSS VALIDATION USING K-FOLD --------------------\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a KFold object for splitting data into 5 folds\n",
        "# n_splits=5 → dataset is divided into 5 equal parts\n",
        "# shuffle=False → data is not shuffled before splitting (default)\n",
        "cv = KFold(n_splits=5)\n",
        "cv  # Display KFold object\n",
        "\n",
        "# Perform cross-validation using the classifier\n",
        "# classifier → trained Logistic Regression model\n",
        "# X_train, y_train → training features and labels\n",
        "# cv=cv → KFold splits\n",
        "# scoring=\"accuracy\" → evaluates accuracy on each fold\n",
        "scores = cross_val_score(classifier, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate mean accuracy across all folds\n",
        "np.mean(scores)\n"
      ],
      "metadata": {
        "id": "TaYR7OxvW93o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION 02"
      ],
      "metadata": {
        "id": "90OM3GJQX0mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- GENERATE SYNTHETIC DATASET --------------------\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic classification dataset\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_redundant=5 → 5 features are redundant (linear combination of informative)\n",
        "# n_informative=5 → 5 features actually useful for prediction\n",
        "# n_classes=2 → binary classification\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=2, random_state=1)\n",
        "\n",
        "# Display feature matrix\n",
        "X\n",
        "\n",
        "# Display target labels\n",
        "y\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "# Split synthetic dataset into training and testing sets\n",
        "# test_size=0.30 → 30% data for testing, 70% for training\n",
        "# random_state=1 → reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# -------------------- LOGISTIC REGRESSION MODEL --------------------\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model  # Display model object\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict target labels for test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred  # Display predictions\n"
      ],
      "metadata": {
        "id": "dxJeJ62-X49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → gives precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Notes on the classification report:\n",
        "# - First two rows (class 0 and 1) → precision, recall, f1-score, support for each class\n",
        "# - macro avg → simple average across classes (ignores class imbalance)\n",
        "# - weighted avg → average weighted by number of samples in each class (important for imbalanced data)\n"
      ],
      "metadata": {
        "id": "f9W2wCLRY5Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- ROC CURVE & AUC --------------------\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate False Positive Rate (FPR), True Positive Rate (TPR), and thresholds\n",
        "# y_test → true labels\n",
        "# y_pred_proba → predicted probabilities for the positive class (class 1)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# -------------------- PLOT ROC CURVE --------------------\n",
        "plt.figure(figsize=(8, 6))  # Set figure size\n",
        "\n",
        "# Plot ROC curve: TPR vs FPR\n",
        "# color='darkorange', linewidth=2 → styling\n",
        "# label → shows AUC value on the legend\n",
        "plt.plot(fpr, tpr, color='darkorange', linewidth=2,\n",
        "         label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "# Plot diagonal line representing random guessing\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "# Set axis limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Set axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "# Add legend at lower-right\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OMW3A_IOZV7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#precision recall accuracy tradeoff to decide optimal thrshold\n",
        "#by default sklean 0.5 uses as threshold"
      ],
      "metadata": {
        "id": "jKy2aiI4ZkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PRECISION, RECALL & ACCURACY VS THRESHOLD --------------------\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define thresholds from 0 to 1 (100 points)\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "# Lists to store metric values for each threshold\n",
        "precisions = []\n",
        "recalls = []\n",
        "accuracies = []\n",
        "\n",
        "# Loop through each threshold\n",
        "for threshold in thresholds:\n",
        "    # Convert predicted probabilities to binary labels based on threshold\n",
        "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    # Calculate precision at this threshold\n",
        "    precision = precision_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Calculate recall at this threshold\n",
        "    recall = recall_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Calculate accuracy at this threshold\n",
        "    accuracy = accuracy_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Store values\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# -------------------- PLOT METRICS --------------------\n",
        "plt.figure(figsize=(10, 6))  # Set figure size\n",
        "\n",
        "# Plot Precision vs Threshold\n",
        "plt.plot(thresholds, precisions, label='Precision')\n",
        "\n",
        "# Plot Recall vs Threshold\n",
        "plt.plot(thresholds, recalls, label='Recall')\n",
        "\n",
        "# Plot Accuracy vs Threshold\n",
        "plt.plot(thresholds, accuracies, label='Accuracy')\n",
        "\n",
        "# Set axis labels and title\n",
        "plt.xlabel('Threshold Probability')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision, Recall, and Accuracy vs. Threshold Probability')\n",
        "\n",
        "# Add legend and grid\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z-fWJzpYZnuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#observation>> cutoff =0.4\n"
      ],
      "metadata": {
        "id": "v6uvZUMJZz5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CUSTOM THRESHOLD PREDICTIONS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Convert predicted probabilities to binary labels using threshold = 0.4\n",
        "# If probability > 0.4 → classify as 1, else 0\n",
        "new_pred_levels = np.where(y_pred_proba > 0.4, 1, 0)\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, new_pred_levels))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, new_pred_levels))\n",
        "\n",
        "# Classification report → precision, recall, f1-score, support for each class\n",
        "print(classification_report(y_test, new_pred_levels))\n"
      ],
      "metadata": {
        "id": "c9EtXKAoZ3vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- K-FOLD CROSS VALIDATION --------------------\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a K-Fold cross-validator\n",
        "# n_splits=5 → split the data into 5 folds\n",
        "# Each fold will be used once as a validation set while the remaining 4 folds form the training set\n",
        "cv = KFold(n_splits=5)\n",
        "\n",
        "# Perform cross-validation\n",
        "# cross_val_score → evaluates model performance for each fold\n",
        "# model → Logistic Regression model\n",
        "# X_train, y_train → training data\n",
        "# cv=cv → cross-validation strategy (here, 5-fold)\n",
        "acc = cross_val_score(model, X_train, y_train, cv=cv)\n",
        "\n",
        "# Display accuracy for each fold\n",
        "acc\n",
        "\n",
        "# Compute mean accuracy across all folds\n",
        "np.mean(acc)\n"
      ],
      "metadata": {
        "id": "fuIGqrFnaD-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION 03"
      ],
      "metadata": {
        "id": "xWRZmW2EafAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LIBRARIES --------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------- CREATE SYNTHETIC CLASSIFICATION DATA --------------------\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_informative=5 → 5 features are actually informative\n",
        "# n_redundant=5 → 5 features are linear combinations of informative features\n",
        "# n_classes=2 → binary classification\n",
        "# random_state=1 → reproducible dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=2, random_state=1)\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "# test_size=0.30 → 30% data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n"
      ],
      "metadata": {
        "id": "0Ige3GZLanGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "#GridSearchCV"
      ],
      "metadata": {
        "id": "ECGFKjaEbEkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT GRIDSEARCHCV --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- DEFINE HYPERPARAMETERS --------------------\n",
        "# 'penalty' → type of regularization (l1, l2, elasticnet)\n",
        "# 'C' → inverse of regularization strength (higher C = less regularization)\n",
        "params = {'penalty': ('l1', 'l2', 'elasticnet'), 'C': [1, 2, 10, 20, 30, 40]}\n",
        "\n",
        "# Create a base Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# -------------------- GRID SEARCH --------------------\n",
        "# GridSearchCV → searches for best hyperparameter combination\n",
        "# cv=5 → 5-fold cross-validation\n",
        "clf = GridSearchCV(classifier, param_grid=params, cv=5)\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the best combination of hyperparameters\n",
        "clf.best_params_\n",
        "\n",
        "# Get the best cross-validated score\n",
        "clf.best_score_\n",
        "\n",
        "# -------------------- FINAL MODEL WITH BEST PARAMETERS --------------------\n",
        "# Create Logistic Regression model with best parameters from grid search\n",
        "model = LogisticRegression(C=1, penalty='l2')\n",
        "\n",
        "# Fit model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict class labels on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Predict probabilities for each class (0 and 1)\n",
        "model.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "HuL46Of7bHWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# -------------------- CONFUSION MATRIX --------------------\n",
        "# Compare actual labels (y_test) vs predicted labels (y_pred)\n",
        "# Returns a 2x2 matrix for binary classification:\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------- ACCURACY SCORE --------------------\n",
        "# Fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------- CLASSIFICATION REPORT --------------------\n",
        "# Gives precision, recall, f1-score, and support for each class\n",
        "# precision → fraction of predicted positives that are correct\n",
        "# recall → fraction of actual positives correctly predicted\n",
        "# f1-score → harmonic mean of precision & recall\n",
        "# support → number of actual occurrences of the class in dataset\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "p5Gl89ozbytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#randomized search cv, it will take randomly some combination"
      ],
      "metadata": {
        "id": "NYTD88O1cFcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT RANDOMIZEDSEARCHCV --------------------\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- RANDOMIZED SEARCH SETUP --------------------\n",
        "# RandomizedSearchCV → searches for best hyperparameters by sampling a given number of combinations randomly\n",
        "# param_distributions = params → grid of hyperparameters to sample from\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# n_iter=10 → number of parameter settings sampled\n",
        "randomized_clf = RandomizedSearchCV(classifier, param_distributions=params, cv=5, n_iter=10)\n",
        "\n",
        "# Fit RandomizedSearchCV on training data\n",
        "randomized_clf.fit(X_train, y_train)\n",
        "\n",
        "# Best cross-validated score from random search\n",
        "randomized_clf.best_score_\n",
        "\n",
        "# Best hyperparameters from random search\n",
        "randomized_clf.best_params_\n",
        "\n",
        "# -------------------- FINAL MODEL WITH BEST PARAMETERS --------------------\n",
        "# Use optimal parameters (example: C=10, penalty='l2') from RandomizedSearchCV\n",
        "model = LogisticRegression(C=10, penalty='l2')\n",
        "\n",
        "# Fit final model on training data\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "fjzxcg7bcGb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULTICLASS CLASSIFICATION"
      ],
      "metadata": {
        "id": "EuCKTc7RclJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LIBRARIES --------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- CREATE SYNTHETIC MULTI-CLASS DATA --------------------\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_informative=5 → 5 features actually informative\n",
        "# n_redundant=5 → 5 features are linear combinations of informative features\n",
        "# n_classes=3 → 3 classes (multi-class classification)\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=3, random_state=1)\n",
        "\n",
        "# Display target vector\n",
        "y\n",
        "\n",
        "# Display feature matrix\n",
        "X\n"
      ],
      "metadata": {
        "id": "lbB_-Gk3csxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CREATE OVR LOGISTIC REGRESSION MODEL --------------------\n",
        "# multi_class='ovr' → One-vs-Rest strategy (fits one classifier per class)\n",
        "# solver='lbfgs' → optimization algorithm used for fitting the model\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs')\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training (70%) and testing (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shapes of training and testing sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the OvR Logistic Regression model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Display predicted class labels\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "qgc1IhvEdl6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "fJGMJxEEeDMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g_5cRYWGeEOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# -------------------- CREATE MULTINOMIAL LOGISTIC REGRESSION MODEL --------------------\n",
        "# multi_class='multinomial' → directly models multiple classes simultaneously\n",
        "# solver='lbfgs' → optimization algorithm that supports multinomial logistic regression\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Display model\n",
        "model\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train multinomial logistic regression on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels for test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of correct/incorrect predictions for each class\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy → fraction of correct predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → precision, recall, f1-score, support for each class\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "GCBlfDs7eH-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#roc auc is only for binary classification problem"
      ],
      "metadata": {
        "id": "R6MVF9zoeOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULTICLASS CLASSIFICATION WITH IRIS IMPLEMENTATION"
      ],
      "metadata": {
        "id": "0JV1lgSMecAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset from sklearn\n",
        "data = load_iris()\n",
        "\n",
        "# Check available keys in the dataset dictionary\n",
        "data.keys()\n",
        "\n",
        "# Print dataset description\n",
        "print(data.DESCR)\n",
        "\n",
        "# Feature matrix (4 columns: sepal length, sepal width, petal length, petal width)\n",
        "data.data\n",
        "\n",
        "# Target vector (species encoded as 0, 1, 2)\n",
        "data.target\n",
        "\n",
        "# Feature names\n",
        "data.feature_names\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame with features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target column to the DataFrame\n",
        "df['target'] = data.target\n",
        "\n",
        "# Display entire DataFrame\n",
        "df\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head()\n",
        "\n",
        "# Show last 5 rows\n",
        "df.tail()\n",
        "\n",
        "# Show 2 random rows\n",
        "df.sample(2)\n",
        "\n",
        "# Check unique classes in target\n",
        "df.target.unique()\n"
      ],
      "metadata": {
        "id": "s14OmAz_er5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for binary classification\n",
        "# df_final =  df[df['target'] != 2]"
      ],
      "metadata": {
        "id": "DazUS9zdfefn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CHECK UNIQUE TARGET CLASSES --------------------\n",
        "df.target.unique()  # Returns [0, 1, 2] → 3 classes in Iris dataset\n",
        "\n",
        "# -------------------- SEPARATE FEATURES AND TARGET --------------------\n",
        "X = df.iloc[:, :-1]  # All columns except last → features\n",
        "y = df.iloc[:, -1]   # Last column → target\n",
        "\n",
        "# Display features\n",
        "X\n",
        "\n",
        "# Display target\n",
        "y\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset: 80% training, 20% testing, random_state=1 ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Check shapes of training and testing sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "DjyL0XiWfhDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LOGISTIC REGRESSION --------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create Logistic Regression classifier\n",
        "# max_iter=300 → maximum number of iterations for solver to converge\n",
        "classifier = LogisticRegression(max_iter=300)\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the model using training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels on test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Display predicted class labels\n",
        "y_pred\n",
        "\n",
        "# -------------------- PREDICT PROBABILITIES --------------------\n",
        "# Predict probabilities for each class for the test set\n",
        "# Output shape → (n_samples, n_classes)\n",
        "classifier.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "8Op-2npyf98-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# -------------------- CONFUSION MATRIX --------------------\n",
        "# Shows number of correct and incorrect predictions for each class\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------- ACCURACY --------------------\n",
        "# Fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------- CLASSIFICATION REPORT --------------------\n",
        "# Includes precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "NV6mL_GKgcSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DECISION TREE CLASSIFICATION"
      ],
      "metadata": {
        "id": "-7V_FPgyh4rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Print full description of dataset\n",
        "# This includes information about features, target, and classes\n",
        "print(data.DESCR)\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame from feature data\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df  # Display all rows of feature data\n",
        "\n",
        "# -------------------- TARGET VECTOR --------------------\n",
        "# Access target (species labels: 0, 1, 2)\n",
        "data.target\n",
        "\n",
        "# -------------------- SEPARATE FEATURES AND TARGET --------------------\n",
        "X = df          # Feature matrix\n",
        "y = data.target # Target vector\n",
        "\n",
        "# Display features and target\n",
        "X\n",
        "y\n"
      ],
      "metadata": {
        "id": "LDdrShuPh6RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "# test_size=0.3 → 30% of data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# -------------------- DECISION TREE CLASSIFIER --------------------\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create Decision Tree classifier using 'entropy' as criterion (information gain)\n",
        "classifier = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the Decision Tree on the training set\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "CsyTiBQBiwsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TREE PLOTTING --------------------\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------- PLOT ORIGINAL TREE --------------------\n",
        "plt.figure(figsize=(12, 10))  # Set figure size\n",
        "# Visualize the trained decision tree\n",
        "tree.plot_tree(classifier, filled=True)\n",
        "\n",
        "# -------------------- POST-PRUNING --------------------\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Restrict tree growth using max_depth (post-pruning)\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "\n",
        "# Fit pruned tree to training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Plot pruned tree\n",
        "plt.figure(figsize=(12, 10))\n",
        "tree.plot_tree(classifier, filled=True)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict on test set using pruned tree\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Calculate accuracy\n",
        "score = accuracy_score(y_pred, y_test)\n",
        "print(score)\n",
        "\n",
        "# Generate detailed classification metrics\n",
        "print(classification_report(y_pred, y_test))\n",
        "\n",
        "# -------------------- PRE-PRUNING HYPERPARAMETER SETUP --------------------\n",
        "# Parameters for GridSearchCV / hyperparameter tuning\n",
        "parameter = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],  # Split criteria\n",
        "    'splitter': ['best', 'random'],                # Node splitting strategy\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6],              # Max tree depth\n",
        "    'max_features': ['sqrt', 'log2', 'auto']      # Number of features to consider at split\n",
        "}\n"
      ],
      "metadata": {
        "id": "U6bemrumjGXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT GRID SEARCH --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# -------------------- CREATE DECISION TREE --------------------\n",
        "clf = DecisionTreeClassifier()  # Basic Decision Tree classifier without hyperparameters\n",
        "\n",
        "# -------------------- GRID SEARCH SETUP --------------------\n",
        "# GridSearchCV will try all combinations of hyperparameters in `parameter`\n",
        "# cv=5 → 5-fold cross-validation to evaluate each combination\n",
        "# scoring='accuracy' → metric used to choose best hyperparameters\n",
        "model = GridSearchCV(clf, param_grid=parameter, cv=5, scoring='accuracy')\n",
        "\n",
        "# -------------------- FIT GRID SEARCH --------------------\n",
        "# Finds the best hyperparameter combination using training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- BEST PARAMETERS AND SCORE --------------------\n",
        "# Best combination of hyperparameters found\n",
        "model.best_params_\n",
        "\n",
        "# Best cross-validated accuracy score achieved\n",
        "model.best_score_\n"
      ],
      "metadata": {
        "id": "zrHQYjE_jvla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DECISION TREE REGRESSOR"
      ],
      "metadata": {
        "id": "o2fCipgWkPLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT DATASET --------------------\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# -------------------- LOAD DATASET --------------------\n",
        "data = fetch_california_housing()  # Fetch California housing dataset from sklearn\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "# Convert dataset into a pandas DataFrame for easier handling\n",
        "# data.data → features\n",
        "# data.feature_names → column names for features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target variable (Price) as a new column\n",
        "df['Price'] = data.target\n",
        "\n",
        "# Display DataFrame\n",
        "df\n",
        "\n",
        "# Check shape of DataFrame (rows, columns)\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "8AU_eq6akZtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- SAMPLE DATA --------------------\n",
        "# Take 20% of the dataset randomly for faster processing\n",
        "df = df.sample(frac=0.20)\n",
        "\n",
        "# Check new shape after sampling\n",
        "df.shape\n",
        "\n",
        "# Display sampled DataFrame\n",
        "df\n",
        "\n",
        "# -------------------- SPLIT INDEPENDENT AND DEPENDENT VARIABLES --------------------\n",
        "# X → all columns except last (features)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "# y → last column (target)\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Display feature set\n",
        "X\n",
        "\n",
        "# Display target variable\n",
        "y\n"
      ],
      "metadata": {
        "id": "BUDW1AQblEYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------- SPLIT DATA --------------------\n",
        "# Split dataset into training and testing sets\n",
        "# test_size=0.2 → 20% data for testing, 80% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# -------------------- IMPORT DECISION TREE REGRESSOR --------------------\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# -------------------- CREATE MODEL --------------------\n",
        "model = DecisionTreeRegressor()  # Basic Decision Tree Regressor\n",
        "\n",
        "# Display model info\n",
        "model\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "model.fit(X_train, y_train)  # Train model on training data\n",
        "\n",
        "# -------------------- PREDICT ON TEST DATA --------------------\n",
        "y_pred = model.predict(X_test)  # Predict target values for test features\n",
        "\n",
        "# Display predictions\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "Jtm0wEPelcuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT R2 SCORE --------------------\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Evaluate model performance using R-squared\n",
        "# Note: y_test should be first argument, y_pred second, but here swapped\n",
        "r2_score(y_pred, y_test)\n",
        "\n",
        "# -------------------- HYPERPARAMETER TUNING --------------------\n",
        "# Define a parameter grid for GridSearchCV to find best hyperparameters\n",
        "parameter = {\n",
        "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],  # split quality measure\n",
        "    'splitter': ['best', 'random'],  # strategy to choose split at each node\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6],  # maximum depth of tree to avoid overfitting\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # max features considered for each split\n",
        "}\n",
        "\n",
        "# Create a DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor()\n",
        "\n",
        "# -------------------- GRID SEARCH CROSS VALIDATION --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# GridSearchCV automatically tests all combinations of parameters and selects the best one\n",
        "# cv=3 → 3-fold cross-validation\n",
        "# scoring='neg_mean_squared_error' → evaluate using negative MSE\n",
        "model = GridSearchCV(regressor, param_grid=parameter, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Display best parameters found\n",
        "model.best_params_\n",
        "\n",
        "# -------------------- CREATE FINAL MODEL --------------------\n",
        "# Use the best parameters found from GridSearchCV\n",
        "final_model = DecisionTreeRegressor(\n",
        "    criterion='poisson',\n",
        "    max_depth=6,\n",
        "    max_features='auto',\n",
        "    splitter='best'\n",
        ")\n",
        "\n",
        "# Train the final model on the full training set\n",
        "final_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "dBlDPOkvl6v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TREE MODULE --------------------\n",
        "from sklearn import tree\n",
        "\n",
        "# -------------------- CREATE PLOT --------------------\n",
        "plt.figure(figsize=(12, 10))  # Set figure size for better readability\n",
        "\n",
        "# Plot the trained decision tree (final_model)\n",
        "# filled=True → nodes are colored according to the predicted value\n",
        "tree.plot_tree(final_model, filled=True)\n"
      ],
      "metadata": {
        "id": "eaVYNIXgnBll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PREDICTION --------------------\n",
        "# Use the trained model to predict target values for test features\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "# Calculate R-squared to see how well predictions match actual test values\n",
        "# Higher R2 (closer to 1) means better model fit\n",
        "r2_score(y_pred, y_test)\n"
      ],
      "metadata": {
        "id": "mwcQYAbinoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUPPORT VECTOR CLASSIFIER"
      ],
      "metadata": {
        "id": "EvMMu1NvpKrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT FUNCTION --------------------\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# -------------------- GENERATE SYNTHETIC DATA --------------------\n",
        "# n_samples=1000 → 1000 rows (data points)\n",
        "# n_features=2 → 2 features (columns)\n",
        "# n_classes=2 → binary classification (0 or 1)\n",
        "# n_clusters_per_class=2 → each class has 2 clusters\n",
        "# n_redundant=0 → no redundant features (all features are informative)\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=2,\n",
        "    n_classes=2,\n",
        "    n_clusters_per_class=2,\n",
        "    n_redundant=0\n",
        ")\n",
        "\n",
        "# X → feature matrix (1000 rows × 2 columns)\n",
        "# y → target vector (1000 labels, 0 or 1)\n",
        "\n",
        "# -------------------- EXAMINE FEATURES --------------------\n",
        "pd.DataFrame(X)       # Convert X to DataFrame to inspect all feature values\n",
        "pd.DataFrame(X)[0]    # Access the first feature (column 0)\n",
        "pd.DataFrame(X)[1]    # Access the second feature (column 1)\n",
        "\n",
        "# -------------------- EXAMINE TARGET --------------------\n",
        "y                     # Display the class labels\n"
      ],
      "metadata": {
        "id": "eTua22BwpTpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a scatter plot using seaborn\n",
        "sns.scatterplot(\n",
        "    x = pd.DataFrame(X)[0],  # X-axis values: first feature (column 0) of dataset X\n",
        "    y = pd.DataFrame(X)[1],  # Y-axis values: second feature (column 1) of dataset X\n",
        "    hue = y                  # Color points according to class labels in y\n",
        ")\n"
      ],
      "metadata": {
        "id": "QOPG1M5RqVwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import function to split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "# X → features, y → target labels\n",
        "# test_size=0.30 → 30% of data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducible splits every time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shape of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "WCqlYNnVUS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SVC (Support Vector Classifier) from sklearn\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize SVM classifier with linear kernel\n",
        "classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train the SVM classifier on training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get the coefficients (weights) of the linear hyperplane\n",
        "classifier.coef_\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred  # Display predicted labels\n"
      ],
      "metadata": {
        "id": "jizFpgERUgkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import evaluation metrics for classification\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Print detailed precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix (true vs predicted labels)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Print overall accuracy of the model\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "VW-cvywxU1Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV for hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid for SVC\n",
        "params = {\n",
        "    'C': [0.1, 0.2, 1, 2, 3, 10, 50, 100],   # Regularization parameter\n",
        "    'gamma': [1, 0.1, 0.2, 0.001, 0.003],    # Kernel coefficient\n",
        "    'kernel': ['linear']                     # Kernel type\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with SVC, 5-fold CV, and verbose for progress\n",
        "grid = GridSearchCV(SVC(), param_grid=params, cv=5, verbose=3)\n",
        "\n",
        "# Fit GridSearchCV to training data (performs exhaustive search over parameter grid)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters found\n",
        "grid.best_params_\n",
        "\n",
        "# Best cross-validated accuracy score achieved with the best hyperparameters\n",
        "grid.best_score_\n",
        "\n",
        "# Predict on test data using the best model found by GridSearchCV\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Import metrics for evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Print precision, recall, f1-score per class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print overall accuracy\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "9n8qE-dbVCHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUPPORT VECTOR REGRESSOR"
      ],
      "metadata": {
        "id": "V2AOK2JuWa3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import make_regression\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate synthetic regression dataset\n",
        "# n_samples=1000 → 1000 rows of data\n",
        "# n_features=2 → 2 independent variables/features\n",
        "# n_targets=1 → 1 dependent variable/target\n",
        "# noise=3.0 → add Gaussian noise to make the data more realistic\n",
        "X, y = make_regression(n_samples=1000, n_features=2, n_targets=1, noise=3.0)\n",
        "\n",
        "# X → feature values, y → target values\n",
        "X\n",
        "y\n",
        "\n",
        "# Plot a scatter plot using seaborn\n",
        "# x-axis → first feature (X[:,0])\n",
        "# y-axis → second feature (X[:,1])\n",
        "# hue → color points according to target value y\n",
        "sns.scatterplot(x=pd.DataFrame(X)[0], y=pd.DataFrame(X)[1], hue=y)\n"
      ],
      "metadata": {
        "id": "Q-4ud68vWyx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import function to split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset\n",
        "# test_size=0.3 → 30% data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shape of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Import Support Vector Regressor (SVR)\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialize SVR model with linear kernel\n",
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Train SVR model on training data\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve coefficients of the linear SVR model (weights for each feature)\n",
        "svr.coef_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svr.predict(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "st9sQJGPXMzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import R² metric\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Evaluate performance of the SVR model\n",
        "# R² (coefficient of determination) measures how well predictions match actual values\n",
        "r2_score(y_test, y_pred)\n",
        "\n",
        "# Hyperparameter tuning for SVR using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define grid of hyperparameters to search\n",
        "params = {\n",
        "    'C': [0.1, 0.2, 1, 2, 3, 10, 50, 100],  # Regularization parameter\n",
        "    'gamma': [1, 0.1, 0.2, 0.001, 0.003],   # Kernel coefficient (not used in linear kernel but included)\n",
        "    'kernel': ['linear'],                   # Using linear kernel for SVR\n",
        "    'epsilon': [0.01, 0.1, 0.2, 0.3]       # Epsilon-tube within which no penalty is given to errors\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV to find the best hyperparameters\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → print progress\n",
        "grid = GridSearchCV(SVR(), param_grid=params, cv=5, verbose=3)\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best combination of hyperparameters found\n",
        "grid.best_params_\n",
        "\n",
        "# Best cross-validated score achieved during grid search\n",
        "grid.best_score_\n",
        "\n",
        "# Make predictions on test data using best SVR model\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Evaluate performance of tuned SVR using R² score\n",
        "r2_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "jetNDj7LXoJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Kernal"
      ],
      "metadata": {
        "id": "HRuqGvSsYUjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create first circle points (radius 10)\n",
        "x = np.linspace(-6.0, 6.0, 100)          # 100 points evenly spaced between -6 and 6\n",
        "y = np.sqrt(10**2 - x**2)                 # Positive half of the circle equation: y = sqrt(r^2 - x^2)\n",
        "y = np.hstack([y, -y])                    # Add negative half to complete the circle\n",
        "x = np.hstack([x, -x])                    # Duplicate x for negative half\n",
        "\n",
        "# Create second circle points (radius 4)\n",
        "x1 = np.linspace(-6.0, 6.0, 100)\n",
        "y1 = np.sqrt(4**2 - x1**2)                # Smaller circle\n",
        "y1 = np.hstack([y1, -y1])\n",
        "x1 = np.hstack([x1, -x1])\n",
        "\n",
        "# Plot both circles\n",
        "plt.scatter(y, x, label='Circle radius 10')  # First circle\n",
        "plt.scatter(y1, x1, label='Circle radius 4') # Second circle\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create DataFrame for first circle and assign class 0\n",
        "df1 = pd.DataFrame(np.vstack([y, x]).T, columns=['X1', 'X2'])\n",
        "df1['Y'] = 0\n",
        "\n",
        "# Create DataFrame for second circle and assign class 1\n",
        "df2 = pd.DataFrame(np.vstack([y1, x1]).T, columns=['X1', 'X2'])\n",
        "df2['Y'] = 1\n",
        "\n",
        "# Combine both datasets into one\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_Ez2Th5uYYLM",
        "outputId": "631d67fa-0b98-4e2a-b056-9fa0cbc3e513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-261024985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the original dataframe and clean it\n",
        "df1 = df.copy()                    # Copy dataset to avoid modifying original\n",
        "df1 = df1.dropna()                 # Drop any missing values (if present)\n",
        "\n",
        "# Create new features for non-linear transformation\n",
        "df1[\"x1square\"] = df1[\"X1\"]**2    # X1 squared\n",
        "df1[\"x2square\"] = df1[\"X2\"]**2    # X2 squared\n",
        "df1[\"x1x2\"] = df1[\"X1\"]*df1[\"X2\"] # Interaction term X1*X2\n",
        "\n",
        "df1.head()                         # Display first 5 rows with new features\n",
        "\n",
        "# Define features (X) and target (y) for modeling\n",
        "X = df1[[\"x1square\", \"x2square\", \"x1x2\"]]  # Only the new non-linear features\n",
        "y = df1['Y']                                # Target label\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "X_train.head()  # Show first few rows of training features\n",
        "\n",
        "# Optional: visualize the transformed features in 3D\n",
        "import plotly.express as px\n",
        "fig = px.scatter_3d(df1, x=\"x1square\", y=\"x2square\", z=\"x1x2\", color=\"Y\")  # Color by class\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "gzSfobZIY6wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "mnX71v0AZW46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the iris dataset and train-test split function\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset directly as features (X) and target (y)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Display features and target\n",
        "X   # Features matrix: 150 samples × 4 features (sepal length, sepal width, petal length, petal width)\n",
        "y   # Target vector: species labels (0, 1, 2) for setosa, versicolor, virginica\n"
      ],
      "metadata": {
        "id": "5Deix_UpZg0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "# 30% of data is reserved for testing, 70% for training\n",
        "# random_state=1 ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Display training and testing feature sets\n",
        "X_train   # 70% of rows used for training\n",
        "X_test    # 30% of rows used for testing\n",
        "\n",
        "# Import Gaussian Naive Bayes classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Create a GaussianNB classifier instance\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target labels for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "SuqseLUzaRjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble Custom bagging classfier"
      ],
      "metadata": {
        "id": "mzhBszTZbiRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary functions\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic classification dataset\n",
        "# n_samples=1000 → 1000 rows\n",
        "# n_features=20 → 20 independent variables\n",
        "# n_classes=2 → binary classification (0 or 1)\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# 20% of data for testing, 80% for training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Show shapes of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display first few rows of training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "nlJPeHBCbpqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import classifiers\n",
        "from sklearn.naive_bayes import GaussianNB          # Naive Bayes for probabilistic classification\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression for linear classification\n",
        "from sklearn.tree import DecisionTreeClassifier      # Decision Tree classifier\n",
        "from sklearn.svm import SVC                          # Support Vector Classifier\n",
        "\n",
        "# Initialize the classifiers\n",
        "nb_clf = GaussianNB()                # Gaussian Naive Bayes classifier\n",
        "lr_clf = LogisticRegression()        # Logistic Regression classifier\n",
        "dt_clf = DecisionTreeClassifier()    # Decision Tree classifier\n",
        "svm_clf = SVC(kernel=\"linear\")       # Linear SVM classifier\n"
      ],
      "metadata": {
        "id": "mpqRDEs1b6ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import VotingClassifier for ensemble learning\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create an ensemble classifier using hard voting\n",
        "# estimators = list of (name, classifier) tuples\n",
        "# voting = 'hard' → majority class prediction (class label predicted by most classifiers)\n",
        "ensemble_clf = VotingClassifier(\n",
        "    estimators=[('decision_tree', dt_clf),\n",
        "                ('naive_bayes', nb_clf),\n",
        "                ('log_reg', lr_clf),\n",
        "                ('svm', svm_clf)],\n",
        "    voting=\"hard\"\n",
        ")\n",
        "\n",
        "# Display ensemble classifier details\n",
        "ensemble_clf\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict class labels for the test set\n",
        "y_pred = ensemble_clf.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# Evaluate accuracy of the ensemble model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "EshCFbKCcHk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Custom Bagging Regressor"
      ],
      "metadata": {
        "id": "IJdNOXT5clCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic regression dataset\n",
        "# n_samples = 1000 → number of rows\n",
        "# n_features = 10 → number of independent variables\n",
        "# noise = 0.1 → standard deviation of Gaussian noise added to target\n",
        "# random_state = 42 → ensures reproducible results\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size = 0.2 → 20% for testing, 80% for training\n",
        "# random_state = 1 → ensures same split every time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Show shapes of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "7foG4DcmcwlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import regression models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Create individual regressors\n",
        "lr = LinearRegression()               # Linear Regression\n",
        "dtr = DecisionTreeRegressor()         # Decision Tree Regressor\n",
        "svr = SVR(kernel=\"linear\")            # Support Vector Regressor with linear kernel\n",
        "\n",
        "# Import VotingRegressor for ensemble\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "# Create ensemble regressor using the three models\n",
        "# estimators → list of tuples ('name', model)\n",
        "ensemble_regressor = VotingRegressor(estimators=[('mlr', lr), (\"dtr\", dtr), (\"svr\", svr)])\n",
        "\n",
        "# Check the ensemble regressor object\n",
        "ensemble_regressor\n",
        "\n",
        "# Fit the ensemble model on training data\n",
        "ensemble_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Display fitted ensemble regressor\n",
        "ensemble_regressor\n"
      ],
      "metadata": {
        "id": "LiDUuyq_de0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple models with Pipeline and ColumnTransformer"
      ],
      "metadata": {
        "id": "vqNAjP8zd89i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'tips' dataset from seaborn\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()  # Display first 5 rows\n",
        "\n",
        "# Target variable: 'time' (lunch or dinner)\n",
        "df.time.unique()  # Check unique categories in 'time'\n",
        "\n",
        "# EDA (Exploratory Data Analysis) can be subjective\n",
        "# Encoding, missing value treatment, and scaling are automated next\n",
        "\n",
        "df.info()  # Check data types and missing values\n",
        "\n",
        "# Since 'time' is a nominal categorical variable, use Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Transform 'time' column: lunch → 0, dinner → 1\n",
        "df['time'] = encoder.fit_transform(df['time'])\n",
        "df\n",
        "df.time.unique()  # Verify encoding: dinner=1, lunch=0\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('time', axis=1)  # Features (all columns except 'time')\n",
        "y = df['time']               # Target variable (time)\n",
        "X\n",
        "y\n"
      ],
      "metadata": {
        "id": "kTdBGJqieumh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "# X_train → 80% of features for training\n",
        "# X_test → 20% of features for testing\n",
        "# y_train → target for training\n",
        "# y_test → target for testing\n",
        "X_train.head()  # Display first 5 rows of training features\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "df.isna().sum()  # Returns count of NaNs for each column\n",
        "\n",
        "# Import necessary preprocessing tools\n",
        "from sklearn.impute import SimpleImputer  # Handles missing values\n",
        "from sklearn.preprocessing import OneHotEncoder  # Encodes categorical columns\n",
        "from sklearn.preprocessing import StandardScaler  # Scales numerical columns\n",
        "\n",
        "# Import tools to create pipelines\n",
        "from sklearn.pipeline import Pipeline  # Chains multiple transformations\n",
        "from sklearn.compose import ColumnTransformer  # Applies transformers to specific columns\n",
        "\n",
        "# Define which columns are categorical and numerical\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\"]  # Categorical features\n",
        "num_cols = [\"total_bill\", \"tip\", \"size\"]  # Numerical features\n"
      ],
      "metadata": {
        "id": "lNOe7xiyfXvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature engineering automation using pipeline and columntransformer\n",
        "\n",
        "# 1️⃣ Numerical pipeline\n",
        "# Steps:\n",
        "# - Imputation → Fill missing values with median\n",
        "# - Scaling → Standardize numerical features\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"median\")),\n",
        "    ('scaling', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2️⃣ Categorical pipeline\n",
        "# Steps:\n",
        "# - Imputation → Fill missing values with most frequent category\n",
        "# - Encoding → Convert categorical values to numeric using one-hot encoding\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"most_frequent\")),\n",
        "    ('encoding', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# 3️⃣ ColumnTransformer\n",
        "# Applies appropriate pipeline to respective columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num_pipeline\", num_pipeline, num_cols),\n",
        "    (\"cat_pipeline\", cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# 4️⃣ Fit on training data and transform\n",
        "X_train = preprocessor.fit_transform(X_train)  # Fit + transform on training data\n",
        "X_test = preprocessor.transform(X_test)        # Only transform on test data\n",
        "\n",
        "X_train  # Transformed training data\n",
        "X_test   # Transformed testing data"
      ],
      "metadata": {
        "id": "_u8VCb3egCnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training and Evaluating Models\n",
        "# ===============================\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Define models\n",
        "models = {\n",
        "    \"support vector classifier\": SVC(),\n",
        "    \"DT classifier\": DecisionTreeClassifier(),\n",
        "    \"logistic regression\": LogisticRegression()\n",
        "}\n",
        "\n",
        "# 2️⃣ Function to train and evaluate models\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    evaluation = {}  # Dictionary to store model name & accuracy\n",
        "    for i in range(len(models)):\n",
        "        model = list(models.values())[i]  # Get model instance\n",
        "        model.fit(X_train, y_train)        # Train the model\n",
        "        y_pred = model.predict(X_test)     # Predict on test set\n",
        "        model_score = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
        "        evaluation[list(models.keys())[i]] = model_score  # Save score\n",
        "    return evaluation\n",
        "\n",
        "# 3️⃣ Train all models and get evaluation scores\n",
        "model_train_eval(X_train, y_train, X_test, y_test, models)\n"
      ],
      "metadata": {
        "id": "4aFeqA_Agx3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOB SCORE"
      ],
      "metadata": {
        "id": "RDRCMSKThg7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Random Forest Classifier with OOB\n",
        "# ====================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# 1️⃣ Create a synthetic dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,     # 1000 samples\n",
        "    n_features=20,      # 20 features\n",
        "    n_classes=2,        # Binary classification\n",
        "    random_state=42     # Reproducibility\n",
        ")\n",
        "\n",
        "# 2️⃣ Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=100,   # 100 trees in the forest\n",
        "    oob_score=True,     # Use Out-of-Bag samples to estimate generalization\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3️⃣ Train the model\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# 4️⃣ Extract Out-of-Bag score\n",
        "oob_score = rf_classifier.oob_score_\n",
        "print(\"Out-of-Bag Score:\", oob_score)\n"
      ],
      "metadata": {
        "id": "qfZ_dONrhkkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FORSEST CLASSIFIER"
      ],
      "metadata": {
        "id": "s_S1zGkhh0q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Loading dataset and basic info\n",
        "# ====================================\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# 1️⃣ Load the 'tips' dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()   # Show first 5 rows to inspect the data\n",
        "\n",
        "# 2️⃣ Check unique values in target column 'time'\n",
        "# 'time' indicates Lunch or Dinner\n",
        "df.time.unique()\n",
        "\n",
        "# 3️⃣ General info about the dataset\n",
        "# - Column names, types\n",
        "# - Number of non-null entries\n",
        "# - Memory usage\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "r2z_Ez5tiJ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Encoding the target variable\n",
        "# ====================================\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1️⃣ Initialize LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# 2️⃣ Fit & transform the 'time' column\n",
        "# - Converts categorical labels into numeric: Lunch→0, Dinner→1\n",
        "df['time'] = encoder.fit_transform(df['time'])\n",
        "df.head()   # Inspect transformed column\n",
        "\n",
        "# 3️⃣ Check unique values after encoding\n",
        "df.time.unique()  # Output: [0, 1] → 0: Lunch, 1: Dinner\n",
        "\n",
        "# 4️⃣ Separate features (X) and target (y)\n",
        "X = df.drop('time', axis=1)  # All columns except 'time'\n",
        "y = df['time']                # Target column\n",
        "X                      # Inspect features\n",
        "y                     # Inspect target\n"
      ],
      "metadata": {
        "id": "kflxMejaidfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Train-Test Split\n",
        "# ====================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1️⃣ Split the dataset into training and testing sets\n",
        "# - X → features, y → target\n",
        "# - test_size=0.20 → 20% data for testing, 80% for training\n",
        "# - random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# 2️⃣ Inspect first few rows of training features\n",
        "X_train.head()\n",
        "\n",
        "# 3️⃣ Check for missing values in the dataset\n",
        "df.isna().sum()  # Returns count of missing values per column\n"
      ],
      "metadata": {
        "id": "Geg3r_-gi7YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Handling Missing Values, Encoding & Scaling Setup\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Import necessary transformers\n",
        "from sklearn.impute import SimpleImputer          # Handles missing values\n",
        "from sklearn.preprocessing import OneHotEncoder   # Encodes categorical variables\n",
        "from sklearn.preprocessing import StandardScaler  # Scales numerical features\n",
        "\n",
        "# 2️⃣ Import pipeline tools\n",
        "from sklearn.pipeline import Pipeline             # Chains multiple transformations\n",
        "from sklearn.compose import ColumnTransformer    # Apply different pipelines to different columns\n",
        "\n",
        "# 3️⃣ Specify categorical and numerical columns\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\"]             # Categorical features to encode\n",
        "num_cols = [\"total_bill\", \"tip\", \"size\"]        # Numerical features to scale and impute if missing\n"
      ],
      "metadata": {
        "id": "k1RjqYxijKyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Feature Engineering Automation\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Numerical pipeline\n",
        "# Steps:\n",
        "# - imputation: fill missing numerical values with median\n",
        "# - scaling: standardize features (mean=0, std=1)\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"median\")),\n",
        "    ('scaling', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2️⃣ Categorical pipeline\n",
        "# Steps:\n",
        "# - imputation: fill missing categorical values with most frequent value\n",
        "# - encoding: convert categorical variables to numerical using one-hot encoding\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"most_frequent\")),\n",
        "    ('encoding', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# 3️⃣ ColumnTransformer: Apply pipelines to respective columns\n",
        "# - num_pipeline → numerical columns\n",
        "# - cat_pipeline → categorical columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num_pipeline\", num_pipeline, num_cols),\n",
        "    (\"cat_pipeline\", cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# 4️⃣ Transform training and testing data\n",
        "# fit_transform on training data, transform on test data\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# 5️⃣ Outputs: Preprocessed feature arrays ready for modeling\n",
        "X_train\n",
        "X_test\n"
      ],
      "metadata": {
        "id": "tARMou-djjCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ====================================\n",
        "# Model Training & Evaluation Function\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Import models\n",
        "# - DecisionTreeClassifier, SVC, LogisticRegression, RandomForestClassifier already imported\n",
        "\n",
        "# 2️⃣ Define dictionary of models\n",
        "# Key = model name (string), Value = model instance\n",
        "models = {\n",
        "    \"support vector classifier\": SVC(),\n",
        "    \"DT classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic regression\": LogisticRegression(),\n",
        "    \"Random_forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# 3️⃣ Function to train and evaluate models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    \"\"\"\n",
        "    Trains each model on X_train/y_train and evaluates on X_test/y_test.\n",
        "    Returns a dictionary with model names as keys and accuracy scores as values.\n",
        "    \"\"\"\n",
        "    evaluation = {}  # store model_name: accuracy\n",
        "    for i in range(len(models)):\n",
        "        model = list(models.values())[i]  # get model instance\n",
        "        model.fit(X_train, y_train)       # train model\n",
        "        y_pred = model.predict(X_test)    # predict on test set\n",
        "        model_score = accuracy_score(y_test, y_pred)  # calculate accuracy\n",
        "        evaluation[list(models.keys())[i]] = model_score  # store result\n",
        "    return evaluation\n",
        "\n",
        "# Example usage:\n",
        "# model_train_eval(X_train, y_train, X_test, y_test, models)\n",
        "model_train_eval(X_train, y_train, X_test, y_test, models)\n"
      ],
      "metadata": {
        "id": "R9pbiHEtkMpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Random Forest Classifier with Hyperparameter Tuning\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 1️⃣ Create Random Forest classifier instance\n",
        "rf = RandomForestClassifier()  # default params\n",
        "rf\n",
        "\n",
        "# 2️⃣ Define hyperparameter grid for tuning\n",
        "params = {\n",
        "    'max_depth': [1, 2, 3, 5, 10, None],   # Maximum depth of each tree\n",
        "    'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
        "    'criterion': ['gini', 'entropy']      # Function to measure quality of split\n",
        "}\n",
        "params  # just to visualize the param grid\n",
        "\n",
        "# 3️⃣ Create RandomizedSearchCV object\n",
        "clf = RandomizedSearchCV(\n",
        "    estimator=rf,            # model to tune\n",
        "    param_distributions=params,  # param grid\n",
        "    cv=5,                    # 5-fold cross-validation\n",
        "    verbose=3,               # print progress\n",
        "    scoring='accuracy'       # metric to evaluate\n",
        ")\n",
        "clf  # see the RandomizedSearchCV object\n",
        "\n",
        "# 4️⃣ Fit RandomizedSearchCV to training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5️⃣ Best parameters and score found\n",
        "clf.best_params_  # best hyperparameters\n",
        "clf.best_score_   # corresponding accuracy\n"
      ],
      "metadata": {
        "id": "yMGenfbOlF3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple models with Pipeline and ColumnTransformer"
      ],
      "metadata": {
        "id": "aoRqHlxZq69o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Prepare dataset for regression task\n",
        "# ==========================================\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()  # Show first 5 rows\n",
        "\n",
        "# 2️⃣ Target variable: 'total_bill' (predict total bill amount)\n",
        "# Features: everything else\n",
        "\n",
        "# 3️⃣ Check unique values for 'time' (categorical column)\n",
        "df.time.unique()  # lunch, dinner\n",
        "\n",
        "# 4️⃣ Basic EDA and data info\n",
        "# Here, subjective exploration: check dtypes, missing values, etc.\n",
        "df.info()\n",
        "\n",
        "# 5️⃣ Split features and target\n",
        "X = df.drop('total_bill', axis=1)  # independent features\n",
        "y = df['total_bill']               # dependent variable (target)\n",
        "\n",
        "X  # feature dataframe\n",
        "y  # target series\n"
      ],
      "metadata": {
        "id": "bUPPM1yRq80v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Train-Test Split & Missing Value Check\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1️⃣ Split dataset into training and testing sets\n",
        "# test_size=0.20 → 20% of data for testing, 80% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# 2️⃣ Preview first 5 rows of training features\n",
        "X_train.head()\n",
        "\n",
        "# 3️⃣ Check for missing values in each column\n",
        "df.isna().sum()\n"
      ],
      "metadata": {
        "id": "iv2QCGqjrT3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing value\n",
        "#data encoding\n",
        "#feature scaling\n",
        "\n",
        "from sklearn.impute import SimpleImputer #for missing vlaue\n",
        "from sklearn.preprocessing import OneHotEncoder #for encoding\n",
        "from sklearn.preprocessing import StandardScaler #for scaling\n",
        "\n",
        "from sklearn.pipeline import Pipeline #A sequence of data transformers\n",
        "from sklearn.compose import ColumnTransformer #Groups all the pipeline steps for each of the clumns\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\", \"time\"]\n",
        "num_cols = [\"tip\", \"size\"]\n",
        "\n",
        "#feature engineering automation using pipeline and columntransformer\n",
        "\n",
        "num_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"median\")),\n",
        "                                ('scaling', StandardScaler())])\n",
        "cat_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"most_frequent\")),\n",
        "                                ('encoding', OneHotEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_cols),\n",
        "                  (\"cat_pipeline\", cat_pipeline, cat_cols)])\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "X_train\n",
        "# X_test"
      ],
      "metadata": {
        "id": "OH3VsQgtrwS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Dictionary of regression models\n",
        "models = {\n",
        "    \"Support Vector Regressor\": SVR(),\n",
        "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor()\n",
        "}\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    evaluation = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)          # Train model\n",
        "        y_pred = model.predict(X_test)       # Predict on test set\n",
        "        model_score = r2_score(y_test, y_pred)  # Calculate R^2 score\n",
        "        evaluation[name] = model_score       # Store result\n",
        "    return evaluation\n",
        "\n",
        "# Call the function and get R^2 scores for all models\n",
        "evaluation_results = model_train_eval(X_train, y_train, X_test, y_test, models)\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "hZV-s5TjsIIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Initialize the Random Forest Regressor with OOB score enabled\n",
        "rfr = RandomForestRegressor(oob_score=True, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for RandomizedSearch\n",
        "params = {\n",
        "    'max_depth': [1, 50, 100, 150, 200],\n",
        "    'n_estimators': [50, 100, 200]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "reg = RandomizedSearchCV(\n",
        "    estimator=rfr,\n",
        "    param_distributions=params,\n",
        "    cv=5,\n",
        "    verbose=3,\n",
        "    scoring='r2',\n",
        "    n_iter=10,       # Number of parameter settings to try\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", reg.best_params_)\n",
        "\n",
        "# Best R2 score from cross-validation\n",
        "print(\"Best CV R2 Score:\", reg.best_score_)\n"
      ],
      "metadata": {
        "id": "qsIP1kBYsmRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoost classifier and regressor"
      ],
      "metadata": {
        "id": "6WDYuxPq7p8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adaboost classifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "frx0lHHY7uvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a synthetic dataset with 1000 samples, 20 features, and 2 classes\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=1)\n",
        "\n",
        "# Split dataset into training (67%) and testing (33%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Initialize AdaBoost Classifier\n",
        "classifier = AdaBoostClassifier()\n",
        "\n",
        "# Train the model on training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model performance\n",
        "print(\"Current model performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")   # Print accuracy score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))          # Print precision, recall, f1-score, and support\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))               # Print confusion matrix\n"
      ],
      "metadata": {
        "id": "tw0XT-oT8L-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the hyperparameter grid (dictionary of possible parameter values)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],      # Number of weak learners (decision stumps/trees) used in boosting\n",
        "    'learning_rate': [0.01, 0.1, 1.0, 1.5, 2.0],  # Step size / contribution of each weak learner\n",
        "    'algorithm': ['SAMME', 'SAMME.R']    # AdaBoost algorithm variations:\n",
        "                                         # 'SAMME' (discrete boosting),\n",
        "                                         # 'SAMME.R' (real boosting, usually faster & better)\n",
        "}\n",
        "\n",
        "# Create AdaBoost classifier object (base model, no parameters set yet)\n",
        "ada = AdaBoostClassifier()\n",
        "\n",
        "# Initialize GridSearchCV to find best hyperparameters\n",
        "# estimator = ada (our base model)\n",
        "# param_grid = parameters we want to test\n",
        "# cv = 5 (5-fold cross-validation will be used)\n",
        "# verbose = 3 (shows detailed training logs in console)\n",
        "# n_jobs = -1 (uses all CPU cores for parallel processing, speeds up training)\n",
        "clf = GridSearchCV(estimator=ada, param_grid=param_grid, cv=5, verbose=3, n_jobs=-1)\n",
        "\n",
        "# NOTE: If n_jobs = -1 → model runs faster, but you won’t see all fitting details printed.\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "# This will train multiple AdaBoost models using all parameter combinations\n",
        "# and choose the best based on cross-validation performance\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Show the best hyperparameters found after Grid Search\n",
        "clf.best_params_\n",
        "\n",
        "# Get the best AdaBoost model (with optimal parameters set automatically)\n",
        "best_model = clf.best_estimator_\n"
      ],
      "metadata": {
        "id": "xKlsxec18-Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best tuned AdaBoostClassifier model to make predictions on test set\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tuned)}\")   # Accuracy score (classification performance)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))           # Shows precision, recall, f1-score per class\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_tuned))                # Shows actual vs predicted values in matrix form\n",
        "\n",
        "\n",
        "# ---------------------------- AdaBoost Regressor Example ----------------------------\n",
        "\n",
        "# Importing necessary libraries\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Generate a synthetic regression dataset\n",
        "# n_samples=1000 → number of data points\n",
        "# n_features=2 → dataset will have 2 input features\n",
        "# noise=10 → adds randomness (to make it realistic)\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_regression(n_samples=1000, n_features=2, noise=10, random_state=1)\n",
        "\n",
        "# Split dataset into training and testing sets (67% train, 33% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Create AdaBoost Regressor object (default parameters)\n",
        "regressor = AdaBoostRegressor()\n",
        "\n",
        "# Fit (train) the AdaBoost regressor on training data\n",
        "regressor.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "8oSmavPP99tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained AdaBoost Regressor to make predictions on test data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# ---------------------- Model Evaluation (Before Tuning) ----------------------\n",
        "print(\"Current model performance:\")\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred)}\")                       # R² score → How well predictions approximate actual values (1 = perfect, 0 = poor)\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}\") # MAE → Average absolute difference between predicted and actual values\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")   # MSE → Average squared error, penalizes large errors more\n",
        "\n",
        "\n",
        "# ---------------------- Hyperparameter Tuning ----------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for AdaBoostRegressor\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],              # Number of weak learners (decision trees)\n",
        "    'learning_rate': [0.01, 0.1, 0.5, 1.0, 1.5], # How much each weak learner contributes\n",
        "    'loss': ['linear', 'square', 'exponential']  # Different loss functions for boosting\n",
        "}\n",
        "\n",
        "# GridSearchCV → performs exhaustive search over parameter grid using cross-validation\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → prints progress logs\n",
        "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5, verbose=3)\n",
        "\n",
        "# Train GridSearchCV on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters found by grid search\n",
        "grid_search.best_params_\n",
        "\n",
        "# Extract the best model (AdaBoostRegressor with tuned hyperparameters)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Use tuned model to make predictions\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "# ---------------------- Model Evaluation (After Tuning) ----------------------\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred_tuned)}\")                       # R² score for tuned model\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_tuned)}\") # MAE for tuned model\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_tuned)}\")   # MSE for tuned model\n"
      ],
      "metadata": {
        "id": "QrGj8kI--Zfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRADIENT BOOSTING CLASSIFIER"
      ],
      "metadata": {
        "id": "KMCo8IWi_It1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "A47TxlPi_S52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Generate Synthetic Dataset ----------------------\n",
        "# make_classification → creates a synthetic classification dataset\n",
        "# n_samples=1000 → total 1000 data points\n",
        "# n_features=20 → each sample has 20 features (independent variables)\n",
        "# n_classes=2 → binary classification problem (2 target classes: 0 and 1)\n",
        "# random_state=1 → for reproducibility (ensures same dataset each time)\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=1)\n",
        "\n",
        "\n",
        "# ---------------------- Split Dataset into Train/Test ----------------------\n",
        "# train_test_split → splits dataset into training and testing sets\n",
        "# test_size=0.33 → 33% of data used for testing, 67% for training\n",
        "# random_state=1 → ensures same split every time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "\n",
        "# ---------------------- Train Gradient Boosting Classifier ----------------------\n",
        "# Initialize GradientBoostingClassifier (default hyperparameters)\n",
        "clf = GradientBoostingClassifier()\n",
        "\n",
        "# Train the model on training dataset\n",
        "clf.fit(X_train, y_train)   # model learns from training data (X_train → features, y_train → labels)\n"
      ],
      "metadata": {
        "id": "na8TkPvh_Wih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Make Predictions ----------------------\n",
        "# Use trained Gradient Boosting Classifier to predict labels for test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# ---------------------- Evaluate the Model ----------------------\n",
        "print(\"Current model performance:\")\n",
        "\n",
        "# Accuracy score → percentage of correctly classified samples\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "# Classification Report → gives precision, recall, f1-score, and support for each class\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix → shows how many predictions were correct/incorrect\n",
        "# Format: [[TN, FP], [FN, TP]]  for binary classification\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ---------------------- Hyperparameter Tuning using GridSearchCV ----------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid for tuning Gradient Boosting Classifier\n",
        "# n_estimators → number of boosting stages (trees)\n",
        "# learning_rate → step size shrinkage (controls contribution of each tree)\n",
        "# (commented params like max_depth, subsample, etc. can also be tuned for better performance)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.05, 0.2],\n",
        "#     'max_depth': [3, 4, 5],\n",
        "#     'subsample': [0.8, 0.9, 1.0],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4]\n",
        "}\n"
      ],
      "metadata": {
        "id": "z2jpveEi_cEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Grid Search with Gradient Boosting Classifier ----------------------\n",
        "\n",
        "# Create a Gradient Boosting Classifier instance (without tuning yet)\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "# GridSearchCV → Performs exhaustive search over the parameter grid\n",
        "# estimator   = gbc (base model)\n",
        "# param_grid  = param_grid (defined earlier with n_estimators & learning_rate)\n",
        "# cv          = 5 (5-fold cross-validation to check model performance stability)\n",
        "# verbose     = 3 (prints detailed logs while training)\n",
        "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, verbose=3)\n",
        "\n",
        "# Just displaying the GridSearch object (before fitting)\n",
        "grid_search\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "# This will train multiple models with all combinations of param_grid\n",
        "# and select the best combination based on cross-validation performance\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Extract the best hyperparameters found by GridSearchCV\n",
        "grid_search.best_params_\n",
        "\n",
        "# Extract the best model (Gradient Boosting with tuned hyperparameters)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# ---------------------- Predictions using Tuned Model ----------------------\n",
        "# Use tuned model to predict on test data\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "# ---------------------- Evaluate the Tuned Model ----------------------\n",
        "print(\"Tuned model performance:\")\n",
        "\n",
        "# Accuracy → overall correctness of model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tuned)}\")\n",
        "\n",
        "# Classification Report → precision, recall, f1-score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))\n",
        "\n",
        "# Confusion Matrix → shows distribution of correct vs incorrect predictions\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_tuned))\n"
      ],
      "metadata": {
        "id": "t7VfMSzZ_fkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Import Libraries ----------------------\n",
        "from sklearn.datasets import make_regression              # For generating a synthetic regression dataset\n",
        "from sklearn.model_selection import train_test_split      # To split dataset into training & testing\n",
        "from sklearn.ensemble import GradientBoostingRegressor    # Gradient Boosting for regression task\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error  # Evaluation metrics\n",
        "\n",
        "\n",
        "# ---------------------- Step 1: Generate Synthetic Dataset ----------------------\n",
        "# make_regression → creates a regression dataset with controlled noise\n",
        "# n_samples = 1000 → 1000 data points\n",
        "# n_features = 2   → 2 independent variables (features)\n",
        "# noise = 10       → Adds randomness to make problem realistic\n",
        "# random_state=42  → Ensures reproducibility\n",
        "X, y = make_regression(n_samples=1000, n_features=2, noise=10, random_state=42)\n",
        "\n",
        "\n",
        "# ---------------------- Step 2: Split Dataset ----------------------\n",
        "# Splitting data into training (67%) and testing (33%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "# ---------------------- Step 3: Initialize Model ----------------------\n",
        "# GradientBoostingRegressor → Ensemble model for regression\n",
        "regressor = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "# ---------------------- Step 4: Train the Model ----------------------\n",
        "# Fitting the regressor on training dataset\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# ---------------------- Step 5: Make Predictions ----------------------\n",
        "# Predicting values for test data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "\n",
        "# ---------------------- Step 6: Evaluate Model ----------------------\n",
        "print(\"Current model performance:\")\n",
        "\n",
        "# R² Score → Measures proportion of variance explained (1 = perfect fit)\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred)}\")\n",
        "\n",
        "# Mean Absolute Error (MAE) → Average of absolute errors (lower is better)\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred)}\")\n",
        "\n",
        "# Mean Squared Error (MSE) → Average of squared errors (penalizes large errors more)\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "id": "zRCx8WWt_sUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Step 1: Import Library ----------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# ---------------------- Step 2: Define Parameter Grid ----------------------\n",
        "# Hyperparameters to tune:\n",
        "# - n_estimators → number of boosting stages (trees)\n",
        "# - learning_rate → step size shrinkage\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],   # how many trees to build\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # smaller → more accurate but slower\n",
        "    # You can also add more params (currently commented):\n",
        "    # 'max_depth': [3, 4, 5],          # depth of trees\n",
        "    # 'subsample': [0.8, 0.9, 1.0],    # fraction of samples per tree\n",
        "    # 'min_samples_split': [2, 5, 10], # min samples to split node\n",
        "    # 'min_samples_leaf': [1, 2, 4]    # min samples at leaf node\n",
        "}\n",
        "\n",
        "\n",
        "# ---------------------- Step 3: Initialize GradientBoosting ----------------------\n",
        "gbr = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "# ---------------------- Step 4: Setup GridSearchCV ----------------------\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → shows progress logs\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gbr,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    verbose=3\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------- Step 5: Fit GridSearchCV ----------------------\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "\n",
        "# ---------------------- Step 6: Best Model from GridSearch ----------------------\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions using tuned model\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "# ---------------------- Step 7: Evaluate Tuned Model ----------------------\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_tuned)}\")\n"
      ],
      "metadata": {
        "id": "0ARCvOtm_1WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST CLASSIFIER"
      ],
      "metadata": {
        "id": "OpkNthSKBgEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Step 1: Import Library ----------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# ---------------------- Step 2: Define Parameter Grid ----------------------\n",
        "# Hyperparameters to tune:\n",
        "# - n_estimators → number of boosting stages (trees)\n",
        "# - learning_rate → step size shrinkage\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],   # how many trees to build\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # smaller → more accurate but slower\n",
        "    # You can also add more params (currently commented):\n",
        "    # 'max_depth': [3, 4, 5],          # depth of trees\n",
        "    # 'subsample': [0.8, 0.9, 1.0],    # fraction of samples per tree\n",
        "    # 'min_samples_split': [2, 5, 10], # min samples to split node\n",
        "    # 'min_samples_leaf': [1, 2, 4]    # min samples at leaf node\n",
        "}\n",
        "\n",
        "\n",
        "# ---------------------- Step 3: Initialize GradientBoosting ----------------------\n",
        "gbr = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "# ---------------------- Step 4: Setup GridSearchCV ----------------------\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → shows progress logs\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gbr,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    verbose=3\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------- Step 5: Fit GridSearchCV ----------------------\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "\n",
        "# ---------------------- Step 6: Best Model from GridSearch ----------------------\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions using tuned model\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "# ---------------------- Step 7: Evaluate Tuned Model ----------------------\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_tuned)}\")\n"
      ],
      "metadata": {
        "id": "RHwTtHwTBkQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------- Step 1: Import Libraries ----------------------\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ---------------------- Step 2: Generate Dataset ----------------------\n",
        "X, y = make_regression(n_samples=1000, n_features=2, noise=10, random_state=1)\n",
        "\n",
        "# ---------------------- Step 3: Train-Test Split ----------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "# ---------------------- Step 4: Initialize Base Model ----------------------\n",
        "regressor = XGBRegressor()\n",
        "\n",
        "# ---------------------- Step 5: Define Hyperparameter Grid ----------------------\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],         # number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2] # step size shrinkage\n",
        "    # Uncomment to tune further:\n",
        "    # 'max_depth': [3, 4, 5, 6],\n",
        "    # 'subsample': [0.8, 0.9, 1.0],\n",
        "    # 'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    # 'reg_alpha': [0, 0.1, 0.5, 1],\n",
        "    # 'reg_lambda': [1, 1.5, 2, 3]\n",
        "}\n",
        "\n",
        "# ---------------------- Step 6: Apply GridSearchCV ----------------------\n",
        "# cv=5 → 5-fold cross validation\n",
        "# n_jobs=-1 → use all CPU cores\n",
        "# verbose=2 → show progress\n",
        "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# ---------------------- Step 7: Fit GridSearch ----------------------\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------- Step 8: Best Parameters ----------------------\n",
        "print(\"Best Parameters found:\", grid_search.best_params_)\n",
        "\n",
        "# ---------------------- Step 9: Best Model ----------------------\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# ---------------------- Step 10: Predictions using Tuned Model ----------------------\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "# ---------------------- Step 11: Evaluate Tuned Model ----------------------\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_tuned)}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_tuned)}\")\n"
      ],
      "metadata": {
        "id": "eiXsdQ6VCo4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost classifier ka use karke classification problem solve karna\n",
        "\n",
        "from xgboost import XGBClassifier                 # XGBoost classifier import (gradient boosting based algorithm)\n",
        "from sklearn.datasets import make_classification  # dummy synthetic dataset generate karne ke liye\n",
        "from sklearn.model_selection import train_test_split  # dataset ko training aur testing me split karne ke liye\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # model evaluation metrics\n",
        "\n",
        "# Generate dataset\n",
        "# make_classification ek synthetic dataset banata hai classification tasks ke liye\n",
        "# n_samples=1000 → total 1000 rows\n",
        "# n_features=20 → har row me 20 input features\n",
        "# n_classes=2 → binary classification (0 ya 1 output)\n",
        "# random_state=1 → reproducibility ke liye same random split\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=1)\n",
        "\n",
        "# Dataset ko train aur test set me split karna\n",
        "# test_size=0.33 → 33% data test ke liye, 67% train ke liye\n",
        "# random_state=1 → consistent split ke liye\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "# XGBClassifier ka ek object banaya (default hyperparameters ke sath)\n",
        "classifier = XGBClassifier()\n",
        "\n",
        "# Model ko training karna (fit karna) training dataset (X_train, y_train) par\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "ZhvxqtvTDH5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model se predictions lena\n",
        "# classifier.predict(X_test) → test data ke liye trained model se predictions generate honge (0 ya 1)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Current model performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")       # accuracy_score → correct predictions / total predictions\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))               # precision, recall, f1-score aur support deta hai\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))                    # 2x2 matrix → TP, TN, FP, FN counts show karta hai\n",
        "\n",
        "\n",
        "# ---------------- HYPERPARAMETER TUNING ----------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "# param_grid ek dictionary hai jisme hyperparameters aur unke values ki list di jaati hai\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],        # total boosting rounds (trees) ki count\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],# learning_rate (eta) → har tree ki contribution control karta hai\n",
        "#   'max_depth': [3, 4, 5, 6],             # tree ki depth (jyada depth → jyada complex model)\n",
        "#   'subsample': [0.8, 0.9, 1.0],          # training samples ka fraction har tree ke liye\n",
        "#   'colsample_bytree': [0.8, 0.9, 1.0],   # features ka fraction har tree ke liye\n",
        "#   'reg_alpha': [0, 0.1, 0.5, 1],         # L1 regularization\n",
        "#   'reg_lambda': [1, 1.5, 2, 3]           # L2 regularization\n",
        "}\n",
        "\n",
        "# GridSearchCV lagana\n",
        "# estimator = classifier → jis model par tuning karni hai\n",
        "# param_grid = hyperparameters ki dictionary\n",
        "# cv=5 → 5-fold cross validation\n",
        "# n_jobs=-1 → sabhi CPU cores ka use kare fast processing ke liye\n",
        "# verbose=3 → tuning ke progress ko detailed print karega\n",
        "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=3)\n",
        "\n",
        "# GridSearchCV ke through best parameters search karna (training ke sath)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters milenge jo sabse acha performance dete hain cross-validation me\n",
        "grid_search.best_params_\n",
        "\n",
        "# Best tuned model ko extract karna\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Best tuned model se predictions lena test data ke liye\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "print(\"Tuned model performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tuned)}\")   # tuned model ki accuracy\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))           # precision, recall, f1-score\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_tuned))                # tuned confusion matrix\n"
      ],
      "metadata": {
        "id": "5wjkkKyHEL1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k nearest neighbhour classifier with hyperparameter tunning"
      ],
      "metadata": {
        "id": "sO4WdjzGVBVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# make_classification function ek synthetic dataset generate karta hai jo classification problems ke liye useful hota hai\n",
        "# Parameters:\n",
        "# n_samples=1000 → 1000 rows (observations / data points banenge)\n",
        "# n_features=3   → har row ke liye 3 independent features (columns) generate honge\n",
        "# n_redundant=0  → koi bhi redundant (duplicate/linear dependent) feature include nahi hoga\n",
        "# n_classes=2    → target variable (y) ke sirf 2 classes (binary classification: 0 aur 1) hongi\n",
        "# random_state=1 → random number generator fix kiya gaya hai, taki result repeatable ho\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=3, n_redundant=0, n_classes=2, random_state=1)\n",
        "\n",
        "X.shape   # X ka shape print karega → (1000, 3), matlab 1000 rows aur 3 features\n",
        "X         # Feature matrix (input variables) ko dikhayega\n",
        "y         # Target vector (labels) ko dikhayega jo sirf 0 aur 1 hote hain\n"
      ],
      "metadata": {
        "id": "qvs6pcIOVkDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_test_split → dataset ko training aur testing parts me divide karne ke liye\n",
        "# X, y → features aur target\n",
        "# test_size=0.30 → 30% data testing ke liye aur 70% data training ke liye\n",
        "# random_state=1 → reproducibility ke liye fixed random seed\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# shapes check karne ke liye → kitna data train aur test me gaya\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "# ------------------- MODEL TRAINING -------------------\n",
        "\n",
        "# sklearn.neighbors se KNN (K-Nearest Neighbors) classifier import kar rahe hain\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# KNN classifier ka object banaya (default parameters ke sath)\n",
        "# default: n_neighbors=5 (matlab 5 nearest points ke basis par prediction hoga)\n",
        "clf = KNeighborsClassifier()\n",
        "clf   # object print karne se model ke parameters dikhte hain\n",
        "\n",
        "\n",
        "# training data ke upar model ko train karna\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# testing data (X_test) ke liye predictions lena\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# y_pred → predicted values (0 ya 1 class ke form me)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "nxcj9U5bW8l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# confusion_matrix → model ke predictions aur actual values ka comparison table\n",
        "# accuracy_score → sahi predictions ka percentage\n",
        "# classification_report → precision, recall, f1-score, support (har class ke liye detailed report)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ------------------- HYPERPARAMETER TUNING -------------------\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# param_grid → alag-alag parameter combinations try karne ke liye dictionary\n",
        "# yaha par KNN ke liye parameters:\n",
        "#   n_neighbors → kitne neighbors consider karne hain (3, 5, 6, 7, 9, 11, 13)\n",
        "#   weights → uniform (sabka equal weight) ya distance (paas ke points ka zyada weight)\n",
        "#   algorithm → nearest neighbor search algorithm (auto, ball_tree, kd_tree, brute)\n",
        "#   leaf_size → tree-based algorithms ke liye parameter (default=30)\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 6, 7, 9, 11, 13],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'leaf_size': [20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# GridSearchCV → sabhi parameter combinations ke liye model train karke best parameters nikalta hai\n",
        "# estimator = clf → KNN classifier\n",
        "# param_grid = param_grid → jo parameters try karne hain\n",
        "# cv=5 → 5-fold cross validation\n",
        "# verbose=3 → training progress details show karega\n",
        "grid = GridSearchCV(estimator = clf, param_grid=param_grid, cv = 5, verbose=3)\n",
        "\n",
        "grid   # object print karne se GridSearchCV ke settings dikhengi\n",
        "\n",
        "\n",
        "# training data par GridSearchCV ko fit karna (sabhi parameter combinations test karega)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# best_params_ → wo parameters jo best accuracy dete hain\n",
        "grid.best_params_\n",
        "\n",
        "# best_score_ → cross validation me jo best accuracy mili\n",
        "grid.best_score_\n"
      ],
      "metadata": {
        "id": "xVkQ7WEhXNdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the best estimator (grid search ke baad jo best model mila usko use karna)\n",
        "# grid.best_estimator_ → GridSearchCV se automatically best hyperparameters wala model return hota hai\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# ab is best_model se test data ke liye predictions karte hain\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "# ------------------- EVALUATE THE TUNED MODEL -------------------\n",
        "\n",
        "print(\"Tuned model performance:\")\n",
        "\n",
        "# Accuracy → tuned model ne test data par kitne sahi predictions kiye\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tuned)}\")\n",
        "\n",
        "# Classification Report → har class ke liye precision, recall, f1-score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))\n",
        "\n",
        "# Confusion Matrix → actual vs predicted values ka summary table\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_tuned))\n"
      ],
      "metadata": {
        "id": "t5clRiiOXoC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k nearest neighbhour regressor wth hyper parameter tunung"
      ],
      "metadata": {
        "id": "D8UQkwveYNC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "# Synthetic regression dataset generate karna\n",
        "# n_samples=1000 → 1000 data points\n",
        "# n_features=2 → har data point ke 2 input features\n",
        "# noise=3 → thoda randomness add karna taaki real-world data jaisa lage\n",
        "# random_state=1 → reproducibility ke liye fixed random seed\n",
        "X, y = make_regression(n_samples=1000, n_features=2, noise=3, random_state=1)\n",
        "\n",
        "X     # Input features (1000 rows × 2 columns ka dataset)\n",
        "y     # Target values (continuous regression values)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Dataset ko training aur testing parts me split karna\n",
        "# test_size=0.30 → 30% data testing ke liye\n",
        "# random_state=1 → reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# KNN Regressor ka object banaya\n",
        "reg = KNeighborsRegressor()\n",
        "\n",
        "reg   # Print karne se default parameters dikhte hain (n_neighbors=5 by default)\n",
        "\n",
        "\n",
        "# Model ko training dataset par fit karna\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Testing data ke liye prediction karna\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "y_pred   # Predicted continuous values\n"
      ],
      "metadata": {
        "id": "19W0m8NwYf4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "# Model ki performance ko evaluate karne ke liye R² score nikalte hain\n",
        "# R² score batata hai ki model kitna variance explain kar raha hai\n",
        "r2_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Hyperparameter tuning ke liye GridSearchCV use karte hain\n",
        "# param_grid me sabhi possible parameter combinations diye hain\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 6, 7, 9, 11, 13],       # Neighbors ka count\n",
        "    'weights': ['uniform', 'distance'],           # Prediction weighting ka method\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Nearest neighbor calculation ka algo\n",
        "    'leaf_size': [20, 30, 40, 50]                 # Tree-based algorithms ke liye leaf size\n",
        "}\n",
        "\n",
        "# GridSearchCV setup\n",
        "# estimator=reg → KNeighborsRegressor model\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → progress print karega tuning ke dauran\n",
        "grid = GridSearchCV(estimator=reg, param_grid=param_grid, cv=5, verbose=3)\n",
        "\n",
        "grid   # Isko run karne se tuning setup ka object dikhega\n",
        "\n",
        "\n",
        "# Training data par GridSearchCV ko fit karna\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Best parameter combination jo sabse acha perform kare\n",
        "grid.best_params_\n",
        "\n",
        "\n",
        "# Best cross-validation score (R² score) jo tuning ke dauran mila\n",
        "grid.best_score_\n",
        "\n",
        "\n",
        "# Best model ke parameters ko store kar liya\n",
        "best_model = grid.best_params_\n",
        "best_model\n"
      ],
      "metadata": {
        "id": "tTuQVBaJY29s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA IMPLEMENTATION"
      ],
      "metadata": {
        "id": "5IsFsJYiZfZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "# Iris dataset load karna (famous dataset classification ke liye)\n",
        "data = load_iris()\n",
        "X = data.data   # Features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target # Target labels (setosa, versicolor, virginica)\n",
        "\n",
        "X   # Features ko dekhne ke liye\n",
        "y   # Target values ko dekhne ke liye\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Dataset ko training aur testing parts me split karte hain\n",
        "# test_size=0.33 → 33% data test ke liye\n",
        "# random_state=1 → reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "# Training aur testing dataset ke shape dekhna\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler  # Features ko normalize karne ke liye (mean=0, std=1)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Training data ko scale karna (fit_transform → pehle mean/std calculate karega aur fir transform karega)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_train   # Scaled training data dekhne ke liye\n"
      ],
      "metadata": {
        "id": "ImofrskUZ6UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# PCA (Principal Component Analysis) dimensionality reduction ke liye use hota hai\n",
        "\n",
        "pca = PCA()\n",
        "# Agar n_components specify nahi karte → to by default jitne features hote hain utne hi principal components nikalta hai\n",
        "\n",
        "pca   # PCA object ko check karna\n",
        "\n",
        "\n",
        "# Training data par PCA apply karna\n",
        "# fit_transform → PCA model ko fit karega aur transform karke naye principal components banayega\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_train   # Ab features PCA ke components (linear combinations) me transform ho gaye\n",
        "\n",
        "\n",
        "# Test data par sirf transform use karte hain (fit nahi karte, warna data leakage ho jayega)\n",
        "X_test = pca.transform(X_test)\n",
        "X_test   # Testing data bhi ab wahi principal components me represent ho gaya\n"
      ],
      "metadata": {
        "id": "rHrC8ej7aN-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dataset ko training aur testing set me split karna\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler # mean=0, variance=1 (standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)   # Training data ko scale karna\n",
        "\n",
        "\n",
        "# PCA apply karna with 3 components (i.e. reduce dimensions from original features → 3 PCs me)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "\n",
        "X_train = pca.fit_transform(X_train)  # Fit aur transform dono training data par\n",
        "X_train   # Ab data 3 dimensions me reduce ho gaya hai (PC1, PC2, PC3)\n",
        "\n",
        "\n",
        "# PCA ke principal components check karna\n",
        "pca.components_\n",
        "# Ye matrix har principal component ke liye original features ka linear combination show karti hai\n",
        "# Har row ek PC ko represent karta hai\n",
        "# Har column ek original feature ke contribution (loading) ko represent karta hai\n",
        "\n",
        "\n",
        "# Explained variance ratio check karna\n",
        "pca.explained_variance_ratio_\n",
        "# Ye batata hai ki har principal component dataset ke total variance ka kitna percentage explain karta hai\n",
        "# Jaise [0.72, 0.22, 0.06] → PC1 = 72%, PC2 = 22%, PC3 = 6%\n"
      ],
      "metadata": {
        "id": "jvh4ckbNaWdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kmeans clustering"
      ],
      "metadata": {
        "id": "RtHKIW0dbDCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X,y=make_blobs(n_samples=1000,centers=3,n_features=2,random_state=1)\n",
        "#usl>> we will not be using y\n",
        "X\n",
        "plt.scatter(X[:,0], X[:, 1])\n",
        "# plt.scatter(X[:,0], X[:, 1], c=y)"
      ],
      "metadata": {
        "id": "2lHf6f-ubJtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "X_train.shape, X_test.shape\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans\n",
        "kmeans.fit(X_train) #fit_predict can also be used\n",
        "y_labels = kmeans.predict(X_train)\n",
        "y_labels"
      ],
      "metadata": {
        "id": "djbR9SiObT_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.scatter(X[:,0], X[:, 1], c=y) #y is actual y on complete data\n",
        "plt.scatter(X_train[:,0], X_train[:, 1], c=y_labels) #on train data, y_labels is predicted on train data\n",
        "#how better this clustering model is\n",
        "from sklearn.metrics import silhouette_score\n",
        "silhouette_score(X_train, kmeans.labels_) #close to 1 we have made a good model\n",
        "kmeans.labels_\n",
        "kmeans.inertia_ #k=3, this is the wcss distance"
      ],
      "metadata": {
        "id": "0NBcBeFYbiAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------\n",
        "# How to select K (centroid) >> Elbow method\n",
        "#-------------------------------------------\n",
        "\n",
        "# Step 1: WCSS (Within-Cluster Sum of Squares) calculate karna\n",
        "# WCSS batata hai cluster ke andar points kitne compact hain\n",
        "wcss = []\n",
        "for k in range(1, 10):   # k=1 se 9 tak check karenge\n",
        "    kmeans = KMeans(n_clusters=k)   # k clusters banenge\n",
        "    kmeans.fit(X_train)             # training data pe fit karenge\n",
        "    wcss.append(kmeans.inertia_)    # inertia = WCSS\n",
        "    wcss  # yeh list har k ke liye decreasing hogi (zyada cluster -> kam WCSS)\n",
        "\n",
        "# Step 2: Elbow Curve plot karna\n",
        "# Elbow point us jagah hota hai jaha WCSS ka decrease slow ho jata hai\n",
        "plt.plot(range(1, 10), wcss)\n",
        "plt.xticks(range(1, 10))\n",
        "plt.xlabel(\"No of cluster\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.show()\n",
        "\n",
        "# Step 3: KneeLocator ka use karke elbow (best k) automatically nikalna\n",
        "# curve='convex' aur direction='decreasing' ka matlab hai ki WCSS graph hamesha neeche jata hai\n",
        "from kneed import KneeLocator\n",
        "k1 = KneeLocator(range(1, 10), wcss, curve = 'convex', direction = 'decreasing')\n",
        "k1.elbow   # yeh value best number of clusters (K) batayegi\n",
        "\n",
        "# Step 4: Silhouette Score calculate karna\n",
        "# Silhouette score batata hai clustering kitni achhi hai (range -1 to 1)\n",
        "# 1 ke kareeb matlab clusters clearly separated hain\n",
        "# 0 ke kareeb matlab overlap hai\n",
        "# Negative matlab galat clustering\n",
        "silhouette_coeff = []\n",
        "for k in range(2, 10):   # silhouette score hamesha k>=2 se calculate hota hai\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    kmeans.fit(X_train)\n",
        "    score = silhouette_score(X_train, kmeans.labels_)\n",
        "    silhouette_coeff.append(score)\n",
        "\n",
        "silhouette_coeff   # jis k par maximum score milega, wahi best K hoga\n"
      ],
      "metadata": {
        "id": "B7dmO7y9bssP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# heirarical clustering"
      ],
      "metadata": {
        "id": "Ral2ed4gc5zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------\n",
        "# Load Iris Dataset from sklearn\n",
        "#-----------------------------------------\n",
        "from sklearn import datasets\n",
        "\n",
        "# Step 1: iris dataset load karna\n",
        "data = datasets.load_iris()\n",
        "\n",
        "# Step 2: features (X) aur target (y) alag karna\n",
        "X = data.data        # X -> features (sepal length, sepal width, petal length, petal width)\n",
        "y = data.target      # y -> labels (0=setosa, 1=versicolor, 2=virginica)\n",
        "\n",
        "# Step 3: Features aur target print karna\n",
        "X   # shape (150,4) -> matlab 150 samples aur 4 features\n",
        "y   # shape (150,) -> matlab har sample ka class label\n"
      ],
      "metadata": {
        "id": "JADaM1s8c952"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------\n",
        "# Feature Scaling using StandardScaler\n",
        "#-----------------------------------------\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()          # StandardScaler object create kiya → mean=0, std=1\n",
        "X_scaled = scaler.fit_transform(X) # X ko scale kiya → har feature ka mean=0 aur std=1\n",
        "\n",
        "#-----------------------------------------\n",
        "# Applying PCA (Principal Component Analysis)\n",
        "#-----------------------------------------\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)         # PCA object, n_components=2 → data ko 2D me reduce karega\n",
        "pca_scaled  = pca.fit_transform(X_scaled)  # scaled data pe PCA apply kiya\n",
        "\n",
        "#-----------------------------------------\n",
        "# Visualize the PCA components\n",
        "#-----------------------------------------\n",
        "plt.scatter(pca_scaled[:, 0], pca_scaled[:, 1], c=y)  # Scatter plot → x=PC1, y=PC2, color=y (labels)\n",
        "plt.scatter(pca_scaled[:, 0], pca_scaled[:, 1],)       # Scatter plot without color → same points\n"
      ],
      "metadata": {
        "id": "foEpO3uNdEz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------\n",
        "# Agglomerative Clustering with Dendrogram\n",
        "#-----------------------------------------\n",
        "import scipy.cluster.hierarchy as sc\n",
        "\n",
        "plt.figure(figsize=(20, 7))                       # Figure size set kiya\n",
        "plt.title(\"dendogram\")                             # Plot ka title\n",
        "\n",
        "sc.dendrogram(sc.linkage(pca_scaled, method=\"ward\"))  # Hierarchical clustering dendrogram\n",
        "# linkage method = \"ward\" → minimize variance within clusters\n",
        "plt.xlabel(\"sample data\")                          # x-axis label\n",
        "plt.ylabel(\"Euclidean distance\")                  # y-axis label → distance measure\n",
        "\n",
        "#-----------------------------------------\n",
        "# Applying Agglomerative Clustering\n",
        "#-----------------------------------------\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(\n",
        "    n_clusters=2,            # clusters ki number\n",
        "    affinity=\"euclidean\",    # distance metric\n",
        "    linkage=\"ward\"           # linkage method\n",
        ")\n",
        "cluster.fit(pca_scaled)      # PCA-reduced data pe fit kiya\n",
        "\n",
        "cluster.labels_               # Cluster labels output\n",
        "plt.scatter(pca_scaled[:,0], pca_scaled[:,1], c=cluster.labels_) # Visualize clusters\n",
        "\n",
        "#-----------------------------------------\n",
        "# Silhouette score for different k (2-10)\n",
        "#-----------------------------------------\n",
        "silhouette_coeff = []\n",
        "for k in range(2, 11):\n",
        "    agglo = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage='ward')\n",
        "    agglo.fit(X_scaled)\n",
        "    score = silhouette_score(X_scaled, agglo.labels_)  # Silhouette coefficient calculate\n",
        "    silhouette_coefficients.append(score)              # List me store\n"
      ],
      "metadata": {
        "id": "_1kztalJdTWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DBSCAN IMPLEMENTATION"
      ],
      "metadata": {
        "id": "XS0xHIZjeJVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------\n",
        "# DBSCAN clustering example\n",
        "#----------------------------\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Make synthetic dataset (two interleaving half circles)\n",
        "X, y = make_moons(n_samples=250, noise=0.10)  # n_samples=250 → data points, noise=0.10 → adds randomness\n",
        "X                                              # feature matrix\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)            # Scatter plot of the dataset\n",
        "# c=y → color by original class labels, visually show two moon shapes\n"
      ],
      "metadata": {
        "id": "HDW1BNNbeVl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------------------------\n",
        "# DBSCAN clustering on moons dataset\n",
        "#----------------------------\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scaling the data\n",
        "scaler = StandardScaler()                # StandardScaler → mean=0, std=1, normalization important for distance-based algorithms like DBSCAN\n",
        "X_scaled = scaler.fit_transform(X)       # Fit scaler on X and transform\n",
        "X_scaled                                  # scaled features\n",
        "\n",
        "# Initialize DBSCAN\n",
        "dbscan = DBSCAN(eps=0.2)                 # eps=0.2 → radius to consider neighbors for clustering\n",
        "dbscan                                     # DBSCAN object\n",
        "\n",
        "# Fit DBSCAN\n",
        "dbscan.fit(X_scaled)                      # Learn clusters\n",
        "dbscan.labels_                            # Cluster labels assigned to each point (-1 → noise points)\n",
        "\n",
        "# Plotting results\n",
        "plt.scatter(X[:,0], X[:,1], c=dbscan.labels_)  # Scatter plot colored by DBSCAN cluster labels\n",
        "plt.scatter(X[:,0], X[:,1], c=y)               # Scatter plot colored by original class labels for comparison\n"
      ],
      "metadata": {
        "id": "SjRojj50edUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ISOLATION FOREST IMPLEMENTATION"
      ],
      "metadata": {
        "id": "2B7_0Ev6fLvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Detecting outliers using Isolation Forest\n",
        "# ----------------------------\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('healthcare.csv')        # Reading CSV file into a DataFrame\n",
        "df.head()                                 # Display first few rows\n",
        "\n",
        "# Visualize data\n",
        "plt.scatter(df.iloc[:, 0], df.iloc[:, 1]) # Scatter plot of first two columns to see potential outliers\n",
        "\n",
        "# Initialize Isolation Forest\n",
        "out = IsolationForest(contamination=0.2) # contamination=0.2 → assumes 20% of the data are outliers\n",
        "out.fit(df)                               # Fit the model on the dataset\n",
        "\n",
        "# Predict outliers\n",
        "pred = out.predict(df)                    # Output: 1 for inliers, -1 for outliers\n",
        "pred                                        # Array showing which points are detected as outliers\n"
      ],
      "metadata": {
        "id": "gbGeyHFlfaNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indices of outliers\n",
        "index = np.where(pred < 0)   # np.where(pred < 0) → positions where IsolationForest marked as outliers\n",
        "index                        # Display indices of detected outliers\n",
        "\n",
        "# Convert DataFrame to numpy array for easier indexing\n",
        "x = df.values\n",
        "x                             # Entire dataset as numpy array\n",
        "\n",
        "# Plot all data points\n",
        "plt.scatter(df.iloc[:, 0], df.iloc[:, 1])  # Scatter plot of original data\n",
        "\n",
        "# Highlight outliers on the scatter plot\n",
        "plt.scatter(x[index, 0], x[index, 1], edgecolors=')   # Scatter plot for detected outliers (pred < 0)\n"
      ],
      "metadata": {
        "id": "wD0em_4NfjPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DBSCAN FOR OUTLIER"
      ],
      "metadata": {
        "id": "GOVsRLZwgWLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DBSCAN clustering and dataset generator\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Generate circular dataset with noise\n",
        "X, y = make_circles(n_samples=750, factor=0.3, noise=0.1)\n",
        "\n",
        "# Plot the raw data points\n",
        "plt.scatter(X[:, 0], X[:, 1])  # Scatter plot of the original circle data\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps = 0.1)        # eps = maximum distance between two points to be considered neighbors\n",
        "dbscan.fit_predict(X)             # Fit the model and assign cluster labels\n",
        "dbscan.labels_                    # Inspect the cluster labels assigned to each point\n",
        "\n",
        "# Visualize clusters found by DBSCAN\n",
        "plt.scatter(X[:, 0], X[:, 1], c = dbscan.labels_)  # Color points according to DBSCAN cluster labels\n",
        "\n",
        "# Compare with true labels\n",
        "plt.scatter(X[:, 0], X[:, 1], c = y)              # Color points according to original dataset labels\n"
      ],
      "metadata": {
        "id": "QzQ4vhzGgddu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOCAL OUTLIER FACTOR IMPLEMENTATION"
      ],
      "metadata": {
        "id": "2nsuoAgCg3KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LocalOutlierFactor for anomaly detection and dataset generator\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Generate moon-shaped dataset\n",
        "X, y = make_moons(n_samples=300, noise=0.1)  # 300 points with noise\n",
        "\n",
        "# Add random outliers to dataset\n",
        "X_outliers = np.random.uniform(low=-3, high=3, size=(20, 2))  # 20 random points\n",
        "X = np.vstack((X, X_outliers))  # Combine original points with outliers\n",
        "\n",
        "# Initialize LocalOutlierFactor\n",
        "out = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "# n_neighbors → number of neighbors for calculating LOF\n",
        "# contamination → proportion of outliers in the dataset\n",
        "\n",
        "# Fit LOF and predict outliers\n",
        "y_pred = out.fit_predict(X)  # Returns 1 for inliers and -1 for outliers\n",
        "y_pred                        # Display prediction labels\n"
      ],
      "metadata": {
        "id": "rM9tChS9hHkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate inliers (normal points) and outliers based on LOF predictions\n",
        "X_inliers = X[y_pred == 1]   # Points predicted as normal (label 1)\n",
        "X_outliers = X[y_pred == -1] # Points predicted as outliers (label -1)\n",
        "\n",
        "# Plotting the results\n",
        "plt.title(\"Local Outlier Factor (LOF) on Moons Data\")  # Set plot title\n",
        "plt.scatter(X_inliers[:, 0], X_inliers[:, 1], color='b', s=20, edgecolor='k', label='Normal data points')  # Blue for inliers\n",
        "plt.scatter(X_outliers[:, 0], X_outliers[:, 1], color='r', s=20, edgecolor='k', label='Outliers')        # Red for outliers\n",
        "plt.legend()  # Show legend\n",
        "plt.show()    # Display the plot\n"
      ],
      "metadata": {
        "id": "rNCtDZeLhaK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCTION TO TIMESERIES"
      ],
      "metadata": {
        "id": "rQMstF68h1RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------- Non Time Series Data --------------------- #\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# Load California Housing dataset (this is NOT time series, it's tabular data)\n",
        "california_housing = fetch_california_housing()\n",
        "\n",
        "# Convert to pandas DataFrame for easy manipulation\n",
        "df = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
        "\n",
        "# Add target column (house value)\n",
        "df['target'] = california_housing.target\n",
        "\n",
        "# Display first 5 rows\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "# --------------------- Time Series Data --------------------- #\n",
        "\n",
        "# Load a Time Series dataset (monthly air passenger counts)\n",
        "df = pd.read_csv(\"AirPassengers.csv\")\n",
        "\n",
        "# Display dataset (usually has columns like Month and #Passengers)\n",
        "df\n"
      ],
      "metadata": {
        "id": "5nZPEPHSh7mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TIME SERIES ANALYSIS AND FORECASTING"
      ],
      "metadata": {
        "id": "6Ojwn9YoiSdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load stock dataset\n",
        "data = pd.read_csv(\"TSLA.csv\")\n",
        "data\n",
        "data.shape        # Shows (rows, columns)\n",
        "data.head().T     # First 5 rows, but transposed (good for wide tables)\n",
        "data.info()       # Info about columns, datatypes, null values\n",
        "\n",
        "# Extract only Date & Close columns (for time series analysis)\n",
        "stock_data = data[[\"Date\", \"Close\"]]\n",
        "stock_data\n",
        "stock_data.info()   # Currently \"Date\" is object (string)\n",
        "\n",
        "# Convert Date column to datetime\n",
        "stock_data[\"Date\"] = pd.to_datetime(stock_data[\"Date\"])\n",
        "stock_data.info()   # Now \"Date\" is datetime64[ns]\n",
        "stock_data\n"
      ],
      "metadata": {
        "id": "A34jHtPaiWwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Time series data and tradition data>> the difference is time series has a time component\n",
        "#Therefore data column should be index.\n",
        "#slicing of data on date columns becomes easy\n",
        "#visulaisation is simple\n",
        "#Libraries related to forecasting models assumes that there is a time/date column"
      ],
      "metadata": {
        "id": "fRvv1HN9ivY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps:\n",
        "#step 1: summary>>mean, median, mode\n",
        "#step 2> visualise the time series data, rolling mean and standard deviation, trend seasonalit and noise\n",
        "#decomposition of time srries\n",
        "#step 3>> stationarity check>> visualisation or statistical test(ADF)\n",
        "#step 4:ACF and PACF\n",
        "#step 5: Outliers"
      ],
      "metadata": {
        "id": "wPHBNeaWi7PZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the 'Date' column as the index so that rows are identified by date, useful for time series operations\n",
        "stock_data = stock_data.set_index(\"Date\")\n",
        "stock_data\n",
        "\n",
        "# Get descriptive statistics of the 'Close' column like count, mean, std, min, max, and quartiles\n",
        "stock_data.describe()\n",
        "\n",
        "# Plot the closing price over time as a line graph\n",
        "plt.plot(stock_data.Close)\n",
        "\n",
        "# Plot a histogram to show the frequency distribution of the closing prices\n",
        "plt.hist(stock_data.Close)\n"
      ],
      "metadata": {
        "id": "61wog4ECixG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#line chart for closing price\n",
        "# Set the plotting style to 'ggplot' for a cleaner, aesthetic look\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Create a figure of size 18x8 inches for better visibility\n",
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "# Enable grid lines for easier reading of the chart\n",
        "plt.grid(True)\n",
        "\n",
        "# Label the x-axis as 'Dates' with font size 20\n",
        "plt.xlabel('Dates', fontsize = 20)\n",
        "\n",
        "# Customize font size for x-axis ticks\n",
        "plt.xticks(fontsize = 15)\n",
        "\n",
        "# Label the y-axis as 'Close Prices' with font size 20\n",
        "plt.ylabel('Close Prices', fontsize = 20)\n",
        "\n",
        "# Customize font size for y-axis ticks\n",
        "plt.yticks(fontsize = 15)\n",
        "\n",
        "# Plot the line chart for Tesla's closing prices with blue color and line width of 3\n",
        "plt.plot(stock_data['Close'], linewidth = 3, color = 'blue')\n",
        "\n",
        "# Set the title of the plot with font size 30\n",
        "plt.title('Tesla Stock Closing Price', fontsize = 30)\n",
        "\n",
        "# Display the line chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "g0KO_QOYjEil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histogram\n",
        "# Set the plotting style to 'ggplot' for a clean and professional look\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Create a figure of size 18x8 inches to make the plot large and readable\n",
        "plt.figure(figsize=(18,8))\n",
        "\n",
        "# Enable grid lines for easier interpretation of the histogram values\n",
        "plt.grid(True)\n",
        "\n",
        "# Set the label for x-axis as 'Dates' with font size 20\n",
        "plt.xlabel('Dates', fontsize=20)\n",
        "\n",
        "# Set the font size of x-axis tick labels to 15 for readability\n",
        "plt.xticks(fontsize=15)\n",
        "\n",
        "# Set the label for y-axis as 'Close Prices' with font size 20\n",
        "plt.ylabel('Close Prices', fontsize=20)\n",
        "\n",
        "# Set the font size of y-axis tick labels to 15\n",
        "plt.yticks(fontsize=15)\n",
        "\n",
        "# Plot a histogram of the 'Close' prices from stock_data\n",
        "# linewidth=3 makes the edges of the bars more visible\n",
        "# color='blue' fills the bars with blue color\n",
        "plt.hist(stock_data['Close'], linewidth=3, color='blue')\n",
        "\n",
        "# Set the title of the plot with font size 30\n",
        "plt.title('Tesla Stock Closing Price', fontsize=30)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YhKUupLDjH5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution plot of closing price\n",
        "# Extract the 'Close' price column from the stock_data DataFrame\n",
        "df_close = stock_data[\"Close\"]\n",
        "\n",
        "# Plot the Kernel Density Estimate (KDE) of closing prices\n",
        "# kind='kde' → smooth estimate of the probability density function\n",
        "# figsize=(18, 8) → sets the figure size\n",
        "# linewidth=3 → makes the KDE line thicker for visibility\n",
        "df_close.plot(kind='kde', figsize=(18, 8), linewidth=3)\n",
        "\n",
        "# Set x-axis tick labels font size to 15\n",
        "plt.xticks(fontsize=15)\n",
        "\n",
        "# Enable both major and minor grid lines for better readability\n",
        "plt.grid(\"both\")\n",
        "\n",
        "# Set y-axis label to \"Density\" with font size 20\n",
        "plt.ylabel(\"Density\", fontsize=20)\n",
        "\n",
        "# Set y-axis tick labels font size to 15\n",
        "plt.yticks(fontsize=15)\n",
        "\n",
        "# Display the KDE plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ng0w1g6MjJ2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate rolling (moving) mean of the 'Close' price over a window of 48 time points\n",
        "rolling_mean = stock_data[\"Close\"].rolling(48).mean()\n",
        "\n",
        "# Calculate rolling standard deviation over the same window\n",
        "rolling_std = stock_data[\"Close\"].rolling(48).std()\n",
        "\n",
        "# Display rolling standard deviation values\n",
        "rolling_std\n",
        "\n",
        "# Plot the original closing prices\n",
        "plt.plot(stock_data.Close, label=\"Original Close\")\n",
        "\n",
        "# Plot the rolling mean on the same plot\n",
        "plt.plot(rolling_mean, label=\"Rolling Mean (48)\")\n",
        "\n",
        "# Plot the rolling standard deviation on the same plot\n",
        "plt.plot(rolling_std, label=\"Rolling Std (48)\")\n",
        "\n",
        "# Add a legend for clarity\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8d_mrEHmjL43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#From the plot above, it is clear that time series is non stationary\n",
        "#lets reverify by statistical test as well > ADF test"
      ],
      "metadata": {
        "id": "wcez4m5IjQ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "adft = adfuller(stock_data[\"Close\"])\n",
        "adft #null hypotheis of adf test is time series is non stationary, pvalue<0.05, reject null hypothesis\n",
        "#here pvalue> 0.05, it means series is non stationary\n",
        "pd.Series(adft[0:4], index = [\"test_statistics\", \"p-value\", 'lag', 'no of data points'])"
      ],
      "metadata": {
        "id": "JzFvBSTtjTbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test for staionarity\n",
        "def test_stationarity(timeseries):\n",
        "    # Determing rolling statistics\n",
        "    rolmean = timeseries.rolling(48).mean() # rolling mean\n",
        "    rolstd = timeseries.rolling(48).std() # rolling standard deviation\n",
        "    # Plot rolling statistics:\n",
        "    plt.figure(figsize = (18,8))\n",
        "    plt.grid('both')\n",
        "    plt.plot(timeseries, color='blue',label='Original', linewidth = 3)\n",
        "    plt.plot(rolmean, color='red', label='Rolling Mean',linewidth = 3)\n",
        "    plt.plot(rolstd, color='black', label = 'Rolling Std',linewidth = 4)\n",
        "    plt.legend(loc='best', fontsize = 20, shadow=True,facecolor='lightpink',edgecolor = 'k')\n",
        "    plt.title('Rolling Mean and Standard Deviation', fontsize = 25)\n",
        "    plt.xticks(fontsize = 15)\n",
        "    plt.yticks(fontsize = 15)\n",
        "    plt.show(block=False)\n",
        "\n",
        "    print(\"Results of dickey fuller test\")\n",
        "    adft = adfuller(timeseries,autolag='AIC')\n",
        "    # output for dft will give us without defining what the values are.\n",
        "    # hence we manually write what values does it explains using a for loop\n",
        "    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n",
        "    for key,values in adft[4].items():\n",
        "        output['critical value (%s)'%key] =  values\n",
        "    print(output)\n",
        "\n",
        "test_stationarity(stock_data.Close)"
      ],
      "metadata": {
        "id": "Y7cZ1Fl_jZZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#series is non stationary"
      ],
      "metadata": {
        "id": "IkPTKzGAjdd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A time series is made up of level, trend, seasonalit, noise\n",
        "#time series is of two types>> additive and multiplicative\n",
        "\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "result = seasonal_decompose(stock_data[['Close']], period = 12) #for 12 months\n",
        "result.seasonal\n",
        "fig = plt.figure(figsize = (20, 10))\n",
        "fig = result.plot()\n",
        "fig.set_size_inches(17, 10)\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "result = seasonal_decompose(stock_data[['Close']], period = 12, model = \"mutiplicative\")\n",
        "result.seasonal\n",
        "fig = plt.figure(figsize = (20, 10))\n",
        "fig = result.plot()\n",
        "fig.set_size_inches(17, 10)\n",
        "\n",
        "sns.boxplot(stock_data.Close)"
      ],
      "metadata": {
        "id": "hGdSXNF3jhMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (20, 10))\n",
        "ax.boxplot(stock_data[\"Close\"])\n",
        "ax.set_xlabel('Variables')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('Boxplot')\n",
        "plt.show()\n",
        "\n",
        "#ACF/PACF plot\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize = (12, 8))\n",
        "plot_acf(stock_data, ax = axes[0])\n",
        "plot_pacf(stock_data, ax = axes[1])\n",
        "plt.show()\n",
        "#since series is non stationary, results are not good"
      ],
      "metadata": {
        "id": "rpCPYelHj9Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To make time series stationary>> differencing\n",
        "df_close = df_close.diff()\n",
        "df_close = df_close.dropna()\n",
        "df_close"
      ],
      "metadata": {
        "id": "Xx-tiqXEkBfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now check again the stationarity\n",
        "test_stationarity(df_close)"
      ],
      "metadata": {
        "id": "us3KCuBvkHxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now pvalues is less than 0.05, reject the null>> time series is stationary, if not stationary, then again you need to differencing\n",
        "\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize = (12, 8))\n",
        "plot_acf(df_close, ax = axes[0])\n",
        "plot_pacf(df_close, ax = axes[1])\n",
        "plt.show()\n",
        "\n",
        "#in time series data, train test split happens based on tim index\n",
        "df_close"
      ],
      "metadata": {
        "id": "mKWAguF3kJ9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = df_close[0:-60]\n",
        "test_data = df_close[-60:]\n",
        "plt.figure(figsize = (18, 8))\n",
        "plt.grid(True)\n",
        "plt.xlabel('Dates', fontsize = 20)\n",
        "plt.ylabel('Closing price', fontsize = 20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.plot(train_data, 'green', label = 'Train data', linewidth = 4)\n",
        "plt.plot(test_data, 'red', label = 'Test data', linewidth = 4)\n",
        "plt.legend(fontsize = 20, shadow=True, facecolor = 'lightpink', edgecolor='k')\n",
        "\n",
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "id": "Cfv-teMhkOKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now since we will use ARIMA, we dont need stationary time series data\n",
        "#why> ARIMA itself has inherent differencing parameter, which will make the series stationary\n",
        "#I>> integrated\n",
        "#we will use original time series data\n",
        "\n",
        "train_data = stock_data[0:-60]\n",
        "test_data = stock_data[-60:]\n",
        "plt.figure(figsize = (18, 8))\n",
        "plt.grid(True)\n",
        "plt.xlabel('Dates', fontsize = 20)\n",
        "plt.ylabel('Closing price', fontsize = 20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.plot(train_data, 'green', label = 'Train data', linewidth = 4)\n",
        "plt.plot(test_data, 'red', label = 'Test data', linewidth = 4)\n",
        "plt.legend(fontsize = 20, shadow=True, facecolor = 'lightpink', edgecolor='k')"
      ],
      "metadata": {
        "id": "861ViQ2HkUJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model building\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "train_data\n",
        "history = train_data['Close']\n",
        "history"
      ],
      "metadata": {
        "id": "JvQMgat6kWzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(history, order = (1, 1, 1))\n",
        "model = model.fit()\n",
        "model.summary()\n",
        "model.forecast() #predict is used for a range of values\n",
        "test_data = test_data['Close']\n",
        "test_data\n",
        "mean_squared_error([test_data[0]], model.forecast())\n",
        "np.sqrt(mean_squared_error([test_data[0]], model.forecast()))"
      ],
      "metadata": {
        "id": "FBz0ebz8kfUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we can treat p, d, q as hyperparameter\n",
        "p_values = range(0, 3)\n",
        "d_values =  range(0, 3)\n",
        "q_values = range(0, 3)\n",
        "\n",
        "for i in p_values:\n",
        "    for j in d_values:\n",
        "        for k in q_values:\n",
        "            print(i, j, k)"
      ],
      "metadata": {
        "id": "JFRLn1G4ks1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_arima_model(X, y, arima_order):\n",
        "    # prepare training dataset\n",
        "    # make predictions list\n",
        "    history = [x for x in X]\n",
        "    predictions = list()\n",
        "    for t in range(len(y)):\n",
        "        model = ARIMA(history, order=arima_order)\n",
        "        model_fit = model.fit()\n",
        "        yhat = model_fit.forecast()[0]\n",
        "        predictions.append(yhat)\n",
        "        history.append(y[t])\n",
        "    # calculate out of sample error\n",
        "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
        "    return rmse\n",
        "\n",
        "def evaluate_models(dataset, test, p_values, d_values, q_values):\n",
        "    if isinstance(dataset, pd.DataFrame):\n",
        "        dataset = dataset['Close']\n",
        "    dataset = dataset.astype('float32')\n",
        "    best_score, best_cfg = float(\"inf\"), None\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p,d,q)\n",
        "                try:\n",
        "                    rmse = train_arima_model(dataset,test, order)\n",
        "                    if rmse < best_score:\n",
        "                        best_score, best_cfg = rmse, order\n",
        "                    print('ARIMA%s RMSE=%.3f' % (order, rmse))\n",
        "                except:\n",
        "                    continue\n",
        "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
        "\n",
        "\n",
        "evaluate_models(train_data, test_data, p_values, d_values, q_values)\n"
      ],
      "metadata": {
        "id": "jFoeGxpAkvII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [x for x in train_data['Close']]\n",
        "predictions = list()\n",
        "conf_list = list()\n",
        "for t in range(len(test_data)):\n",
        "    model = ARIMA(history,order=(2,0,0))\n",
        "    model_fit = model.fit()\n",
        "    fc = model_fit.forecast(alpha = 0.05)\n",
        "    predictions.append(fc)\n",
        "    history.append(test_data[t])\n",
        "print('RMSE of ARIMA Model:', np.sqrt(mean_squared_error(test_data, predictions)))"
      ],
      "metadata": {
        "id": "2mZRuS-DkwdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plt.grid(True)\n",
        "plt.plot(range(len(test_data)),test_data, label = 'True Test Close Value', linewidth = 5)\n",
        "plt.plot(range(len(predictions)), predictions, label = 'Predictions on test data', linewidth = 5)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.legend(fontsize = 20, shadow=True,facecolor='lightpink',edgecolor = 'k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "py8nWglAk3YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fc_series = pd.Series(predictions, index=test_data.index)\n",
        "fc_series"
      ],
      "metadata": {
        "id": "4cenr3_ok7N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forecast value with actual test data\n",
        "plt.figure(figsize=(12,5), dpi=100)\n",
        "plt.plot(train_data['Close'], label='Training', color = 'blue')\n",
        "plt.plot(test_data, label='Test', color = 'green', linewidth = 3)\n",
        "plt.plot(fc_series, label='Forecast', color = 'red')\n",
        "plt.title('Forecast vs Actuals on test data')\n",
        "plt.legend(loc='upper left', fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-KMOtq7XlA03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_predict\n",
        "fig = plt.figure(figsize=(18,8))\n",
        "ax1 = fig.add_subplot(111)\n",
        "plot_predict(result=model_fit,start=1, end=len(df_close)+60, ax = ax1)\n",
        "plt.grid(\"both\")\n",
        "plt.legend(['Forecast','Close','95% confidence interval'],fontsize = 20, shadow=True,facecolor='lightblue',edgecolor = 'k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Eq8bZswolDzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SARIMA -p, d, q, P, Q, D,s\n",
        "\n",
        "history = [x for x in train_data['Close']]\n",
        "predictions = list()\n",
        "conf_list = list()\n",
        "for t in range(len(test_data)):\n",
        "    model = sm.tsa.statespace.SARIMAX(history, order = (0,1,0), seasonal_order = (1,1,1,3))\n",
        "    model_fit = model.fit()\n",
        "    fc = model_fit.forecast()\n",
        "    predictions.append(fc)\n",
        "    history.append(test_data[t])\n",
        "print('RMSE of SARIMA Model:', np.sqrt(mean_squared_error(test_data, predictions)))"
      ],
      "metadata": {
        "id": "z-q5LRTSlGPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(18,8))\n",
        "plt.title('Forecast vs Actual', fontsize = 25)\n",
        "plt.plot(range(60), predictions, label = 'Predictions', linewidth = 4)\n",
        "plt.plot(range(60), test_data, label = 'Close', linewidth = 4)\n",
        "plt.legend(fontsize = 25, shadow=True,facecolor='lightpink',edgecolor = 'k')"
      ],
      "metadata": {
        "id": "fUGBZtCzlJjj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}