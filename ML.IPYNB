{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuIYt28n1VaOGS2c677jSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashish78905/OPTICONNECT_CALLL_CENTER_ANALYSIS-ASSIGNMENT/blob/main/ML.IPYNB\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE LINEAR REGRESSION 01"
      ],
      "metadata": {
        "id": "hq9RBEyp4_WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the diabetes dataset from sklearn\n",
        "from sklearn.datasets import load_diabetes\n",
        "diabetes = load_diabetes()\n",
        "\n",
        "# Display the loaded dataset object\n",
        "diabetes\n",
        "# Print the description of the dataset\n",
        "print(diabetes.DESCR)\n",
        "# Access and display the feature data\n",
        "diabetes.data\n",
        "# Access and display the target variable\n",
        "diabetes.target\n",
        "# Access and display the names of the features\n",
        "diabetes.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "# Add the target variable as a new column in the DataFrame\n",
        "data['target'] = diabetes.target"
      ],
      "metadata": {
        "id": "woiVUp8r5Hta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA, DATCLEANING, DATA PREPARATION, FEATURE ENGINEERING"
      ],
      "metadata": {
        "id": "Xbjv1e6K5mMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVIDE THE DATA INTO X, Y. For simple linear regression, we take only one feature.\n",
        "\n",
        "# Select the 'bmi' column as the feature (X)\n",
        "X = data[[\"bmi\"]]\n",
        "# Select the 'target' column as the target variable (y)\n",
        "y = data[\"target\"]\n",
        "# Display the feature data (X)\n",
        "X\n",
        "# Display the target variable (y)\n",
        "y"
      ],
      "metadata": {
        "id": "xLWAFKIY5qZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the data into train-test"
      ],
      "metadata": {
        "id": "9KmV8sYa58UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the train_test_split function from sklearn.model_selection to split data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "dKp_gU_G59d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# X_train: training features\n",
        "# X_test: testing features\n",
        "# y_train: training target\n",
        "# y_test: testing target\n",
        "# test_size = 0.2 means 20% of the data will be used for testing\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "metadata": {
        "id": "BlC2UKnt6BJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the training features\n",
        "X_train\n",
        "# Display the testing features\n",
        "X_test\n",
        "# Display the training target\n",
        "y_train\n",
        "# Display the testing target\n",
        "y_test"
      ],
      "metadata": {
        "id": "KHayKB6F6FPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "I-1ntDZ46PiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the LinearRegression model from sklearn.linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Create an instance of the LinearRegression model\n",
        "model = LinearRegression()\n",
        "# Display the model object\n",
        "model\n",
        "# Training of the model\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "# At the backend, it will use gradient descent to give optimal coefficients\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "aS7wKLfp6R5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the coefficient (slope) of the linear regression model\n",
        "model.coef_\n",
        "# Display the intercept (y-intercept) of the linear regression model\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "-uz5TH6g6kZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model pridiction"
      ],
      "metadata": {
        "id": "k2mBfQYD6wTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the target variable (y) for the test set (X_test)\n",
        "y_pred = model.predict(X_test)\n",
        "# Display the predicted values\n",
        "y_pred"
      ],
      "metadata": {
        "id": "Wu7OpINb60LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vizualize the result"
      ],
      "metadata": {
        "id": "W0Q_xD3q7Gix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the matplotlib.pyplot library for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# visualise the result\n",
        "# Create a scatter plot of the actual test data (X_test vs y_test)\n",
        "plt.scatter(X_test, y_test, color = 'black', label = 'Actual data')\n",
        "# Plot the linear regression line using the test features and predicted values\n",
        "plt.plot(X_test, y_pred, color = 'blue', linewidth = 3, label = \"Linear regression line\")\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"BMI\")\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"One year progression-target\")\n",
        "# Set the title of the plot\n",
        "plt.title(\"Linear regression on diabetes data\")\n",
        "# Display the legend\n",
        "plt.legend()\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A7ZnKzBQ69oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bic4N0x3hKCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple linear regression 02"
      ],
      "metadata": {
        "id": "g_uXZO5468ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "# Import matplotlib.pyplot for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "# Read the data from the csv file into a pandas DataFrame\n",
        "df = pd.read_csv(\"height-weight.csv\")\n",
        "# Create a scatter plot of Weight vs Height\n",
        "plt.scatter(df.Weight, df.Height)\n",
        "# Set the label for the x-axis\n",
        "plt.xlabel(\"weight\")\n",
        "# Set the label for the y-axis\n",
        "plt.ylabel(\"height\")\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j5xXKonP8B0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "divide the data into X, y"
      ],
      "metadata": {
        "id": "7Sq72S7mGExj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the independent feature (X) as the 'Weight' column from the DataFrame\n",
        "X=df[[\"Weight\"]] #independent feature\n",
        "# Define the dependent feature (y) as the 'Height' column from the DataFrame\n",
        "y = df[\"Height\"] #dependent feature"
      ],
      "metadata": {
        "id": "gnTyeF1SGEDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the train_test_split function from sklearn.model_selection to split data\n",
        "#train test split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XxmtR0GPGO5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# X_train: training features\n",
        "# X_test: testing features\n",
        "# y_train: training target\n",
        "# y_test: testing target\n",
        "# test_size = 0.25 means 25% of the data will be used for testing\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
        "# Display the shapes of the resulting arrays\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "Hiai4GF6GRfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling>> standardization >> fit_transform >>tain, transform>>test"
      ],
      "metadata": {
        "id": "9nvnCv96GhPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the StandardScaler from sklearn.preprocessing for feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Create an instance of the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Always perform scaling after train test split\n",
        "# y/target variable should not be scaled\n",
        "# avoid scaling categorical features\n",
        "# Scale the training features using fit_transform\n",
        "X_train = scaler.fit_transform(X_train) #for train data use fit_transform\n",
        "# Scale the testing features using only transform\n",
        "X_test = scaler.transform(X_test) #for test use only transform as it is representative of unknown data>>\n",
        "# Display the scaled training features\n",
        "X_train\n",
        "# Display the scaled testing features\n",
        "X_test\n",
        "# Create a scatter plot of the scaled training features vs the training target\n",
        "plt.scatter(X_train, y_train)"
      ],
      "metadata": {
        "id": "5wvpDZ6UGi_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the LinearRegression model from sklearn.linear_model\n",
        "#model training\n",
        "from sklearn.linear_selection import LinearRegression\n",
        "\n",
        "#linear regression parameters:\n",
        "#fit_intercept >> The best fit line will have intercept, by default it is true\n",
        "#copy__X >> copy the original X_train and then build the model, dont modify the original data,by default>>true\n",
        "#n_jobs >> processor you want to use\n",
        "#positive>> you want all of your coefficient to be positive\n",
        "\n",
        "\n",
        "#After building the model, you have attributes of the mode\n",
        "#coef\n",
        "#intercept"
      ],
      "metadata": {
        "id": "yHhJ9uN8G8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the LinearRegression model\n",
        "regressor = LinearRegression()\n",
        "# Display the model object\n",
        "regressor\n",
        "# Training of the model\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iVDGwrdBHAuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coefficient (slope) of the linear regression model\n",
        "print(\"The slope or coef of model is\", regressor.coef_)\n",
        "# Print the intercept (y-intercept) of the linear regression model\n",
        "print(\"The intercept of the model is\", regressor.intercept_)"
      ],
      "metadata": {
        "id": "LyUzSKzIHHuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predicted height output = intercept + coef_(weights), y_pred_train = 160.0+17.74*(X_train)\n",
        "Prediction on test data\n",
        "predicted height output = intercept + coef_(weights) , y_pred_test = 160.0+17.74*(X_test)"
      ],
      "metadata": {
        "id": "aWxAyXUlHNhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training data\n",
        "regressor.predict(X_train)\n",
        "# Create a scatter plot of the scaled training features vs the training target\n",
        "plt.scatter(X_train, y_train)\n",
        "# Plot the linear regression line for the training data\n",
        "plt.plot(X_train, regressor.predict(X_train), 'r')\n",
        "# Make predictions on the testing data\n",
        "y_pred_test = regressor.predict(X_test)\n",
        "# Display the predicted and actual values for the test set\n",
        "y_pred_test, y_test\n",
        "# Create a scatter plot of the scaled testing features vs the testing target\n",
        "plt.scatter(X_test, y_test)\n",
        "# Plot the linear regression line for the testing data\n",
        "plt.plot(X_test, regressor.predict(X_test), 'r')"
      ],
      "metadata": {
        "id": "4twbkhwTHOxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performance metrics"
      ],
      "metadata": {
        "id": "mIRLQmYfHf3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary metrics from sklearn.metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# Calculate the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "# Calculate the Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "# Calculate the Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print the calculated metrics\n",
        "print(mse, mae, rmse)\n",
        "\n",
        "# Rsquare =  1-SSR/SST\n",
        "\n",
        "# Import the r2_score from sklearn.metrics\n",
        "from sklearn.metrics import r2_score\n",
        "# Calculate the R-squared score\n",
        "score = r2_score(y_test, y_pred_test)\n",
        "# Display the R-squared score\n",
        "score\n",
        "\n",
        "#adjusted r square\n",
        "#R2 = 1 – [(1-R2)*(n-1)/(n-k-1)] #n is no of obs, k is no predictor varaiables\n",
        "# Calculate the adjusted R-squared score\n",
        "1-(1-score)*(len(y_test)-1)/(len(y_test) - X_test.shape[1] -1)\n",
        "#adjusted r square will be always lesser than rsquare"
      ],
      "metadata": {
        "id": "girk30E6HhvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of columns in the testing features (X_test)\n",
        "#to get no of columns\n",
        "X_test.shape[1]"
      ],
      "metadata": {
        "id": "K1O8os02IAd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assumption\n",
        "#X-y should have linear relationship\n",
        "# Observation should have no relation\n",
        "# error should have constant variance\n",
        "#error should be normally distribute\n",
        "# Create a scatter plot of the actual test values vs the predicted test values\n",
        "plt.scatter(y_test, y_pred_test)\n",
        "\n",
        "#residual/error\n",
        "# Calculate the residual error\n",
        "error = y_test - y_pred_test\n",
        "# Display the residual error\n",
        "error"
      ],
      "metadata": {
        "id": "sEcP87vKICo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiple linear regression 01"
      ],
      "metadata": {
        "id": "6rDX0gajI0IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple linear regression - It models the relationship between dependent variable y and more than one independent variable X#To predict disease progression one year after the baseline"
      ],
      "metadata": {
        "id": "G0MSOPjEReJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the load_diabetes function from sklearn.datasets\n",
        "from sklearn.datasets import load_diabetes\n",
        "# Read the dataset\n",
        "diabetes = load_diabetes()\n",
        "# Print the description of the dataset\n",
        "print(diabetes.DESCR)\n",
        "# Access the feature data\n",
        "diabetes.data\n",
        "# Access the target variable\n",
        "diabetes.target\n",
        "# Access the names of the features\n",
        "diabetes.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "data = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "# Display the DataFrame\n",
        "data\n",
        "# Add the target variable as a new column in the DataFrame\n",
        "data['target'] = diabetes.target"
      ],
      "metadata": {
        "id": "iity8kNXJJnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA and data prep\n",
        "# Divide into X (features) and y (target)\n",
        "\n",
        "# Define the independent features (X) by dropping the 'target' column\n",
        "X = data.drop('target', axis = 1)\n",
        "# Define the dependent feature (y) as the 'target' column\n",
        "y = data['target']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "# random_state = 1 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "# Display the shapes of the training and testing feature sets\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "4d8qaj9pSMaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling (optional)\n",
        "# This section is commented out, but if scaling were needed,\n",
        "# you would typically use StandardScaler here after splitting the data.\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Mcs4a9rhSePA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Create an instance of the LinearRegression model\n",
        "model = LinearRegression()\n",
        "# Fit the model to the training data (X_train and y_train)\n",
        "model.fit(X_train, y_train)\n",
        "# Display the shape of the training data\n",
        "X_train.shape\n",
        "# Display the coefficients of the model\n",
        "model.coef_\n",
        "# Display the number of coefficients\n",
        "len(model.coef_)\n",
        "# Display the intercept of the model\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "wt9L6VGYShT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data using the trained model\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "b0gobS5uSzXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary metrics from sklearn.metrics (Mean Squared Error and R-squared)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "# Calculate and display the Mean Squared Error (MSE) between actual and predicted values\n",
        "mean_squared_error(y_test, y_pred)\n",
        "# Calculate and display the R-squared score, which indicates the proportion of variance in the target variable that is predictable from the features\n",
        "r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "SHTUaBrbS1wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple linear regression 02"
      ],
      "metadata": {
        "id": "dFDbA6ftTxxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "# Display the dataset object\n",
        "data\n",
        "# Print the description of the dataset\n",
        "print(data.DESCR)\n",
        "# Print the keys of the dataset dictionary\n",
        "data.keys()\n",
        "# Print the target names of the dataset\n",
        "data.target_names\n",
        "# Access and display the feature data\n",
        "data.data\n",
        "# Access and display the names of the features\n",
        "data.feature_names\n",
        "# Create a pandas DataFrame from the feature data, using feature names as columns\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "# Display the DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "u_ruEqjOT2sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the target variable ('Price') as a new column to the DataFrame\n",
        "df['Price'] = data.target\n",
        "# Display information about the DataFrame (column types, non-null values, etc.)\n",
        "df.info()\n",
        "# Display the data types of each column\n",
        "df.dtypes\n",
        "# Display the first 5 rows of the DataFrame\n",
        "df.head()\n",
        "# Display the last 5 rows of the DataFrame\n",
        "df.tail()\n",
        "# Display 3 random rows from the DataFrame\n",
        "df.sample(3)\n",
        "# Check for and display the sum of null values in each column\n",
        "df.isnull().sum()\n",
        "# Display descriptive statistics for the numerical columns\n",
        "df.describe()\n",
        "# Calculate and display the correlation matrix of the DataFrame\n",
        "df.corr()\n",
        "# Create a heatmap visualization of the correlation matrix with annotations\n",
        "sns.heatmap(df.corr(), annot = True)"
      ],
      "metadata": {
        "id": "z7vOrhe8YZ78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the data into independent features (X) and the dependent variable (y)\n",
        "X = df.iloc[:, :-1] #independent var (all columns except the last one)\n",
        "y = df.iloc[:, -1] #dependent variable (the last column, 'Price')\n",
        "# Display the independent features (X)\n",
        "X\n",
        "# Display the dependent variable (y)\n",
        "y"
      ],
      "metadata": {
        "id": "9VmwIyztYzWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing train_test_split function from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# X -> features (independent variables)\n",
        "# y -> target/labels (dependent variable)\n",
        "# test_size = 0.30 → 30% data goes to testing, 70% to training\n",
        "# random_state = 1 → ensures reproducibility (same split every run)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=1)\n",
        "\n",
        "# Checking the shape of the resulting splits\n",
        "# X_train → training features\n",
        "# X_test  → testing features\n",
        "# y_train → training labels\n",
        "# y_test  → testing labels\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "EuR6MURyY-H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing StandardScaler from sklearn.preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Creating an object of StandardScaler\n",
        "# StandardScaler removes the mean and scales the data to unit variance (z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler on X_train and transforming it\n",
        "# fit() → calculates mean & standard deviation from training data\n",
        "# transform() → applies scaling using those values\n",
        "# fit_transform() = fit() + transform() (done in one step)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transforming X_test using the same mean & std from X_train\n",
        "# (Important: we do NOT fit again on test data, to avoid data leakage)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Now X_train and X_test contain standardized values (mean=0, std=1 for training set)\n",
        "X_train\n",
        "X_test\n"
      ],
      "metadata": {
        "id": "pR2YaXb3ZIol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "# Importing LinearRegression model from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Creating an object of LinearRegression\n",
        "model = LinearRegression()\n",
        "\n",
        "# Training the model using training data (X_train, y_train)\n",
        "# .fit() → learns the relationship between features (X_train) and target (y_train)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Checking the shape of X_train\n",
        "# This tells us how many samples (rows) and features (columns) we have\n",
        "X_train.shape\n",
        "\n",
        "# Checking the number of coefficients learned by the model\n",
        "# len(model.coef_) → should equal number of features (columns in X_train)\n",
        "len(model.coef_)\n",
        "\n",
        "# Coefficients of the model\n",
        "# Each coefficient represents the weight assigned to a feature\n",
        "model.coef_\n",
        "\n",
        "# Intercept of the model\n",
        "# This is the constant term (bias) in the linear regression equation\n",
        "model.intercept_\n"
      ],
      "metadata": {
        "id": "ySkKiorbZYjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test set using the trained model\n",
        "\n",
        "# model.predict(X_test) → uses the learned coefficients & intercept\n",
        "# to predict target values for the unseen test features\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "wwMxjoGJZpXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Metrics\n",
        "\n",
        "# Importing different regression performance metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "# Formula: average of (actual - predicted)^2\n",
        "# Punishes larger errors more (because of squaring)\n",
        "print(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "# Formula: average of |actual - predicted|\n",
        "# Gives error in the same unit as target variable\n",
        "print(mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "# Square root of MSE → easier to interpret as it has same unit as target\n",
        "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# R² Score (Coefficient of Determination)\n",
        "# Tells how well model explains the variance in data\n",
        "# R² = 1 → perfect prediction, R² = 0 → model no better than mean\n",
        "score = r2_score(y_test, y_pred)\n",
        "\n",
        "# Adjusted R² Score\n",
        "# Adjusts R² by considering number of features\n",
        "# Formula: 1 - (1 - R²) * (n - 1) / (n - p - 1)\n",
        "# n = number of samples in test set\n",
        "# p = number of features in test set\n",
        "1 - (1 - score) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n"
      ],
      "metadata": {
        "id": "T7KjsLB_ZuHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumption Checking (Residual Analysis)\n",
        "\n",
        "# Scatter plot between actual values (y_test) and predicted values (y_pred)\n",
        "# If predictions are good, points should lie close to a straight diagonal line\n",
        "plt.scatter(y_test, y_pred)\n",
        "\n",
        "# Calculate residuals (errors)\n",
        "# residual = actual - predicted\n",
        "error = y_test - y_pred\n",
        "\n",
        "# Distribution plot of residuals\n",
        "# Ideally residuals should follow a normal distribution (mean ≈ 0)\n",
        "# This helps to validate the linear regression assumptions\n",
        "sns.distplot(error)\n",
        "\n",
        "# Scatter plot between predicted values and residuals\n",
        "# Ideally residuals should be randomly scattered around 0\n",
        "# (No visible pattern → good sign for linear regression assumptions)\n",
        "plt.scatter(y_pred, error)\n"
      ],
      "metadata": {
        "id": "OatNzmc4Z4oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pickling model"
      ],
      "metadata": {
        "id": "3dQVhejndRhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python pickle module is used for serialising and de-serialising a Python object structure. Any object in Python can be pickled so that it can be saved on disk. What pickle does is that it “serialises” the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script\n",
        "\n",
        "pickle>> aloows you to store the python object on the disk\n",
        "serialization : Serialization is the process of converting a data structure or object into a format that can be easily stored, transmitted, or persisted. During serialization, the object's state is converted into a stream of bytes or other formats that can be written to disk, sent over a network, or stored in memory\n",
        "Deserialization>>Deserialization is the process of reconstructing a serialized object back into its original form. During deserialization, the serialized data is read and converted back into a data structure or object that matches the original."
      ],
      "metadata": {
        "id": "teLDIt1bkvHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle   # Importing pickle module for saving/loading Python objects\n",
        "\n",
        "# Saving the trained model into a file named \"model.pkl\"\n",
        "# pickle.dump(object, file, mode)\n",
        "# object = model → the trained LinearRegression model\n",
        "# open(\"model.pkl\", \"wb\") → open file in write-binary mode to store bytes\n",
        "pickle.dump(model, open(\"model.pkl\", \"wb\"))  # write binary mode\n",
        "\n",
        "# Explanation:\n",
        "# Python object (here: model), along with its attributes (coefficients, intercept, etc.)\n",
        "# and methods, is converted into a byte stream and saved into a file.\n",
        "# Later, we can load this model back using pickle.load() without retraining.\n"
      ],
      "metadata": {
        "id": "AA6cTrCOkh7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved model from the file \"model.pkl\"\n",
        "\n",
        "# pickle.load(file) → reads the byte stream and reconstructs the original Python object\n",
        "# open(\"model.pkl\", \"rb\") → open file in read-binary mode\n",
        "model = pickle.load(open(\"model.pkl\", 'rb'))\n",
        "\n",
        "# Now 'model' is the same trained LinearRegression model we saved earlier.\n",
        "# We can directly use it for predictions without retraining.\n"
      ],
      "metadata": {
        "id": "qHELTiYalC39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the loaded model to make predictions on the test set\n",
        "\n",
        "# model.predict(X_test) → applies the learned coefficients & intercept\n",
        "# to the features in X_test and returns predicted values for target variable\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Now y_pred contains the predictions made by the trained (or loaded) model\n"
      ],
      "metadata": {
        "id": "QwIj3clClIH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# polynomial Regression"
      ],
      "metadata": {
        "id": "7WsIy9w7lTk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Generating synthetic feature X\n",
        "# np.random.rand(100,1) → 100 random numbers between 0 and 1\n",
        "# Multiplying by 2 → scales values to range [0, 2)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "X\n",
        "\n",
        "# Generating synthetic target variable y\n",
        "# Formula used: y = 4 + 3*X + 1.5*X^2 + noise\n",
        "# (Here, noise is added using np.random.randn(100,1), which gives normal distribution N(0,1))\n",
        "# This creates a quadratic relationship between X and y\n",
        "y = 4 + 3*X + 1.5*X**2 + np.random.randn(100, 1)\n",
        "y\n"
      ],
      "metadata": {
        "id": "NK3mh89ulXQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "\n",
        "# Importing train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# X = features, y = target\n",
        "# test_size = 0.2 → 20% data goes to testing, 80% to training\n",
        "# random_state = 42 → ensures reproducibility (same split every time)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Checking the shape of training and testing sets\n",
        "# X_train → training features\n",
        "# X_test  → testing features\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "pVO3GxTYoLkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Polynomial Regression\n",
        "\n",
        "# Importing PolynomialFeatures for polynomial transformation\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Degree of the polynomial (here quadratic: x, x^2)\n",
        "degree = 2\n",
        "\n",
        "# Creating polynomial features (without bias term, since LinearRegression adds intercept itself)\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "# Transforming training data into polynomial features\n",
        "# If X_train has column [x], after transformation it becomes [x, x^2]\n",
        "X_poly_train = poly_features.fit_transform(X_train)\n",
        "X_poly_train\n",
        "\n",
        "# Creating LinearRegression model\n",
        "poly_reg = LinearRegression()\n",
        "\n",
        "# Training the model with polynomial features\n",
        "poly_reg.fit(X_poly_train, y_train)\n",
        "\n",
        "# Coefficients learned by the model (for x and x^2 terms)\n",
        "poly_reg.coef_\n",
        "\n",
        "# Intercept (constant term) of the model\n",
        "poly_reg.intercept_\n"
      ],
      "metadata": {
        "id": "QYhA2cd-oV3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making prediction on training data itself\n",
        "\n",
        "# Using the trained polynomial regression model to predict on training set\n",
        "y_poly_predict = poly_reg.predict(X_poly_train)\n",
        "\n",
        "# Importing mean_squared_error for evaluation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculating Mean Squared Error (MSE) on training data\n",
        "# Measures how far predicted values are from actual target values\n",
        "mse_train = mean_squared_error(y_train, y_poly_predict)\n",
        "print(f'Mean Squared Error on Training Data: {mse_train}')\n",
        "\n",
        "# Visualizing the training data\n",
        "# Scatter plot → actual training points (X_train, y_train)\n",
        "plt.scatter(X_train, y_train, label=\"training data\")\n"
      ],
      "metadata": {
        "id": "lE0b6I3Uoqgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Polynomial Regression Curve along with Training Data\n",
        "\n",
        "# Scatter plot of actual training data points\n",
        "plt.scatter(X_train, y_train, label=\"training data\")\n",
        "\n",
        "# Creating a smooth range of X values between 0 and 2 (100 points)\n",
        "# This helps to draw a smooth regression curve\n",
        "X_range = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "\n",
        "# Transforming these X values into polynomial features (x, x^2)\n",
        "X_range_poly = poly_features.transform(X_range)\n",
        "\n",
        "# Plotting the polynomial regression curve\n",
        "# poly_reg.predict(X_range_poly) → predicted y values for the smooth range\n",
        "plt.plot(X_range, poly_reg.predict(X_range_poly), color='red',\n",
        "         label=f'Polynomial Regression (Degree {degree})')\n",
        "\n",
        "# Adding axis labels and title\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression')\n",
        "\n",
        "# Showing legend (training data points vs regression curve)\n",
        "plt.legend()\n",
        "\n",
        "# Displaying the final plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VF02SMo0o05O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multicollenearity"
      ],
      "metadata": {
        "id": "Qx-ZhiwzpvDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading California Housing dataset\n",
        "\n",
        "# fetch_california_housing → built-in dataset in sklearn\n",
        "# Contains features related to California districts and their housing prices\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "# Fetching the dataset (called twice in your code, but one call is enough)\n",
        "data = fetch_california_housing()\n",
        "\n",
        "# Creating a DataFrame from the dataset\n",
        "# data.data → contains the feature values (independent variables)\n",
        "# data.feature_names → column names for the features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Adding the target variable (house price) as a new column 'Price'\n",
        "# data.target → median house value for each district\n",
        "df['Price'] = data.target\n"
      ],
      "metadata": {
        "id": "ffGO2wOZp6_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multicollinearity>> when one feature is explained by all other features(more than 2)\n",
        "#when two features>> correlation\n",
        "#more than two features relationship >> VIF, clustermap"
      ],
      "metadata": {
        "id": "MHg4yBLLwH8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Heatmap of correlation matrix\n",
        "# df.corr() → computes correlation between all pairs of numerical features\n",
        "# annot=True → displays correlation values inside the heatmap cells\n",
        "# vmin=-1, vmax=1 → scale of correlation (from -1 to +1)\n",
        "sns.heatmap(df.corr(), annot=True, vmin=-1, vmax=1)\n",
        "\n",
        "# Clustermap: groups features based on their correlation similarity\n",
        "# This helps to visually identify clusters of features that are highly correlated\n",
        "# figsize → sets the size of the plot\n",
        "plt.figure(figsize=(5, 5))\n",
        "sns.clustermap(df.corr(), vmin=-1, vmax=1, annot=True)\n"
      ],
      "metadata": {
        "id": "ry3exublwKQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Multicollinearity using Variance Inflation Factor (VIF)\n",
        "\n",
        "# Importing variance_inflation_factor function\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a copy of the original DataFrame\n",
        "df1 = df.copy()\n",
        "\n",
        "# Dropping \"Longitude\" column (maybe due to high multicollinearity or not needed)\n",
        "df1.drop(\"Longitude\", axis=1, inplace=True)\n",
        "\n",
        "# Creating empty DataFrame to store VIF results\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Calculating VIF for each feature\n",
        "# variance_inflation_factor(df1.values, i) → calculates VIF for column i\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Display the VIF table\n",
        "vif\n"
      ],
      "metadata": {
        "id": "ut6b9TDnwZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping another feature (\"AveRooms\") from the DataFrame\n",
        "# Reason: It might have high multicollinearity (high VIF) with other features\n",
        "df1.drop(\"AveRooms\", axis=1, inplace=True)\n",
        "\n",
        "# Creating a new DataFrame to store updated VIF results\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding remaining feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Recalculating VIF values for all remaining features\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Displaying the updated VIF table\n",
        "vif\n"
      ],
      "metadata": {
        "id": "-EshZ2IUwsyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping another feature (\"Latitude\") from the DataFrame\n",
        "# Reason: It may have shown high VIF value (high multicollinearity with other features)\n",
        "df1.drop(\"Latitude\", axis=1, inplace=True)\n",
        "\n",
        "# Creating a new DataFrame to store recalculated VIF values\n",
        "vif = pd.DataFrame()\n",
        "\n",
        "# Adding the remaining feature names\n",
        "vif[\"Feature\"] = df1.columns\n",
        "\n",
        "# Recalculating VIF for each remaining feature\n",
        "# variance_inflation_factor(df1.values, i) → calculates VIF for feature at index i\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df1.values, i) for i in range(len(df1.columns))]\n",
        "\n",
        "# Displaying the updated VIF table after dropping \"Latitude\"\n",
        "vif\n"
      ],
      "metadata": {
        "id": "5vvqwmMZwxMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting independent variables (all columns except last one)\n",
        "X = df1.iloc[:, :-1]   # features\n",
        "\n",
        "# Selecting dependent variable (last column → \"Price\")\n",
        "y = df1.iloc[:, -1]    # target\n"
      ],
      "metadata": {
        "id": "FQVhmuEoxfUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFE Elimination"
      ],
      "metadata": {
        "id": "ytKZL8dDy1ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1]   # all independent variables (except last column)\n",
        "y = df.iloc[:, -1]    # last column (dependent variable)\n",
        "X.columns\n"
      ],
      "metadata": {
        "id": "_HTdHpbwy7bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Features\n",
        "X.columns\n",
        "\n",
        "# Apply RFE with Linear Regression\n",
        "rfe = RFE(estimator=LinearRegression(), n_features_to_select=5)\n",
        "rfe.fit(X, y)\n",
        "\n",
        "# Predictions (not needed for feature selection, but works)\n",
        "rfe.predict(X)\n"
      ],
      "metadata": {
        "id": "mKgqt0fpzOb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean mask: True = selected\n",
        "print(rfe.support_)\n",
        "\n",
        "# Ranking of features (1 = selected, higher = eliminated earlier)\n",
        "print(rfe.ranking_)\n",
        "\n",
        "# Get the actual selected feature names\n",
        "selected_features = X.columns[rfe.support_]\n",
        "print(\"Selected Features:\", selected_features.tolist())\n"
      ],
      "metadata": {
        "id": "kjTnu2HIzoqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lasso ,ridge and elsticnet inplementation"
      ],
      "metadata": {
        "id": "YKDMFzESz0it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'mpg' dataset directly from seaborn's built-in datasets\n",
        "df = sns.load_dataset('mpg')\n",
        "\n",
        "# Show the first 5 rows of the dataset to quickly inspect its structure\n",
        "df.head()\n",
        "\n",
        "# Drop the \"name\" column from the dataframe, since it is categorical text and not needed for modeling\n",
        "# axis = 1 → column-wise drop, inplace=True → modify original dataframe directly\n",
        "df.drop(\"name\", axis = 1, inplace = True)\n",
        "\n",
        "# Check how many missing values (NaN) each column contains\n",
        "df.isna().sum()\n",
        "\n",
        "# Find the median value of the 'horsepower' column (used for filling missing values)\n",
        "df['horsepower'].median()\n",
        "\n",
        "# Fill missing values in 'horsepower' column with its median (better than mean in case of skewed data)\n",
        "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
        "\n",
        "# Check again for missing values after filling\n",
        "df.isna().sum()\n",
        "\n",
        "# Display summary information of the dataframe:\n",
        "# - Number of entries\n",
        "# - Column names\n",
        "# - Data types\n",
        "# - Non-null counts\n",
        "df.info()\n",
        "\n",
        "# Get data types of each column (as a Series object)\n",
        "df.dtypes\n",
        "\n",
        "# Count frequency of each unique value in the 'origin' column\n",
        "# (origin shows country of manufacture: 'usa', 'japan', 'europe')\n",
        "df['origin'].value_counts()\n",
        "\n",
        "# Convert categorical string values of 'origin' into numeric mapping:\n",
        "# 'usa' → 1, 'japan' → 2, 'europe' → 3\n",
        "df['origin'] = df['origin'].map({'usa': 1, \"japan\": 2, \"europe\": 3})\n",
        "\n",
        "# Explicitly set the 'origin' column data type to integer\n",
        "df['origin'] = df['origin'].astype(int)\n"
      ],
      "metadata": {
        "id": "87Tytcs-0xtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (independent variables) and target (dependent variable)\n",
        "\n",
        "# Create X (features): drop the 'mpg' column from df\n",
        "# axis = 1 → drop column, not row\n",
        "X = df.drop('mpg', axis=1)\n",
        "\n",
        "# Create y (target): select only the 'mpg' column (this is the value we want to predict)\n",
        "y = df['mpg']\n",
        "\n",
        "# Display the feature matrix (all columns except 'mpg')\n",
        "X\n",
        "\n",
        "# Display the target vector (only 'mpg')\n",
        "y\n"
      ],
      "metadata": {
        "id": "EDLAt0H1OzSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function for splitting dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# X → features, y → target\n",
        "# test_size = 0.3 → 30% data for testing, 70% for training\n",
        "# random_state = 1 → ensures same random split every time (reproducibility)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "\n",
        "# Show the shape (rows, columns) of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "HU0CJhSVPB2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LinearRegression model from sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an object (instance) of LinearRegression class\n",
        "# This object will represent our regression model\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Just displaying the model object (optional, shows its parameters)\n",
        "regression_model\n",
        "\n",
        "# Train (fit) the regression model using training data\n",
        "# X_train → input features, y_train → target variable\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Loop through each feature column to print its coefficient\n",
        "# enumerate(X_train.columns) → gives index (i) and column name (col_name)\n",
        "# regression_model.coef_[i] → coefficient value for that feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {regression_model.coef_[i]}\")\n"
      ],
      "metadata": {
        "id": "9-BQ2-W1Pw0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficients are relatively smaller, if one independent variable changes\n",
        "slightly there will be not much difference in prediction.\n",
        "This is sometime is called smoother model"
      ],
      "metadata": {
        "id": "o9XXlY3iP72C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import r2_score metric from sklearn\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Use the trained regression model to make predictions on the test dataset\n",
        "# X_test → unseen features (30% data), y_pred_linear → predicted mpg values\n",
        "y_pred_linear = regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R² score (coefficient of determination)\n",
        "# y_test → actual mpg values, y_pred_linear → predicted mpg values\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "# Print the R² score in a formatted string\n",
        "print(f\"R square of linear regression {r2_linear}\")\n"
      ],
      "metadata": {
        "id": "tBNDoZTAQd8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge regression\n",
        "from sklearn.linear_model import Ridge              # importing Ridge class from sklearn.linear_model\n",
        "ridge_regression_model = Ridge(alpha = 0.1)         # creating a Ridge Regression model with regularization strength (alpha) = 0.1\n",
        "ridge_regression_model.fit(X_train, y_train)        # training the Ridge Regression model using training features and labels\n",
        "\n",
        "# printing coefficients for each feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {ridge_regression_model.coef_[i]}\")\n",
        "\n",
        "# Use the trained Ridge Regression model to make predictions on the test set\n",
        "y_pred_ridge = ridge_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score to check how well model predictions match actual values\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "# Print the R² score (goodness of fit measure)\n",
        "print(f\"R-squared score for Ridge Regression: {r2_ridge}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "848SZT1_QpSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We dont see much variation in coeff of ridge regression as compared to linear regression"
      ],
      "metadata": {
        "id": "-37tbKfXRHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso Regression model\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Create a Lasso Regression model with alpha = 0.5 (regularization strength)\n",
        "lasso_regression_model = Lasso(alpha = 0.5)\n",
        "\n",
        "# Train (fit) the Lasso model on training data\n",
        "lasso_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Loop through each feature column and print its coefficient\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {lasso_regression_model.coef_[i]}\")\n",
        "\n",
        "# Predict target values on the test set using the trained Lasso model\n",
        "y_pred_lasso = lasso_regression_model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score for Lasso predictions\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "# Print the R² score of the Lasso model\n",
        "print(f\"R-squared score for Lasso Regression: {r2_lasso}\")\n"
      ],
      "metadata": {
        "id": "AInxYQ7tR-cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 features coefficients are 0, Lasso helps in feature selection"
      ],
      "metadata": {
        "id": "lV6XKHkQSM88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ElasticNet Regression\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Create ElasticNet model (alpha = regularization strength, l1_ratio = balance between Lasso & Ridge)\n",
        "elastic_net_model = ElasticNet(alpha = 1, l1_ratio = 0.5)\n",
        "\n",
        "# Train the model on training data\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "\n",
        "# Print coefficients for each feature\n",
        "for i, col_name in enumerate(X_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is {elastic_net_model.coef_[i]}\")\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_elastic_net = elastic_net_model.predict(X_test)\n",
        "\n",
        "# Evaluate model with R² score\n",
        "r2_elastic_net = r2_score(y_test, y_pred_elastic_net)\n",
        "print(f\"R-squared score for Elastic Net Regression: {r2_elastic_net}\")\n"
      ],
      "metadata": {
        "id": "XdeMTkZPScH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- LASSO REGRESSION WITH CROSS VALIDATION --------------------\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# LassoCV = Lasso regression + automatic alpha tuning using cross-validation\n",
        "# cv=5 → Perform 5-fold cross-validation to find the best alpha\n",
        "lassocv = LassoCV(cv=5)\n",
        "\n",
        "# Train the model on training data\n",
        "lassocv.fit(X_train, y_train)\n",
        "\n",
        "# Predict target values for the test dataset\n",
        "y_pred_lassocv = lassocv.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using R-squared score\n",
        "score_lassocv = r2_score(y_test, y_pred_lassocv)\n",
        "\n",
        "# Print the best alpha chosen automatically after CV\n",
        "print(\"Best alpha chosen by LassoCV:\", lassocv.alpha_)\n",
        "\n",
        "# Print the final R2 Score\n",
        "print(\"R2 Score (LassoCV):\", score_lassocv)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- RIDGE REGRESSION WITH CROSS VALIDATION --------------------\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "# RidgeCV = Ridge regression + automatic alpha tuning using cross-validation\n",
        "# cv=5 → Perform 5-fold cross-validation\n",
        "ridgecv = RidgeCV(cv=5)\n",
        "\n",
        "# Train the Ridge model\n",
        "ridgecv.fit(X_train, y_train)\n",
        "\n",
        "# Predict target values for the test dataset\n",
        "y_pred_ridgecv = ridgecv.predict(X_test)\n",
        "\n",
        "# Evaluate model performance using R-squared score\n",
        "score_ridgecv = r2_score(y_test, y_pred_ridgecv)\n",
        "\n",
        "# Print the best alpha chosen automatically after CV\n",
        "print(\"Best alpha chosen by RidgeCV:\", ridgecv.alpha_)\n",
        "\n",
        "# Print the final R2 Score\n",
        "print(\"R2 Score (RidgeCV):\", score_ridgecv)\n",
        "\n",
        "# Print all hyperparameters of the trained RidgeCV model\n",
        "print(\"RidgeCV Parameters:\", ridgecv.get_params())\n"
      ],
      "metadata": {
        "id": "jNzo3KPTSybf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# logistic regression implementation 01"
      ],
      "metadata": {
        "id": "do_9g7mgTlBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT & LOAD IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load the built-in Iris dataset from sklearn\n",
        "data = load_iris()\n",
        "\n",
        "# Show all keys available in the dataset object\n",
        "# (like data, target, feature_names, DESCR, etc.)\n",
        "print(data.keys())\n",
        "\n",
        "# Print the description of the dataset\n",
        "# (contains details about features, targets, citations, etc.)\n",
        "print(data.DESCR)\n",
        "\n",
        "# Features (independent variables) → numerical values of measurements\n",
        "# Each row = 1 flower sample, Columns = sepal/petal length & width\n",
        "print(data.data)\n",
        "\n",
        "# Target (dependent variable) → species labels (0 = setosa, 1 = versicolor, 2 = virginica)\n",
        "print(data.target)\n",
        "\n",
        "# Feature names (column labels for the dataset)\n",
        "print(data.feature_names)\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "# Convert data into pandas DataFrame for easy exploration\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target column (species labels) to the DataFrame\n",
        "df['target'] = data.target\n",
        "\n",
        "# Show first 5 rows of dataset\n",
        "print(df.head())\n",
        "\n",
        "# Show last 5 rows of dataset\n",
        "print(df.tail())\n",
        "\n",
        "# Show 2 random rows (for sampling)\n",
        "print(df.sample(2))\n",
        "\n",
        "# Show unique values in the target column (which species classes exist)\n",
        "print(df['target'].unique())\n"
      ],
      "metadata": {
        "id": "l7b3_fy4Tssq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- BINARY CLASSIFICATION SETUP --------------------\n",
        "\n",
        "# Create a new dataframe by removing rows where target = 2 (Virginica)\n",
        "# So only Setosa (0) and Versicolor (1) remain\n",
        "df_final = df[df['target'] != 2]\n",
        "\n",
        "# Check unique target values (should be [0,1])\n",
        "print(df_final.target.unique())\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "# X = all columns except last one (features)\n",
        "X = df_final.iloc[:, :-1]\n",
        "\n",
        "# y = only last column (target labels)\n",
        "y = df_final.iloc[:, -1]\n",
        "\n",
        "# Display X (independent variables)\n",
        "print(X)\n",
        "\n",
        "# Display y (dependent variable)\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "Ea0PU0oHUYCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# X → features, y → target labels\n",
        "# test_size = 0.20 → 20% data for testing, 80% for training\n",
        "# random_state = 1 → ensures the split is reproducible\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Show the shape (rows, columns) of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "ANGk9TvbVI2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- LOGISTIC REGRESSION MODEL TRAINING --------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a Logistic Regression classifier object\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# Train the classifier on training data (X_train features and y_train labels)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict target labels for the test dataset\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# Predict probabilities for each class (0 or 1) for the test set\n",
        "# Logistic Regression predicts probabilities and then assigns the class with higher probability\n",
        "# Default cutoff = 0.5 → if P(class=1) > 0.5, predicted label = 1\n",
        "classifier.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "zQs74wphVaF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → gives precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Notes on the classification report:\n",
        "# - First two rows (class 0 and 1) → precision, recall, f1-score, support for each class\n",
        "# - macro avg → simple average of metrics for all classes (ignores class imbalance)\n",
        "# - weighted avg → average weighted by number of samples in each class (important for imbalanced data)\n"
      ],
      "metadata": {
        "id": "dY9jQMNWV3G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- ROC CURVE & AUC --------------------\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class (class = 1)\n",
        "# predict_proba() returns two columns → [:,1] selects probability for class 1\n",
        "y_pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate False Positive Rate (FPR), True Positive Rate (TPR), and thresholds for ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "roc_auc\n"
      ],
      "metadata": {
        "id": "hOPZwbO4WYmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PLOT ROC-AUC CURVE --------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure of size 8x6 inches\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the ROC curve\n",
        "# fpr → x-axis (False Positive Rate)\n",
        "# tpr → y-axis (True Positive Rate)\n",
        "# color='darkorange', linewidth=2 → styling\n",
        "# label → shows AUC value in legend\n",
        "plt.plot(fpr, tpr, color='darkorange', linewidth=2,\n",
        "         label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "# Plot diagonal line representing random guessing (baseline)\n",
        "plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--')\n",
        "\n",
        "# Set x-axis limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "\n",
        "# Set y-axis limits slightly above 1 to give space for plot\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Set x-axis label\n",
        "plt.xlabel('False Positive Rate')\n",
        "\n",
        "# Set y-axis label\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "# Display legend at lower-right\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Render the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GajnuqLGWul1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CROSS VALIDATION USING K-FOLD --------------------\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a KFold object for splitting data into 5 folds\n",
        "# n_splits=5 → dataset is divided into 5 equal parts\n",
        "# shuffle=False → data is not shuffled before splitting (default)\n",
        "cv = KFold(n_splits=5)\n",
        "cv  # Display KFold object\n",
        "\n",
        "# Perform cross-validation using the classifier\n",
        "# classifier → trained Logistic Regression model\n",
        "# X_train, y_train → training features and labels\n",
        "# cv=cv → KFold splits\n",
        "# scoring=\"accuracy\" → evaluates accuracy on each fold\n",
        "scores = cross_val_score(classifier, X_train, y_train, cv=cv, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate mean accuracy across all folds\n",
        "np.mean(scores)\n"
      ],
      "metadata": {
        "id": "TaYR7OxvW93o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION 02"
      ],
      "metadata": {
        "id": "90OM3GJQX0mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- GENERATE SYNTHETIC DATASET --------------------\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic classification dataset\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_redundant=5 → 5 features are redundant (linear combination of informative)\n",
        "# n_informative=5 → 5 features actually useful for prediction\n",
        "# n_classes=2 → binary classification\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=2, random_state=1)\n",
        "\n",
        "# Display feature matrix\n",
        "X\n",
        "\n",
        "# Display target labels\n",
        "y\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "# Split synthetic dataset into training and testing sets\n",
        "# test_size=0.30 → 30% data for testing, 70% for training\n",
        "# random_state=1 → reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# -------------------- LOGISTIC REGRESSION MODEL --------------------\n",
        "# Create a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model  # Display model object\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict target labels for test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred  # Display predictions\n"
      ],
      "metadata": {
        "id": "dxJeJ62-X49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → gives precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Notes on the classification report:\n",
        "# - First two rows (class 0 and 1) → precision, recall, f1-score, support for each class\n",
        "# - macro avg → simple average across classes (ignores class imbalance)\n",
        "# - weighted avg → average weighted by number of samples in each class (important for imbalanced data)\n"
      ],
      "metadata": {
        "id": "f9W2wCLRY5Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- ROC CURVE & AUC --------------------\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate False Positive Rate (FPR), True Positive Rate (TPR), and thresholds\n",
        "# y_test → true labels\n",
        "# y_pred_proba → predicted probabilities for the positive class (class 1)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate Area Under the Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# -------------------- PLOT ROC CURVE --------------------\n",
        "plt.figure(figsize=(8, 6))  # Set figure size\n",
        "\n",
        "# Plot ROC curve: TPR vs FPR\n",
        "# color='darkorange', linewidth=2 → styling\n",
        "# label → shows AUC value on the legend\n",
        "plt.plot(fpr, tpr, color='darkorange', linewidth=2,\n",
        "         label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "# Plot diagonal line representing random guessing\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "# Set axis limits\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "# Set axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Set plot title\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "# Add legend at lower-right\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OMW3A_IOZV7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#precision recall accuracy tradeoff to decide optimal thrshold\n",
        "#by default sklean 0.5 uses as threshold"
      ],
      "metadata": {
        "id": "jKy2aiI4ZkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PRECISION, RECALL & ACCURACY VS THRESHOLD --------------------\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define thresholds from 0 to 1 (100 points)\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "\n",
        "# Lists to store metric values for each threshold\n",
        "precisions = []\n",
        "recalls = []\n",
        "accuracies = []\n",
        "\n",
        "# Loop through each threshold\n",
        "for threshold in thresholds:\n",
        "    # Convert predicted probabilities to binary labels based on threshold\n",
        "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    # Calculate precision at this threshold\n",
        "    precision = precision_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Calculate recall at this threshold\n",
        "    recall = recall_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Calculate accuracy at this threshold\n",
        "    accuracy = accuracy_score(y_test, y_pred_threshold)\n",
        "\n",
        "    # Store values\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# -------------------- PLOT METRICS --------------------\n",
        "plt.figure(figsize=(10, 6))  # Set figure size\n",
        "\n",
        "# Plot Precision vs Threshold\n",
        "plt.plot(thresholds, precisions, label='Precision')\n",
        "\n",
        "# Plot Recall vs Threshold\n",
        "plt.plot(thresholds, recalls, label='Recall')\n",
        "\n",
        "# Plot Accuracy vs Threshold\n",
        "plt.plot(thresholds, accuracies, label='Accuracy')\n",
        "\n",
        "# Set axis labels and title\n",
        "plt.xlabel('Threshold Probability')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision, Recall, and Accuracy vs. Threshold Probability')\n",
        "\n",
        "# Add legend and grid\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z-fWJzpYZnuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#observation>> cutoff =0.4\n"
      ],
      "metadata": {
        "id": "v6uvZUMJZz5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CUSTOM THRESHOLD PREDICTIONS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Convert predicted probabilities to binary labels using threshold = 0.4\n",
        "# If probability > 0.4 → classify as 1, else 0\n",
        "new_pred_levels = np.where(y_pred_proba > 0.4, 1, 0)\n",
        "\n",
        "# Confusion matrix → shows counts of True Positive, True Negative, False Positive, False Negative\n",
        "print(confusion_matrix(y_test, new_pred_levels))\n",
        "\n",
        "# Accuracy score → fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, new_pred_levels))\n",
        "\n",
        "# Classification report → precision, recall, f1-score, support for each class\n",
        "print(classification_report(y_test, new_pred_levels))\n"
      ],
      "metadata": {
        "id": "c9EtXKAoZ3vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- K-FOLD CROSS VALIDATION --------------------\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Create a K-Fold cross-validator\n",
        "# n_splits=5 → split the data into 5 folds\n",
        "# Each fold will be used once as a validation set while the remaining 4 folds form the training set\n",
        "cv = KFold(n_splits=5)\n",
        "\n",
        "# Perform cross-validation\n",
        "# cross_val_score → evaluates model performance for each fold\n",
        "# model → Logistic Regression model\n",
        "# X_train, y_train → training data\n",
        "# cv=cv → cross-validation strategy (here, 5-fold)\n",
        "acc = cross_val_score(model, X_train, y_train, cv=cv)\n",
        "\n",
        "# Display accuracy for each fold\n",
        "acc\n",
        "\n",
        "# Compute mean accuracy across all folds\n",
        "np.mean(acc)\n"
      ],
      "metadata": {
        "id": "fuIGqrFnaD-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOGISTIC REGRESSION 03"
      ],
      "metadata": {
        "id": "xWRZmW2EafAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LIBRARIES --------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------- CREATE SYNTHETIC CLASSIFICATION DATA --------------------\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_informative=5 → 5 features are actually informative\n",
        "# n_redundant=5 → 5 features are linear combinations of informative features\n",
        "# n_classes=2 → binary classification\n",
        "# random_state=1 → reproducible dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=2, random_state=1)\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "# test_size=0.30 → 30% data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n"
      ],
      "metadata": {
        "id": "0Ige3GZLanGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "#GridSearchCV"
      ],
      "metadata": {
        "id": "ECGFKjaEbEkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT GRIDSEARCHCV --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- DEFINE HYPERPARAMETERS --------------------\n",
        "# 'penalty' → type of regularization (l1, l2, elasticnet)\n",
        "# 'C' → inverse of regularization strength (higher C = less regularization)\n",
        "params = {'penalty': ('l1', 'l2', 'elasticnet'), 'C': [1, 2, 10, 20, 30, 40]}\n",
        "\n",
        "# Create a base Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# -------------------- GRID SEARCH --------------------\n",
        "# GridSearchCV → searches for best hyperparameter combination\n",
        "# cv=5 → 5-fold cross-validation\n",
        "clf = GridSearchCV(classifier, param_grid=params, cv=5)\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the best combination of hyperparameters\n",
        "clf.best_params_\n",
        "\n",
        "# Get the best cross-validated score\n",
        "clf.best_score_\n",
        "\n",
        "# -------------------- FINAL MODEL WITH BEST PARAMETERS --------------------\n",
        "# Create Logistic Regression model with best parameters from grid search\n",
        "model = LogisticRegression(C=1, penalty='l2')\n",
        "\n",
        "# Fit model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict class labels on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Predict probabilities for each class (0 and 1)\n",
        "model.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "HuL46Of7bHWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# -------------------- CONFUSION MATRIX --------------------\n",
        "# Compare actual labels (y_test) vs predicted labels (y_pred)\n",
        "# Returns a 2x2 matrix for binary classification:\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------- ACCURACY SCORE --------------------\n",
        "# Fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------- CLASSIFICATION REPORT --------------------\n",
        "# Gives precision, recall, f1-score, and support for each class\n",
        "# precision → fraction of predicted positives that are correct\n",
        "# recall → fraction of actual positives correctly predicted\n",
        "# f1-score → harmonic mean of precision & recall\n",
        "# support → number of actual occurrences of the class in dataset\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "p5Gl89ozbytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#randomized search cv, it will take randomly some combination"
      ],
      "metadata": {
        "id": "NYTD88O1cFcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT RANDOMIZEDSEARCHCV --------------------\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- RANDOMIZED SEARCH SETUP --------------------\n",
        "# RandomizedSearchCV → searches for best hyperparameters by sampling a given number of combinations randomly\n",
        "# param_distributions = params → grid of hyperparameters to sample from\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# n_iter=10 → number of parameter settings sampled\n",
        "randomized_clf = RandomizedSearchCV(classifier, param_distributions=params, cv=5, n_iter=10)\n",
        "\n",
        "# Fit RandomizedSearchCV on training data\n",
        "randomized_clf.fit(X_train, y_train)\n",
        "\n",
        "# Best cross-validated score from random search\n",
        "randomized_clf.best_score_\n",
        "\n",
        "# Best hyperparameters from random search\n",
        "randomized_clf.best_params_\n",
        "\n",
        "# -------------------- FINAL MODEL WITH BEST PARAMETERS --------------------\n",
        "# Use optimal parameters (example: C=10, penalty='l2') from RandomizedSearchCV\n",
        "model = LogisticRegression(C=10, penalty='l2')\n",
        "\n",
        "# Fit final model on training data\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "fjzxcg7bcGb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULTICLASS CLASSIFICATION"
      ],
      "metadata": {
        "id": "EuCKTc7RclJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LIBRARIES --------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore warnings for cleaner output\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# -------------------- CREATE SYNTHETIC MULTI-CLASS DATA --------------------\n",
        "# n_samples=1000 → total 1000 samples\n",
        "# n_features=10 → 10 features\n",
        "# n_informative=5 → 5 features actually informative\n",
        "# n_redundant=5 → 5 features are linear combinations of informative features\n",
        "# n_classes=3 → 3 classes (multi-class classification)\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=10,\n",
        "                           n_redundant=5, n_informative=5,\n",
        "                           n_classes=3, random_state=1)\n",
        "\n",
        "# Display target vector\n",
        "y\n",
        "\n",
        "# Display feature matrix\n",
        "X\n"
      ],
      "metadata": {
        "id": "lbB_-Gk3csxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CREATE OVR LOGISTIC REGRESSION MODEL --------------------\n",
        "# multi_class='ovr' → One-vs-Rest strategy (fits one classifier per class)\n",
        "# solver='lbfgs' → optimization algorithm used for fitting the model\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs')\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training (70%) and testing (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shapes of training and testing sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the OvR Logistic Regression model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Display predicted class labels\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "qgc1IhvEdl6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "fJGMJxEEeDMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g_5cRYWGeEOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# -------------------- CREATE MULTINOMIAL LOGISTIC REGRESSION MODEL --------------------\n",
        "# multi_class='multinomial' → directly models multiple classes simultaneously\n",
        "# solver='lbfgs' → optimization algorithm that supports multinomial logistic regression\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Display model\n",
        "model\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train multinomial logistic regression on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels for test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Confusion matrix → shows counts of correct/incorrect predictions for each class\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Accuracy → fraction of correct predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Classification report → precision, recall, f1-score, support for each class\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "GCBlfDs7eH-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#roc auc is only for binary classification problem"
      ],
      "metadata": {
        "id": "R6MVF9zoeOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MULTICLASS CLASSIFICATION WITH IRIS IMPLEMENTATION"
      ],
      "metadata": {
        "id": "0JV1lgSMecAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset from sklearn\n",
        "data = load_iris()\n",
        "\n",
        "# Check available keys in the dataset dictionary\n",
        "data.keys()\n",
        "\n",
        "# Print dataset description\n",
        "print(data.DESCR)\n",
        "\n",
        "# Feature matrix (4 columns: sepal length, sepal width, petal length, petal width)\n",
        "data.data\n",
        "\n",
        "# Target vector (species encoded as 0, 1, 2)\n",
        "data.target\n",
        "\n",
        "# Feature names\n",
        "data.feature_names\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame with features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target column to the DataFrame\n",
        "df['target'] = data.target\n",
        "\n",
        "# Display entire DataFrame\n",
        "df\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head()\n",
        "\n",
        "# Show last 5 rows\n",
        "df.tail()\n",
        "\n",
        "# Show 2 random rows\n",
        "df.sample(2)\n",
        "\n",
        "# Check unique classes in target\n",
        "df.target.unique()\n"
      ],
      "metadata": {
        "id": "s14OmAz_er5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for binary classification\n",
        "# df_final =  df[df['target'] != 2]"
      ],
      "metadata": {
        "id": "DazUS9zdfefn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- CHECK UNIQUE TARGET CLASSES --------------------\n",
        "df.target.unique()  # Returns [0, 1, 2] → 3 classes in Iris dataset\n",
        "\n",
        "# -------------------- SEPARATE FEATURES AND TARGET --------------------\n",
        "X = df.iloc[:, :-1]  # All columns except last → features\n",
        "y = df.iloc[:, -1]   # Last column → target\n",
        "\n",
        "# Display features\n",
        "X\n",
        "\n",
        "# Display target\n",
        "y\n",
        "\n",
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset: 80% training, 20% testing, random_state=1 ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# Check shapes of training and testing sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "DjyL0XiWfhDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT LOGISTIC REGRESSION --------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create Logistic Regression classifier\n",
        "# max_iter=300 → maximum number of iterations for solver to converge\n",
        "classifier = LogisticRegression(max_iter=300)\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the model using training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict class labels on test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Display predicted class labels\n",
        "y_pred\n",
        "\n",
        "# -------------------- PREDICT PROBABILITIES --------------------\n",
        "# Predict probabilities for each class for the test set\n",
        "# Output shape → (n_samples, n_classes)\n",
        "classifier.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "8Op-2npyf98-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT EVALUATION METRICS --------------------\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# -------------------- CONFUSION MATRIX --------------------\n",
        "# Shows number of correct and incorrect predictions for each class\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -------------------- ACCURACY --------------------\n",
        "# Fraction of correct predictions over total predictions\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------- CLASSIFICATION REPORT --------------------\n",
        "# Includes precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "NV6mL_GKgcSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DECISION TREE CLASSIFICATION"
      ],
      "metadata": {
        "id": "-7V_FPgyh4rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT IRIS DATASET --------------------\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Print full description of dataset\n",
        "# This includes information about features, target, and classes\n",
        "print(data.DESCR)\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "import pandas as pd\n",
        "\n",
        "# Create DataFrame from feature data\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df  # Display all rows of feature data\n",
        "\n",
        "# -------------------- TARGET VECTOR --------------------\n",
        "# Access target (species labels: 0, 1, 2)\n",
        "data.target\n",
        "\n",
        "# -------------------- SEPARATE FEATURES AND TARGET --------------------\n",
        "X = df          # Feature matrix\n",
        "y = data.target # Target vector\n",
        "\n",
        "# Display features and target\n",
        "X\n",
        "y\n"
      ],
      "metadata": {
        "id": "LDdrShuPh6RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "# test_size=0.3 → 30% of data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# -------------------- DECISION TREE CLASSIFIER --------------------\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create Decision Tree classifier using 'entropy' as criterion (information gain)\n",
        "classifier = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "# Display classifier object\n",
        "classifier\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "# Train the Decision Tree on the training set\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "CsyTiBQBiwsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TREE PLOTTING --------------------\n",
        "from sklearn import tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------- PLOT ORIGINAL TREE --------------------\n",
        "plt.figure(figsize=(12, 10))  # Set figure size\n",
        "# Visualize the trained decision tree\n",
        "tree.plot_tree(classifier, filled=True)\n",
        "\n",
        "# -------------------- POST-PRUNING --------------------\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Restrict tree growth using max_depth (post-pruning)\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "\n",
        "# Fit pruned tree to training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Plot pruned tree\n",
        "plt.figure(figsize=(12, 10))\n",
        "tree.plot_tree(classifier, filled=True)\n",
        "\n",
        "# -------------------- PREDICTION --------------------\n",
        "# Predict on test set using pruned tree\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Calculate accuracy\n",
        "score = accuracy_score(y_pred, y_test)\n",
        "print(score)\n",
        "\n",
        "# Generate detailed classification metrics\n",
        "print(classification_report(y_pred, y_test))\n",
        "\n",
        "# -------------------- PRE-PRUNING HYPERPARAMETER SETUP --------------------\n",
        "# Parameters for GridSearchCV / hyperparameter tuning\n",
        "parameter = {\n",
        "    'criterion': ['gini', 'entropy', 'log_loss'],  # Split criteria\n",
        "    'splitter': ['best', 'random'],                # Node splitting strategy\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6],              # Max tree depth\n",
        "    'max_features': ['sqrt', 'log2', 'auto']      # Number of features to consider at split\n",
        "}\n"
      ],
      "metadata": {
        "id": "U6bemrumjGXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT GRID SEARCH --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# -------------------- CREATE DECISION TREE --------------------\n",
        "clf = DecisionTreeClassifier()  # Basic Decision Tree classifier without hyperparameters\n",
        "\n",
        "# -------------------- GRID SEARCH SETUP --------------------\n",
        "# GridSearchCV will try all combinations of hyperparameters in `parameter`\n",
        "# cv=5 → 5-fold cross-validation to evaluate each combination\n",
        "# scoring='accuracy' → metric used to choose best hyperparameters\n",
        "model = GridSearchCV(clf, param_grid=parameter, cv=5, scoring='accuracy')\n",
        "\n",
        "# -------------------- FIT GRID SEARCH --------------------\n",
        "# Finds the best hyperparameter combination using training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -------------------- BEST PARAMETERS AND SCORE --------------------\n",
        "# Best combination of hyperparameters found\n",
        "model.best_params_\n",
        "\n",
        "# Best cross-validated accuracy score achieved\n",
        "model.best_score_\n"
      ],
      "metadata": {
        "id": "zrHQYjE_jvla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DECISION TREE REGRESSOR"
      ],
      "metadata": {
        "id": "o2fCipgWkPLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT DATASET --------------------\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "# -------------------- LOAD DATASET --------------------\n",
        "data = fetch_california_housing()  # Fetch California housing dataset from sklearn\n",
        "\n",
        "# -------------------- CREATE DATAFRAME --------------------\n",
        "# Convert dataset into a pandas DataFrame for easier handling\n",
        "# data.data → features\n",
        "# data.feature_names → column names for features\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Add target variable (Price) as a new column\n",
        "df['Price'] = data.target\n",
        "\n",
        "# Display DataFrame\n",
        "df\n",
        "\n",
        "# Check shape of DataFrame (rows, columns)\n",
        "df.shape\n"
      ],
      "metadata": {
        "id": "8AU_eq6akZtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- SAMPLE DATA --------------------\n",
        "# Take 20% of the dataset randomly for faster processing\n",
        "df = df.sample(frac=0.20)\n",
        "\n",
        "# Check new shape after sampling\n",
        "df.shape\n",
        "\n",
        "# Display sampled DataFrame\n",
        "df\n",
        "\n",
        "# -------------------- SPLIT INDEPENDENT AND DEPENDENT VARIABLES --------------------\n",
        "# X → all columns except last (features)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "# y → last column (target)\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Display feature set\n",
        "X\n",
        "\n",
        "# Display target variable\n",
        "y\n"
      ],
      "metadata": {
        "id": "BUDW1AQblEYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TRAIN-TEST SPLIT --------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------- SPLIT DATA --------------------\n",
        "# Split dataset into training and testing sets\n",
        "# test_size=0.2 → 20% data for testing, 80% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# -------------------- IMPORT DECISION TREE REGRESSOR --------------------\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# -------------------- CREATE MODEL --------------------\n",
        "model = DecisionTreeRegressor()  # Basic Decision Tree Regressor\n",
        "\n",
        "# Display model info\n",
        "model\n",
        "\n",
        "# -------------------- FIT MODEL --------------------\n",
        "model.fit(X_train, y_train)  # Train model on training data\n",
        "\n",
        "# -------------------- PREDICT ON TEST DATA --------------------\n",
        "y_pred = model.predict(X_test)  # Predict target values for test features\n",
        "\n",
        "# Display predictions\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "Jtm0wEPelcuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT R2 SCORE --------------------\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Evaluate model performance using R-squared\n",
        "# Note: y_test should be first argument, y_pred second, but here swapped\n",
        "r2_score(y_pred, y_test)\n",
        "\n",
        "# -------------------- HYPERPARAMETER TUNING --------------------\n",
        "# Define a parameter grid for GridSearchCV to find best hyperparameters\n",
        "parameter = {\n",
        "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],  # split quality measure\n",
        "    'splitter': ['best', 'random'],  # strategy to choose split at each node\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6],  # maximum depth of tree to avoid overfitting\n",
        "    'max_features': ['auto', 'sqrt', 'log2']  # max features considered for each split\n",
        "}\n",
        "\n",
        "# Create a DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor()\n",
        "\n",
        "# -------------------- GRID SEARCH CROSS VALIDATION --------------------\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# GridSearchCV automatically tests all combinations of parameters and selects the best one\n",
        "# cv=3 → 3-fold cross-validation\n",
        "# scoring='neg_mean_squared_error' → evaluate using negative MSE\n",
        "model = GridSearchCV(regressor, param_grid=parameter, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Display best parameters found\n",
        "model.best_params_\n",
        "\n",
        "# -------------------- CREATE FINAL MODEL --------------------\n",
        "# Use the best parameters found from GridSearchCV\n",
        "final_model = DecisionTreeRegressor(\n",
        "    criterion='poisson',\n",
        "    max_depth=6,\n",
        "    max_features='auto',\n",
        "    splitter='best'\n",
        ")\n",
        "\n",
        "# Train the final model on the full training set\n",
        "final_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "dBlDPOkvl6v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT TREE MODULE --------------------\n",
        "from sklearn import tree\n",
        "\n",
        "# -------------------- CREATE PLOT --------------------\n",
        "plt.figure(figsize=(12, 10))  # Set figure size for better readability\n",
        "\n",
        "# Plot the trained decision tree (final_model)\n",
        "# filled=True → nodes are colored according to the predicted value\n",
        "tree.plot_tree(final_model, filled=True)\n"
      ],
      "metadata": {
        "id": "eaVYNIXgnBll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- PREDICTION --------------------\n",
        "# Use the trained model to predict target values for test features\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# -------------------- EVALUATION --------------------\n",
        "# Calculate R-squared to see how well predictions match actual test values\n",
        "# Higher R2 (closer to 1) means better model fit\n",
        "r2_score(y_pred, y_test)\n"
      ],
      "metadata": {
        "id": "mwcQYAbinoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUPPORT VECTOR CLASSIFIER"
      ],
      "metadata": {
        "id": "EvMMu1NvpKrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- IMPORT FUNCTION --------------------\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# -------------------- GENERATE SYNTHETIC DATA --------------------\n",
        "# n_samples=1000 → 1000 rows (data points)\n",
        "# n_features=2 → 2 features (columns)\n",
        "# n_classes=2 → binary classification (0 or 1)\n",
        "# n_clusters_per_class=2 → each class has 2 clusters\n",
        "# n_redundant=0 → no redundant features (all features are informative)\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=2,\n",
        "    n_classes=2,\n",
        "    n_clusters_per_class=2,\n",
        "    n_redundant=0\n",
        ")\n",
        "\n",
        "# X → feature matrix (1000 rows × 2 columns)\n",
        "# y → target vector (1000 labels, 0 or 1)\n",
        "\n",
        "# -------------------- EXAMINE FEATURES --------------------\n",
        "pd.DataFrame(X)       # Convert X to DataFrame to inspect all feature values\n",
        "pd.DataFrame(X)[0]    # Access the first feature (column 0)\n",
        "pd.DataFrame(X)[1]    # Access the second feature (column 1)\n",
        "\n",
        "# -------------------- EXAMINE TARGET --------------------\n",
        "y                     # Display the class labels\n"
      ],
      "metadata": {
        "id": "eTua22BwpTpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a scatter plot using seaborn\n",
        "sns.scatterplot(\n",
        "    x = pd.DataFrame(X)[0],  # X-axis values: first feature (column 0) of dataset X\n",
        "    y = pd.DataFrame(X)[1],  # Y-axis values: second feature (column 1) of dataset X\n",
        "    hue = y                  # Color points according to class labels in y\n",
        ")\n"
      ],
      "metadata": {
        "id": "QOPG1M5RqVwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import function to split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "# X → features, y → target labels\n",
        "# test_size=0.30 → 30% of data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducible splits every time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shape of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "WCqlYNnVUS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SVC (Support Vector Classifier) from sklearn\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize SVM classifier with linear kernel\n",
        "classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train the SVM classifier on training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get the coefficients (weights) of the linear hyperplane\n",
        "classifier.coef_\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred  # Display predicted labels\n"
      ],
      "metadata": {
        "id": "jizFpgERUgkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import evaluation metrics for classification\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Print detailed precision, recall, f1-score, and support for each class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print confusion matrix (true vs predicted labels)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Print overall accuracy of the model\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "VW-cvywxU1Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV for hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid for SVC\n",
        "params = {\n",
        "    'C': [0.1, 0.2, 1, 2, 3, 10, 50, 100],   # Regularization parameter\n",
        "    'gamma': [1, 0.1, 0.2, 0.001, 0.003],    # Kernel coefficient\n",
        "    'kernel': ['linear']                     # Kernel type\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with SVC, 5-fold CV, and verbose for progress\n",
        "grid = GridSearchCV(SVC(), param_grid=params, cv=5, verbose=3)\n",
        "\n",
        "# Fit GridSearchCV to training data (performs exhaustive search over parameter grid)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters found\n",
        "grid.best_params_\n",
        "\n",
        "# Best cross-validated accuracy score achieved with the best hyperparameters\n",
        "grid.best_score_\n",
        "\n",
        "# Predict on test data using the best model found by GridSearchCV\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Import metrics for evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Print precision, recall, f1-score per class\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Print overall accuracy\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "9n8qE-dbVCHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUPPORT VECTOR REGRESSOR"
      ],
      "metadata": {
        "id": "V2AOK2JuWa3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import make_regression\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Generate synthetic regression dataset\n",
        "# n_samples=1000 → 1000 rows of data\n",
        "# n_features=2 → 2 independent variables/features\n",
        "# n_targets=1 → 1 dependent variable/target\n",
        "# noise=3.0 → add Gaussian noise to make the data more realistic\n",
        "X, y = make_regression(n_samples=1000, n_features=2, n_targets=1, noise=3.0)\n",
        "\n",
        "# X → feature values, y → target values\n",
        "X\n",
        "y\n",
        "\n",
        "# Plot a scatter plot using seaborn\n",
        "# x-axis → first feature (X[:,0])\n",
        "# y-axis → second feature (X[:,1])\n",
        "# hue → color points according to target value y\n",
        "sns.scatterplot(x=pd.DataFrame(X)[0], y=pd.DataFrame(X)[1], hue=y)\n"
      ],
      "metadata": {
        "id": "Q-4ud68vWyx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import function to split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split dataset\n",
        "# test_size=0.3 → 30% data for testing, 70% for training\n",
        "# random_state=1 → ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# Check the shape of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Import Support Vector Regressor (SVR)\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialize SVR model with linear kernel\n",
        "svr = SVR(kernel='linear')\n",
        "\n",
        "# Train SVR model on training data\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve coefficients of the linear SVR model (weights for each feature)\n",
        "svr.coef_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svr.predict(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "st9sQJGPXMzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import R² metric\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Evaluate performance of the SVR model\n",
        "# R² (coefficient of determination) measures how well predictions match actual values\n",
        "r2_score(y_test, y_pred)\n",
        "\n",
        "# Hyperparameter tuning for SVR using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define grid of hyperparameters to search\n",
        "params = {\n",
        "    'C': [0.1, 0.2, 1, 2, 3, 10, 50, 100],  # Regularization parameter\n",
        "    'gamma': [1, 0.1, 0.2, 0.001, 0.003],   # Kernel coefficient (not used in linear kernel but included)\n",
        "    'kernel': ['linear'],                   # Using linear kernel for SVR\n",
        "    'epsilon': [0.01, 0.1, 0.2, 0.3]       # Epsilon-tube within which no penalty is given to errors\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV to find the best hyperparameters\n",
        "# cv=5 → 5-fold cross-validation\n",
        "# verbose=3 → print progress\n",
        "grid = GridSearchCV(SVR(), param_grid=params, cv=5, verbose=3)\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best combination of hyperparameters found\n",
        "grid.best_params_\n",
        "\n",
        "# Best cross-validated score achieved during grid search\n",
        "grid.best_score_\n",
        "\n",
        "# Make predictions on test data using best SVR model\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Evaluate performance of tuned SVR using R² score\n",
        "r2_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "jetNDj7LXoJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Kernal"
      ],
      "metadata": {
        "id": "HRuqGvSsYUjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create first circle points (radius 10)\n",
        "x = np.linspace(-6.0, 6.0, 100)          # 100 points evenly spaced between -6 and 6\n",
        "y = np.sqrt(10**2 - x**2)                 # Positive half of the circle equation: y = sqrt(r^2 - x^2)\n",
        "y = np.hstack([y, -y])                    # Add negative half to complete the circle\n",
        "x = np.hstack([x, -x])                    # Duplicate x for negative half\n",
        "\n",
        "# Create second circle points (radius 4)\n",
        "x1 = np.linspace(-6.0, 6.0, 100)\n",
        "y1 = np.sqrt(4**2 - x1**2)                # Smaller circle\n",
        "y1 = np.hstack([y1, -y1])\n",
        "x1 = np.hstack([x1, -x1])\n",
        "\n",
        "# Plot both circles\n",
        "plt.scatter(y, x, label='Circle radius 10')  # First circle\n",
        "plt.scatter(y1, x1, label='Circle radius 4') # Second circle\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Create DataFrame for first circle and assign class 0\n",
        "df1 = pd.DataFrame(np.vstack([y, x]).T, columns=['X1', 'X2'])\n",
        "df1['Y'] = 0\n",
        "\n",
        "# Create DataFrame for second circle and assign class 1\n",
        "df2 = pd.DataFrame(np.vstack([y1, x1]).T, columns=['X1', 'X2'])\n",
        "df2['Y'] = 1\n",
        "\n",
        "# Combine both datasets into one\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Show first 5 rows\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "_Ez2Th5uYYLM",
        "outputId": "631d67fa-0b98-4e2a-b056-9fa0cbc3e513"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-261024985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the original dataframe and clean it\n",
        "df1 = df.copy()                    # Copy dataset to avoid modifying original\n",
        "df1 = df1.dropna()                 # Drop any missing values (if present)\n",
        "\n",
        "# Create new features for non-linear transformation\n",
        "df1[\"x1square\"] = df1[\"X1\"]**2    # X1 squared\n",
        "df1[\"x2square\"] = df1[\"X2\"]**2    # X2 squared\n",
        "df1[\"x1x2\"] = df1[\"X1\"]*df1[\"X2\"] # Interaction term X1*X2\n",
        "\n",
        "df1.head()                         # Display first 5 rows with new features\n",
        "\n",
        "# Define features (X) and target (y) for modeling\n",
        "X = df1[[\"x1square\", \"x2square\", \"x1x2\"]]  # Only the new non-linear features\n",
        "y = df1['Y']                                # Target label\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "X_train.head()  # Show first few rows of training features\n",
        "\n",
        "# Optional: visualize the transformed features in 3D\n",
        "import plotly.express as px\n",
        "fig = px.scatter_3d(df1, x=\"x1square\", y=\"x2square\", z=\"x1x2\", color=\"Y\")  # Color by class\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "gzSfobZIY6wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "mnX71v0AZW46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the iris dataset and train-test split function\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset directly as features (X) and target (y)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Display features and target\n",
        "X   # Features matrix: 150 samples × 4 features (sepal length, sepal width, petal length, petal width)\n",
        "y   # Target vector: species labels (0, 1, 2) for setosa, versicolor, virginica\n"
      ],
      "metadata": {
        "id": "5Deix_UpZg0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "# 30% of data is reserved for testing, 70% for training\n",
        "# random_state=1 ensures reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Display training and testing feature sets\n",
        "X_train   # 70% of rows used for training\n",
        "X_test    # 30% of rows used for testing\n",
        "\n",
        "# Import Gaussian Naive Bayes classifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Create a GaussianNB classifier instance\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target labels for the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred\n"
      ],
      "metadata": {
        "id": "SuqseLUzaRjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble Custom bagging classfier"
      ],
      "metadata": {
        "id": "mzhBszTZbiRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary functions\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic classification dataset\n",
        "# n_samples=1000 → 1000 rows\n",
        "# n_features=20 → 20 independent variables\n",
        "# n_classes=2 → binary classification (0 or 1)\n",
        "# random_state=1 → ensures reproducibility\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# 20% of data for testing, 80% for training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Show shapes of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "# Display first few rows of training features\n",
        "X_train\n"
      ],
      "metadata": {
        "id": "nlJPeHBCbpqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import classifiers\n",
        "from sklearn.naive_bayes import GaussianNB          # Naive Bayes for probabilistic classification\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression for linear classification\n",
        "from sklearn.tree import DecisionTreeClassifier      # Decision Tree classifier\n",
        "from sklearn.svm import SVC                          # Support Vector Classifier\n",
        "\n",
        "# Initialize the classifiers\n",
        "nb_clf = GaussianNB()                # Gaussian Naive Bayes classifier\n",
        "lr_clf = LogisticRegression()        # Logistic Regression classifier\n",
        "dt_clf = DecisionTreeClassifier()    # Decision Tree classifier\n",
        "svm_clf = SVC(kernel=\"linear\")       # Linear SVM classifier\n"
      ],
      "metadata": {
        "id": "mpqRDEs1b6ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import VotingClassifier for ensemble learning\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create an ensemble classifier using hard voting\n",
        "# estimators = list of (name, classifier) tuples\n",
        "# voting = 'hard' → majority class prediction (class label predicted by most classifiers)\n",
        "ensemble_clf = VotingClassifier(\n",
        "    estimators=[('decision_tree', dt_clf),\n",
        "                ('naive_bayes', nb_clf),\n",
        "                ('log_reg', lr_clf),\n",
        "                ('svm', svm_clf)],\n",
        "    voting=\"hard\"\n",
        ")\n",
        "\n",
        "# Display ensemble classifier details\n",
        "ensemble_clf\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict class labels for the test set\n",
        "y_pred = ensemble_clf.predict(X_test)\n",
        "y_pred\n",
        "\n",
        "# Evaluate accuracy of the ensemble model\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "EshCFbKCcHk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Custom Bagging Regressor"
      ],
      "metadata": {
        "id": "IJdNOXT5clCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a synthetic regression dataset\n",
        "# n_samples = 1000 → number of rows\n",
        "# n_features = 10 → number of independent variables\n",
        "# noise = 0.1 → standard deviation of Gaussian noise added to target\n",
        "# random_state = 42 → ensures reproducible results\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size = 0.2 → 20% for testing, 80% for training\n",
        "# random_state = 1 → ensures same split every time\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Show shapes of training and testing feature sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "7foG4DcmcwlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import regression models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Create individual regressors\n",
        "lr = LinearRegression()               # Linear Regression\n",
        "dtr = DecisionTreeRegressor()         # Decision Tree Regressor\n",
        "svr = SVR(kernel=\"linear\")            # Support Vector Regressor with linear kernel\n",
        "\n",
        "# Import VotingRegressor for ensemble\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "# Create ensemble regressor using the three models\n",
        "# estimators → list of tuples ('name', model)\n",
        "ensemble_regressor = VotingRegressor(estimators=[('mlr', lr), (\"dtr\", dtr), (\"svr\", svr)])\n",
        "\n",
        "# Check the ensemble regressor object\n",
        "ensemble_regressor\n",
        "\n",
        "# Fit the ensemble model on training data\n",
        "ensemble_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Display fitted ensemble regressor\n",
        "ensemble_regressor\n"
      ],
      "metadata": {
        "id": "LiDUuyq_de0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple models with Pipeline and ColumnTransformer"
      ],
      "metadata": {
        "id": "vqNAjP8zd89i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'tips' dataset from seaborn\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()  # Display first 5 rows\n",
        "\n",
        "# Target variable: 'time' (lunch or dinner)\n",
        "df.time.unique()  # Check unique categories in 'time'\n",
        "\n",
        "# EDA (Exploratory Data Analysis) can be subjective\n",
        "# Encoding, missing value treatment, and scaling are automated next\n",
        "\n",
        "df.info()  # Check data types and missing values\n",
        "\n",
        "# Since 'time' is a nominal categorical variable, use Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Transform 'time' column: lunch → 0, dinner → 1\n",
        "df['time'] = encoder.fit_transform(df['time'])\n",
        "df\n",
        "df.time.unique()  # Verify encoding: dinner=1, lunch=0\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('time', axis=1)  # Features (all columns except 'time')\n",
        "y = df['time']               # Target variable (time)\n",
        "X\n",
        "y\n"
      ],
      "metadata": {
        "id": "kTdBGJqieumh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "# X_train → 80% of features for training\n",
        "# X_test → 20% of features for testing\n",
        "# y_train → target for training\n",
        "# y_test → target for testing\n",
        "X_train.head()  # Display first 5 rows of training features\n",
        "\n",
        "# Check for missing values in the dataset\n",
        "df.isna().sum()  # Returns count of NaNs for each column\n",
        "\n",
        "# Import necessary preprocessing tools\n",
        "from sklearn.impute import SimpleImputer  # Handles missing values\n",
        "from sklearn.preprocessing import OneHotEncoder  # Encodes categorical columns\n",
        "from sklearn.preprocessing import StandardScaler  # Scales numerical columns\n",
        "\n",
        "# Import tools to create pipelines\n",
        "from sklearn.pipeline import Pipeline  # Chains multiple transformations\n",
        "from sklearn.compose import ColumnTransformer  # Applies transformers to specific columns\n",
        "\n",
        "# Define which columns are categorical and numerical\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\"]  # Categorical features\n",
        "num_cols = [\"total_bill\", \"tip\", \"size\"]  # Numerical features\n"
      ],
      "metadata": {
        "id": "lNOe7xiyfXvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature engineering automation using pipeline and columntransformer\n",
        "\n",
        "# 1️⃣ Numerical pipeline\n",
        "# Steps:\n",
        "# - Imputation → Fill missing values with median\n",
        "# - Scaling → Standardize numerical features\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"median\")),\n",
        "    ('scaling', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2️⃣ Categorical pipeline\n",
        "# Steps:\n",
        "# - Imputation → Fill missing values with most frequent category\n",
        "# - Encoding → Convert categorical values to numeric using one-hot encoding\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"most_frequent\")),\n",
        "    ('encoding', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# 3️⃣ ColumnTransformer\n",
        "# Applies appropriate pipeline to respective columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num_pipeline\", num_pipeline, num_cols),\n",
        "    (\"cat_pipeline\", cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# 4️⃣ Fit on training data and transform\n",
        "X_train = preprocessor.fit_transform(X_train)  # Fit + transform on training data\n",
        "X_test = preprocessor.transform(X_test)        # Only transform on test data\n",
        "\n",
        "X_train  # Transformed training data\n",
        "X_test   # Transformed testing data"
      ],
      "metadata": {
        "id": "_u8VCb3egCnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Training and Evaluating Models\n",
        "# ===============================\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1️⃣ Define models\n",
        "models = {\n",
        "    \"support vector classifier\": SVC(),\n",
        "    \"DT classifier\": DecisionTreeClassifier(),\n",
        "    \"logistic regression\": LogisticRegression()\n",
        "}\n",
        "\n",
        "# 2️⃣ Function to train and evaluate models\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    evaluation = {}  # Dictionary to store model name & accuracy\n",
        "    for i in range(len(models)):\n",
        "        model = list(models.values())[i]  # Get model instance\n",
        "        model.fit(X_train, y_train)        # Train the model\n",
        "        y_pred = model.predict(X_test)     # Predict on test set\n",
        "        model_score = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
        "        evaluation[list(models.keys())[i]] = model_score  # Save score\n",
        "    return evaluation\n",
        "\n",
        "# 3️⃣ Train all models and get evaluation scores\n",
        "model_train_eval(X_train, y_train, X_test, y_test, models)\n"
      ],
      "metadata": {
        "id": "4aFeqA_Agx3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOB SCORE"
      ],
      "metadata": {
        "id": "RDRCMSKThg7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Random Forest Classifier with OOB\n",
        "# ====================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# 1️⃣ Create a synthetic dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,     # 1000 samples\n",
        "    n_features=20,      # 20 features\n",
        "    n_classes=2,        # Binary classification\n",
        "    random_state=42     # Reproducibility\n",
        ")\n",
        "\n",
        "# 2️⃣ Initialize Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=100,   # 100 trees in the forest\n",
        "    oob_score=True,     # Use Out-of-Bag samples to estimate generalization\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3️⃣ Train the model\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# 4️⃣ Extract Out-of-Bag score\n",
        "oob_score = rf_classifier.oob_score_\n",
        "print(\"Out-of-Bag Score:\", oob_score)\n"
      ],
      "metadata": {
        "id": "qfZ_dONrhkkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RANDOM FORSEST CLASSIFIER"
      ],
      "metadata": {
        "id": "s_S1zGkhh0q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Loading dataset and basic info\n",
        "# ====================================\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# 1️⃣ Load the 'tips' dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()   # Show first 5 rows to inspect the data\n",
        "\n",
        "# 2️⃣ Check unique values in target column 'time'\n",
        "# 'time' indicates Lunch or Dinner\n",
        "df.time.unique()\n",
        "\n",
        "# 3️⃣ General info about the dataset\n",
        "# - Column names, types\n",
        "# - Number of non-null entries\n",
        "# - Memory usage\n",
        "df.info()\n"
      ],
      "metadata": {
        "id": "r2z_Ez5tiJ7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Encoding the target variable\n",
        "# ====================================\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1️⃣ Initialize LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# 2️⃣ Fit & transform the 'time' column\n",
        "# - Converts categorical labels into numeric: Lunch→0, Dinner→1\n",
        "df['time'] = encoder.fit_transform(df['time'])\n",
        "df.head()   # Inspect transformed column\n",
        "\n",
        "# 3️⃣ Check unique values after encoding\n",
        "df.time.unique()  # Output: [0, 1] → 0: Lunch, 1: Dinner\n",
        "\n",
        "# 4️⃣ Separate features (X) and target (y)\n",
        "X = df.drop('time', axis=1)  # All columns except 'time'\n",
        "y = df['time']                # Target column\n",
        "X                      # Inspect features\n",
        "y                     # Inspect target\n"
      ],
      "metadata": {
        "id": "kflxMejaidfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Train-Test Split\n",
        "# ====================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1️⃣ Split the dataset into training and testing sets\n",
        "# - X → features, y → target\n",
        "# - test_size=0.20 → 20% data for testing, 80% for training\n",
        "# - random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# 2️⃣ Inspect first few rows of training features\n",
        "X_train.head()\n",
        "\n",
        "# 3️⃣ Check for missing values in the dataset\n",
        "df.isna().sum()  # Returns count of missing values per column\n"
      ],
      "metadata": {
        "id": "Geg3r_-gi7YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Handling Missing Values, Encoding & Scaling Setup\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Import necessary transformers\n",
        "from sklearn.impute import SimpleImputer          # Handles missing values\n",
        "from sklearn.preprocessing import OneHotEncoder   # Encodes categorical variables\n",
        "from sklearn.preprocessing import StandardScaler  # Scales numerical features\n",
        "\n",
        "# 2️⃣ Import pipeline tools\n",
        "from sklearn.pipeline import Pipeline             # Chains multiple transformations\n",
        "from sklearn.compose import ColumnTransformer    # Apply different pipelines to different columns\n",
        "\n",
        "# 3️⃣ Specify categorical and numerical columns\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\"]             # Categorical features to encode\n",
        "num_cols = [\"total_bill\", \"tip\", \"size\"]        # Numerical features to scale and impute if missing\n"
      ],
      "metadata": {
        "id": "k1RjqYxijKyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================\n",
        "# Feature Engineering Automation\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Numerical pipeline\n",
        "# Steps:\n",
        "# - imputation: fill missing numerical values with median\n",
        "# - scaling: standardize features (mean=0, std=1)\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"median\")),\n",
        "    ('scaling', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2️⃣ Categorical pipeline\n",
        "# Steps:\n",
        "# - imputation: fill missing categorical values with most frequent value\n",
        "# - encoding: convert categorical variables to numerical using one-hot encoding\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('imputation', SimpleImputer(strategy=\"most_frequent\")),\n",
        "    ('encoding', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# 3️⃣ ColumnTransformer: Apply pipelines to respective columns\n",
        "# - num_pipeline → numerical columns\n",
        "# - cat_pipeline → categorical columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num_pipeline\", num_pipeline, num_cols),\n",
        "    (\"cat_pipeline\", cat_pipeline, cat_cols)\n",
        "])\n",
        "\n",
        "# 4️⃣ Transform training and testing data\n",
        "# fit_transform on training data, transform on test data\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "# 5️⃣ Outputs: Preprocessed feature arrays ready for modeling\n",
        "X_train\n",
        "X_test\n"
      ],
      "metadata": {
        "id": "tARMou-djjCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ====================================\n",
        "# Model Training & Evaluation Function\n",
        "# ====================================\n",
        "\n",
        "# 1️⃣ Import models\n",
        "# - DecisionTreeClassifier, SVC, LogisticRegression, RandomForestClassifier already imported\n",
        "\n",
        "# 2️⃣ Define dictionary of models\n",
        "# Key = model name (string), Value = model instance\n",
        "models = {\n",
        "    \"support vector classifier\": SVC(),\n",
        "    \"DT classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic regression\": LogisticRegression(),\n",
        "    \"Random_forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# 3️⃣ Function to train and evaluate models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    \"\"\"\n",
        "    Trains each model on X_train/y_train and evaluates on X_test/y_test.\n",
        "    Returns a dictionary with model names as keys and accuracy scores as values.\n",
        "    \"\"\"\n",
        "    evaluation = {}  # store model_name: accuracy\n",
        "    for i in range(len(models)):\n",
        "        model = list(models.values())[i]  # get model instance\n",
        "        model.fit(X_train, y_train)       # train model\n",
        "        y_pred = model.predict(X_test)    # predict on test set\n",
        "        model_score = accuracy_score(y_test, y_pred)  # calculate accuracy\n",
        "        evaluation[list(models.keys())[i]] = model_score  # store result\n",
        "    return evaluation\n",
        "\n",
        "# Example usage:\n",
        "# model_train_eval(X_train, y_train, X_test, y_test, models)\n",
        "model_train_eval(X_train, y_train, X_test, y_test, models)\n"
      ],
      "metadata": {
        "id": "R9pbiHEtkMpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Random Forest Classifier with Hyperparameter Tuning\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 1️⃣ Create Random Forest classifier instance\n",
        "rf = RandomForestClassifier()  # default params\n",
        "rf\n",
        "\n",
        "# 2️⃣ Define hyperparameter grid for tuning\n",
        "params = {\n",
        "    'max_depth': [1, 2, 3, 5, 10, None],   # Maximum depth of each tree\n",
        "    'n_estimators': [50, 100, 200, 300],  # Number of trees in the forest\n",
        "    'criterion': ['gini', 'entropy']      # Function to measure quality of split\n",
        "}\n",
        "params  # just to visualize the param grid\n",
        "\n",
        "# 3️⃣ Create RandomizedSearchCV object\n",
        "clf = RandomizedSearchCV(\n",
        "    estimator=rf,            # model to tune\n",
        "    param_distributions=params,  # param grid\n",
        "    cv=5,                    # 5-fold cross-validation\n",
        "    verbose=3,               # print progress\n",
        "    scoring='accuracy'       # metric to evaluate\n",
        ")\n",
        "clf  # see the RandomizedSearchCV object\n",
        "\n",
        "# 4️⃣ Fit RandomizedSearchCV to training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5️⃣ Best parameters and score found\n",
        "clf.best_params_  # best hyperparameters\n",
        "clf.best_score_   # corresponding accuracy\n"
      ],
      "metadata": {
        "id": "yMGenfbOlF3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple models with Pipeline and ColumnTransformer"
      ],
      "metadata": {
        "id": "aoRqHlxZq69o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Prepare dataset for regression task\n",
        "# ==========================================\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 1️⃣ Load dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "df.head()  # Show first 5 rows\n",
        "\n",
        "# 2️⃣ Target variable: 'total_bill' (predict total bill amount)\n",
        "# Features: everything else\n",
        "\n",
        "# 3️⃣ Check unique values for 'time' (categorical column)\n",
        "df.time.unique()  # lunch, dinner\n",
        "\n",
        "# 4️⃣ Basic EDA and data info\n",
        "# Here, subjective exploration: check dtypes, missing values, etc.\n",
        "df.info()\n",
        "\n",
        "# 5️⃣ Split features and target\n",
        "X = df.drop('total_bill', axis=1)  # independent features\n",
        "y = df['total_bill']               # dependent variable (target)\n",
        "\n",
        "X  # feature dataframe\n",
        "y  # target series\n"
      ],
      "metadata": {
        "id": "bUPPM1yRq80v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Train-Test Split & Missing Value Check\n",
        "# ==========================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1️⃣ Split dataset into training and testing sets\n",
        "# test_size=0.20 → 20% of data for testing, 80% for training\n",
        "# random_state=1 → ensures reproducible split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
        "\n",
        "# 2️⃣ Preview first 5 rows of training features\n",
        "X_train.head()\n",
        "\n",
        "# 3️⃣ Check for missing values in each column\n",
        "df.isna().sum()\n"
      ],
      "metadata": {
        "id": "iv2QCGqjrT3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the missing value\n",
        "#data encoding\n",
        "#feature scaling\n",
        "\n",
        "from sklearn.impute import SimpleImputer #for missing vlaue\n",
        "from sklearn.preprocessing import OneHotEncoder #for encoding\n",
        "from sklearn.preprocessing import StandardScaler #for scaling\n",
        "\n",
        "from sklearn.pipeline import Pipeline #A sequence of data transformers\n",
        "from sklearn.compose import ColumnTransformer #Groups all the pipeline steps for each of the clumns\n",
        "cat_cols = [\"sex\", \"smoker\", \"day\", \"time\"]\n",
        "num_cols = [\"tip\", \"size\"]\n",
        "\n",
        "#feature engineering automation using pipeline and columntransformer\n",
        "\n",
        "num_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"median\")),\n",
        "                                ('scaling', StandardScaler())])\n",
        "cat_pipeline = Pipeline(steps = [('imputation', SimpleImputer(strategy = \"most_frequent\")),\n",
        "                                ('encoding', OneHotEncoder())])\n",
        "\n",
        "preprocessor = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_cols),\n",
        "                  (\"cat_pipeline\", cat_pipeline, cat_cols)])\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "X_train\n",
        "# X_test"
      ],
      "metadata": {
        "id": "OH3VsQgtrwS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Dictionary of regression models\n",
        "models = {\n",
        "    \"Support Vector Regressor\": SVR(),\n",
        "    \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "    \"Multiple Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest Regressor\": RandomForestRegressor()\n",
        "}\n",
        "\n",
        "# Function to train and evaluate models\n",
        "def model_train_eval(X_train, y_train, X_test, y_test, models):\n",
        "    evaluation = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)          # Train model\n",
        "        y_pred = model.predict(X_test)       # Predict on test set\n",
        "        model_score = r2_score(y_test, y_pred)  # Calculate R^2 score\n",
        "        evaluation[name] = model_score       # Store result\n",
        "    return evaluation\n",
        "\n",
        "# Call the function and get R^2 scores for all models\n",
        "evaluation_results = model_train_eval(X_train, y_train, X_test, y_test, models)\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "id": "hZV-s5TjsIIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Initialize the Random Forest Regressor with OOB score enabled\n",
        "rfr = RandomForestRegressor(oob_score=True, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for RandomizedSearch\n",
        "params = {\n",
        "    'max_depth': [1, 50, 100, 150, 200],\n",
        "    'n_estimators': [50, 100, 200]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "reg = RandomizedSearchCV(\n",
        "    estimator=rfr,\n",
        "    param_distributions=params,\n",
        "    cv=5,\n",
        "    verbose=3,\n",
        "    scoring='r2',\n",
        "    n_iter=10,       # Number of parameter settings to try\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", reg.best_params_)\n",
        "\n",
        "# Best R2 score from cross-validation\n",
        "print(\"Best CV R2 Score:\", reg.best_score_)\n"
      ],
      "metadata": {
        "id": "qsIP1kBYsmRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}